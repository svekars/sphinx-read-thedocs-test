Search.setIndex({"alltitles": {"API test": [[710, "api-test"]], "Accelerators": [[712, "accelerators"]], "Admonitions": [[0, null]], "Aliases": [[707, "aliases"]], "Another Heading": [[709, "another-heading"]], "BLAS and LAPACK Operations": [[712, "blas-and-lapack-operations"]], "BasePruningMethod": [[520, null]], "Build from source": [[703, "build-from-source"]], "Check availability for Intel GPU": [[703, "check-availability-for-intel-gpu"]], "Communication payload size": [[704, "communication-payload-size"]], "Comparison Ops": [[712, "comparison-ops"]], "Containers": [[707, "containers"]], "Control Flow": [[712, "control-flow"]], "Convolution Layers": [[707, "convolution-layers"]], "Creation Ops": [[712, "creation-ops"]], "CustomFromMask": [[521, null]], "DataParallel Layers (multi-GPU, distributed)": [[707, "module-torch.nn.parallel"]], "Distance Functions": [[707, "distance-functions"]], "Dropout Layers": [[707, "dropout-layers"]], "Event": [[1, null]], "Examples": [[703, "examples"]], "Export Path": [[712, "export-path"]], "FSDP Notes": [[704, null]], "FSDP Prefetch Nuances": [[704, "fsdp-prefetch-nuances"]], "FSDP buffers sizes": [[704, "fsdp-buffers-sizes"]], "Foreach Operations": [[712, "foreach-operations"]], "Generator": [[2, null]], "Generators": [[712, "generators"]], "Getting Started": [[709, null]], "Hardware Prerequisites": [[703, "hardware-prerequisites"]], "Heading 1": [[708, "heading-1"]], "Heading 1-2": [[708, "heading-1-2"]], "Heading 2": [[701, "heading-2"]], "Heading 3": [[701, "heading-3"], [701, "id1"], [709, "heading-3"]], "Heading 4": [[701, "heading-4"]], "Identity": [[522, null]], "In-place random sampling": [[712, "in-place-random-sampling"]], "Indexing, Slicing, Joining, Mutating Ops": [[712, "indexing-slicing-joining-mutating-ops"]], "Inference Examples": [[703, "inference-examples"]], "Inference with AMP": [[703, "inference-with-amp"]], "Inference with FP32": [[703, "inference-with-fp32"]], "Inference with torch.compile": [[703, "inference-with-torch-compile"]], "L1Unstructured": [[523, null]], "Lazy Modules Initialization": [[707, "lazy-modules-initialization"]], "Linear Layers": [[707, "linear-layers"]], "LnStructured": [[524, null]], "Locally disabling gradient computation": [[712, "locally-disabling-gradient-computation"]], "Loss Functions": [[707, "loss-functions"]], "Math operations": [[712, "math-operations"]], "Minimum Code Change": [[703, "minimum-code-change"]], "My subheading 2-1": [[705, "my-subheading-2-1"]], "My subheading 2-2": [[705, "my-subheading-2-2"]], "Non-linear Activations (other)": [[707, "non-linear-activations-other"]], "Non-linear Activations (weighted sum, nonlinearity)": [[707, "non-linear-activations-weighted-sum-nonlinearity"]], "Normalization Layers": [[707, "normalization-layers"]], "Operator Tags": [[712, "operator-tags"]], "Optimizations": [[712, "optimizations"]], "Other Operations": [[712, "other-operations"]], "Overview": [[708, null]], "PackedSequence": [[539, null]], "Padding Layers": [[707, "padding-layers"]], "Parallelism": [[712, "parallelism"]], "Pointwise Ops": [[712, "pointwise-ops"]], "Pooling layers": [[707, "pooling-layers"]], "PruningContainer": [[525, null]], "PyTorch Sphinx Theme 2 documentation": [[701, null]], "Pytorch 2.4: Getting Started on Intel GPU": [[703, null]], "Quantized Functions": [[707, "quantized-functions"]], "Quasi-random sampling": [[712, "quasi-random-sampling"]], "Random sampling": [[712, "random-sampling"]], "RandomStructured": [[526, null]], "RandomUnstructured": [[527, null]], "Recurrent Layers": [[707, "recurrent-layers"]], "Reduction Ops": [[712, "reduction-ops"]], "Serialization": [[712, "serialization"]], "Set up Environment": [[703, "set-up-environment"]], "Shuffle Layers": [[707, "shuffle-layers"]], "Software Prerequisites": [[703, "software-prerequisites"]], "Sparse Layers": [[707, "sparse-layers"]], "Spectral Ops": [[712, "spectral-ops"]], "Stream": [[3, null]], "Subeading 2": [[708, "subeading-2"]], "Subintro page home": [[702, null]], "Symbolic Numbers": [[712, "symbolic-numbers"]], "Tensor Attributes": [[711, null]], "Tensors": [[710, "tensors"], [712, "tensors"]], "Test 2 page": [[706, null]], "Test Markdown Page": [[710, null]], "Test Page 1": [[705, null]], "Testing warning:": [[710, "testing-warning"]], "Torch": [[710, "module-torch"]], "Train with AMP": [[703, "train-with-amp"]], "Train with FP32": [[703, "train-with-fp32"]], "Training Examples": [[703, "training-examples"]], "Transformer Layers": [[707, "transformer-layers"]], "Tutorial 1": [[714, null]], "Tutorial 2": [[715, null]], "Tutorials": [[713, null]], "Utilities": [[707, "module-torch.nn.utils"], [712, "utilities"]], "Vision Layers": [[707, "vision-layers"]], "_assert": [[4, null]], "_foreach_abs": [[5, null]], "_foreach_abs_": [[6, null]], "_foreach_acos": [[7, null]], "_foreach_acos_": [[8, null]], "_foreach_asin": [[9, null]], "_foreach_asin_": [[10, null]], "_foreach_atan": [[11, null]], "_foreach_atan_": [[12, null]], "_foreach_ceil": [[13, null]], "_foreach_ceil_": [[14, null]], "_foreach_cos": [[15, null]], "_foreach_cos_": [[16, null]], "_foreach_cosh": [[17, null]], "_foreach_cosh_": [[18, null]], "_foreach_erf": [[19, null]], "_foreach_erf_": [[20, null]], "_foreach_erfc": [[21, null]], "_foreach_erfc_": [[22, null]], "_foreach_exp": [[23, null]], "_foreach_exp_": [[24, null]], "_foreach_expm1": [[25, null]], "_foreach_expm1_": [[26, null]], "_foreach_floor": [[27, null]], "_foreach_floor_": [[28, null]], "_foreach_frac": [[29, null]], "_foreach_frac_": [[30, null]], "_foreach_lgamma": [[31, null]], "_foreach_lgamma_": [[32, null]], "_foreach_log": [[33, null]], "_foreach_log10": [[34, null]], "_foreach_log10_": [[35, null]], "_foreach_log1p": [[36, null]], "_foreach_log1p_": [[37, null]], "_foreach_log2": [[38, null]], "_foreach_log2_": [[39, null]], "_foreach_log_": [[40, null]], "_foreach_neg": [[41, null]], "_foreach_neg_": [[42, null]], "_foreach_reciprocal": [[43, null]], "_foreach_reciprocal_": [[44, null]], "_foreach_round": [[45, null]], "_foreach_round_": [[46, null]], "_foreach_sigmoid": [[47, null]], "_foreach_sigmoid_": [[48, null]], "_foreach_sin": [[49, null]], "_foreach_sin_": [[50, null]], "_foreach_sinh": [[51, null]], "_foreach_sinh_": [[52, null]], "_foreach_sqrt": [[53, null]], "_foreach_sqrt_": [[54, null]], "_foreach_tan": [[55, null]], "_foreach_tan_": [[56, null]], "_foreach_trunc": [[57, null]], "_foreach_trunc_": [[58, null]], "_foreach_zero_": [[59, null]], "abs": [[60, null]], "absolute": [[61, null]], "acos": [[62, null]], "acosh": [[63, null]], "add": [[64, null]], "addbmm": [[65, null]], "addcdiv": [[66, null]], "addcmul": [[67, null]], "addmm": [[68, null]], "addmv": [[69, null]], "addr": [[70, null]], "adjoint": [[71, null]], "all": [[72, null]], "allclose": [[73, null]], "amax": [[74, null]], "amin": [[75, null]], "aminmax": [[76, null]], "angle": [[77, null]], "any": [[78, null]], "arange": [[79, null]], "arccos": [[80, null]], "arccosh": [[81, null]], "arcsin": [[82, null]], "arcsinh": [[83, null]], "arctan": [[84, null]], "arctan2": [[85, null]], "arctanh": [[86, null]], "are_deterministic_algorithms_enabled": [[87, null]], "argmax": [[88, null]], "argmin": [[89, null]], "argsort": [[90, null]], "argwhere": [[91, null]], "as_strided": [[92, null]], "as_tensor": [[93, null]], "asarray": [[94, null]], "asin": [[95, null]], "asinh": [[96, null]], "atan": [[97, null]], "atan2": [[98, null]], "atanh": [[99, null]], "atleast_1d": [[100, null]], "atleast_2d": [[101, null]], "atleast_3d": [[102, null]], "baddbmm": [[105, null]], "bartlett_window": [[106, null]], "bernoulli": [[107, null]], "bincount": [[108, null]], "bitwise_and": [[109, null]], "bitwise_left_shift": [[110, null]], "bitwise_not": [[111, null]], "bitwise_or": [[112, null]], "bitwise_right_shift": [[113, null]], "bitwise_xor": [[114, null]], "blackman_window": [[115, null]], "block_diag": [[116, null]], "bmm": [[117, null]], "broadcast_shapes": [[118, null]], "broadcast_tensors": [[119, null]], "broadcast_to": [[120, null]], "bucketize": [[121, null]], "cached": [[516, null]], "can_cast": [[122, null]], "cartesian_prod": [[123, null]], "cat": [[124, null]], "cdist": [[125, null]], "ceil": [[126, null]], "chain_matmul": [[127, null]], "cholesky": [[128, null]], "cholesky_inverse": [[129, null]], "cholesky_solve": [[130, null]], "chunk": [[131, null]], "clamp": [[132, null]], "clip": [[133, null]], "clip_grad_norm": [[502, null], [503, null]], "clip_grad_value": [[504, null]], "clone": [[134, null]], "column_stack": [[135, null]], "combinations": [[136, null]], "compile": [[137, null]], "compiled_with_cxx11_abi": [[138, null]], "complex": [[139, null]], "concat": [[140, null]], "concatenate": [[141, null]], "cond": [[142, null]], "conj": [[143, null]], "conj_physical": [[144, null]], "convert_conv2d_weight_memory_format": [[505, null]], "convert_conv3d_weight_memory_format": [[506, null]], "copysign": [[145, null]], "corrcoef": [[146, null]], "cos": [[147, null]], "cosh": [[148, null]], "count_nonzero": [[149, null]], "cov": [[150, null]], "cross": [[151, null]], "cummax": [[152, null]], "cummin": [[153, null]], "cumprod": [[154, null]], "cumsum": [[155, null]], "cumulative_trapezoid": [[156, null]], "custom_from_mask": [[528, null]], "deg2rad": [[157, null]], "dequantize": [[158, null]], "det": [[159, null]], "diag": [[160, null]], "diag_embed": [[161, null]], "diagflat": [[162, null]], "diagonal": [[163, null]], "diagonal_scatter": [[164, null]], "diff": [[165, null]], "digamma": [[166, null]], "dist": [[167, null]], "div": [[168, null]], "divide": [[169, null]], "dot": [[170, null]], "dsplit": [[171, null]], "dstack": [[172, null]], "einsum": [[173, null]], "empty": [[174, null]], "empty_like": [[175, null]], "empty_strided": [[176, null]], "enable_grad": [[177, null]], "eq": [[178, null]], "equal": [[179, null]], "erf": [[180, null]], "erfc": [[181, null]], "erfinv": [[182, null]], "exp": [[183, null]], "exp2": [[184, null]], "expm1": [[185, null]], "eye": [[186, null]], "fake_quantize_per_channel_affine": [[187, null]], "fake_quantize_per_tensor_affine": [[188, null]], "fix": [[189, null]], "flatten": [[190, null]], "flip": [[191, null]], "fliplr": [[192, null]], "flipud": [[193, null]], "float_power": [[194, null]], "floor": [[195, null]], "floor_divide": [[196, null]], "fmax": [[197, null]], "fmin": [[198, null]], "fmod": [[199, null]], "frac": [[200, null]], "frexp": [[201, null]], "from_dlpack": [[202, null]], "from_file": [[203, null]], "from_numpy": [[204, null]], "frombuffer": [[205, null]], "full": [[206, null]], "full_like": [[207, null]], "functional_call": [[548, null]], "fuse_conv_bn_eval": [[507, null]], "fuse_conv_bn_weights": [[508, null]], "fuse_linear_bn_eval": [[509, null]], "fuse_linear_bn_weights": [[510, null]], "gather": [[208, null]], "gcd": [[209, null]], "ge": [[210, null]], "geqrf": [[211, null]], "ger": [[212, null]], "get_default_device": [[213, null]], "get_default_dtype": [[214, null]], "get_deterministic_debug_mode": [[215, null]], "get_device_module": [[216, null]], "get_float32_matmul_precision": [[217, null]], "get_num_interop_threads": [[218, null]], "get_num_threads": [[219, null]], "get_rng_state": [[220, null]], "global_unstructured": [[529, null]], "gradient": [[221, null]], "greater": [[222, null]], "greater_equal": [[223, null]], "gt": [[224, null]], "hamming_window": [[225, null]], "hann_window": [[226, null]], "heaviside": [[227, null]], "histc": [[228, null]], "histogram": [[229, null]], "histogramdd": [[230, null]], "hsplit": [[231, null]], "hstack": [[232, null]], "hypot": [[233, null]], "i0": [[234, null]], "identity": [[530, null]], "igamma": [[235, null]], "igammac": [[236, null]], "imag": [[237, null]], "index_add": [[238, null]], "index_copy": [[239, null]], "index_reduce": [[240, null]], "index_select": [[241, null]], "inference_mode": [[103, null]], "initial_seed": [[242, null]], "inner": [[243, null]], "inverse": [[244, null]], "is_complex": [[245, null]], "is_conj": [[246, null]], "is_deterministic_algorithms_warn_only_enabled": [[247, null]], "is_floating_point": [[248, null]], "is_grad_enabled": [[249, null]], "is_inference_mode_enabled": [[250, null]], "is_nonzero": [[251, null]], "is_parametrized": [[517, null]], "is_pruned": [[531, null]], "is_storage": [[252, null]], "is_tensor": [[253, null]], "is_warn_always_enabled": [[254, null]], "isclose": [[255, null]], "isfinite": [[256, null]], "isin": [[257, null]], "isinf": [[258, null]], "isnan": [[259, null]], "isneginf": [[260, null]], "isposinf": [[261, null]], "isreal": [[262, null]], "istft": [[263, null]], "kaiser_window": [[264, null]], "kron": [[265, null]], "kthvalue": [[266, null]], "l1_unstructured": [[532, null]], "lcm": [[267, null]], "ldexp": [[268, null]], "le": [[269, null]], "lerp": [[270, null]], "less": [[271, null]], "less_equal": [[272, null]], "lgamma": [[273, null]], "linspace": [[274, null]], "ln_structured": [[533, null]], "load": [[275, null]], "lobpcg": [[276, null]], "log": [[277, null]], "log10": [[278, null]], "log1p": [[279, null]], "log2": [[280, null]], "logaddexp": [[281, null]], "logaddexp2": [[282, null]], "logcumsumexp": [[283, null]], "logdet": [[284, null]], "logical_and": [[285, null]], "logical_not": [[286, null]], "logical_or": [[287, null]], "logical_xor": [[288, null]], "logit": [[289, null]], "logspace": [[290, null]], "logsumexp": [[291, null]], "lt": [[292, null]], "lu": [[293, null]], "lu_solve": [[294, null]], "lu_unpack": [[295, null]], "manual_seed": [[296, null]], "masked_select": [[297, null]], "matmul": [[298, null]], "matrix_exp": [[299, null]], "matrix_power": [[300, null]], "max": [[301, null]], "maximum": [[302, null]], "mean": [[303, null]], "median": [[304, null]], "meshgrid": [[305, null]], "min": [[306, null]], "minimum": [[307, null]], "mm": [[308, null]], "mode": [[309, null]], "moveaxis": [[310, null]], "movedim": [[311, null]], "msort": [[312, null]], "mul": [[313, null]], "multinomial": [[314, null]], "multiply": [[315, null]], "mv": [[316, null]], "mvlgamma": [[317, null]], "nan_to_num": [[318, null]], "nanmean": [[319, null]], "nanmedian": [[320, null]], "nanquantile": [[321, null]], "nansum": [[322, null]], "narrow": [[323, null]], "narrow_copy": [[324, null]], "ne": [[325, null]], "neg": [[326, null]], "negative": [[327, null]], "nextafter": [[328, null]], "no_grad": [[551, null]], "nonzero": [[552, null]], "norm": [[553, null]], "normal": [[554, null]], "not_equal": [[555, null]], "numel": [[556, null]], "ones": [[557, null]], "ones_like": [[558, null]], "orgqr": [[559, null]], "ormqr": [[560, null]], "orthogonal": [[512, null]], "outer": [[561, null]], "pack_padded_sequence": [[540, null]], "pack_sequence": [[541, null]], "pad_packed_sequence": [[542, null]], "pad_sequence": [[543, null]], "parameters_to_vector": [[511, null]], "pca_lowrank": [[562, null]], "permute": [[563, null]], "pinverse": [[564, null]], "poisson": [[565, null]], "polar": [[566, null]], "polygamma": [[567, null]], "positive": [[568, null]], "pow": [[569, null]], "prod": [[570, null]], "promote_types": [[571, null]], "qr": [[572, null]], "quantile": [[573, null]], "quantize_per_channel": [[574, null]], "quantize_per_tensor": [[575, null]], "quantized_batch_norm": [[576, null]], "quantized_max_pool1d": [[577, null]], "quantized_max_pool2d": [[578, null]], "rad2deg": [[580, null]], "rand": [[581, null]], "rand_like": [[582, null]], "randint": [[583, null]], "randint_like": [[584, null]], "randn": [[585, null]], "randn_like": [[586, null]], "random_structured": [[534, null]], "random_unstructured": [[535, null]], "randperm": [[587, null]], "range": [[588, null]], "ravel": [[589, null]], "real": [[590, null]], "reciprocal": [[591, null]], "register_module_backward_hook": [[488, null]], "register_module_buffer_registration_hook": [[489, null]], "register_module_forward_hook": [[490, null]], "register_module_forward_pre_hook": [[491, null]], "register_module_full_backward_hook": [[492, null]], "register_module_full_backward_pre_hook": [[493, null]], "register_module_module_registration_hook": [[494, null]], "register_module_parameter_registration_hook": [[495, null]], "register_parametrization": [[518, null]], "remainder": [[592, null]], "remove": [[536, null]], "remove_parametrizations": [[519, null]], "remove_spectral_norm": [[537, null]], "remove_weight_norm": [[538, null]], "renorm": [[593, null]], "repeat_interleave": [[594, null]], "reshape": [[595, null]], "resolve_conj": [[596, null]], "resolve_neg": [[597, null]], "result_type": [[598, null]], "roll": [[599, null]], "rot90": [[600, null]], "round": [[601, null]], "row_stack": [[602, null]], "rsqrt": [[603, null]], "save": [[604, null]], "scatter": [[605, null]], "scatter_add": [[606, null]], "scatter_reduce": [[607, null]], "searchsorted": [[608, null]], "seed": [[609, null]], "select": [[610, null]], "select_scatter": [[611, null]], "set_default_device": [[612, null]], "set_default_dtype": [[613, null]], "set_default_tensor_type": [[614, null]], "set_deterministic_debug_mode": [[615, null]], "set_float32_matmul_precision": [[616, null]], "set_flush_denormal": [[617, null]], "set_grad_enabled": [[104, null]], "set_num_interop_threads": [[618, null]], "set_num_threads": [[619, null]], "set_printoptions": [[620, null]], "set_rng_state": [[621, null]], "set_warn_always": [[622, null]], "sgn": [[623, null]], "sigmoid": [[624, null]], "sign": [[625, null]], "signbit": [[626, null]], "sin": [[627, null]], "sinc": [[628, null]], "sinh": [[629, null]], "skip_init": [[546, null]], "slice_scatter": [[630, null]], "slogdet": [[631, null]], "softmax": [[632, null]], "sort": [[633, null]], "sparse_bsc_tensor": [[634, null]], "sparse_bsr_tensor": [[635, null]], "sparse_coo_tensor": [[636, null]], "sparse_csc_tensor": [[637, null]], "sparse_csr_tensor": [[638, null]], "spectral_norm": [[513, null], [547, null]], "split": [[639, null]], "sqrt": [[640, null]], "square": [[641, null]], "squeeze": [[642, null]], "stack": [[643, null]], "std": [[644, null]], "std_mean": [[645, null]], "stft": [[646, null]], "sub": [[647, null]], "subtract": [[648, null]], "sum": [[649, null]], "svd": [[650, null]], "svd_lowrank": [[651, null]], "swapaxes": [[652, null]], "swapdims": [[653, null]], "sym_float": [[654, null]], "sym_int": [[655, null]], "sym_ite": [[656, null]], "sym_max": [[657, null]], "sym_min": [[658, null]], "sym_not": [[659, null]], "t": [[660, null]], "take": [[661, null]], "take_along_dim": [[662, null]], "tan": [[663, null]], "tanh": [[664, null]], "tensor": [[665, null]], "tensor_split": [[666, null]], "tensordot": [[667, null]], "tile": [[668, null]], "topk": [[669, null]], "torch": [[712, null]], "torch.device": [[711, "torch-device"]], "torch.dtype": [[711, "torch-dtype"]], "torch.layout": [[711, "torch-layout"]], "torch.memory_format": [[711, "torch-memory-format"]], "torch.nn": [[707, null], [707, "id1"]], "torch.nn.AdaptiveAvgPool1d": [[329, null]], "torch.nn.AdaptiveAvgPool2d": [[330, null]], "torch.nn.AdaptiveAvgPool3d": [[331, null]], "torch.nn.AdaptiveLogSoftmaxWithLoss": [[332, null]], "torch.nn.AdaptiveMaxPool1d": [[333, null]], "torch.nn.AdaptiveMaxPool2d": [[334, null]], "torch.nn.AdaptiveMaxPool3d": [[335, null]], "torch.nn.AlphaDropout": [[336, null]], "torch.nn.AvgPool1d": [[337, null]], "torch.nn.AvgPool2d": [[338, null]], "torch.nn.AvgPool3d": [[339, null]], "torch.nn.BCELoss": [[340, null]], "torch.nn.BCEWithLogitsLoss": [[341, null]], "torch.nn.BatchNorm1d": [[342, null]], "torch.nn.BatchNorm2d": [[343, null]], "torch.nn.BatchNorm3d": [[344, null]], "torch.nn.Bilinear": [[345, null]], "torch.nn.CELU": [[346, null]], "torch.nn.CTCLoss": [[347, null]], "torch.nn.ChannelShuffle": [[348, null]], "torch.nn.CircularPad1d": [[349, null]], "torch.nn.CircularPad2d": [[350, null]], "torch.nn.CircularPad3d": [[351, null]], "torch.nn.ConstantPad1d": [[352, null]], "torch.nn.ConstantPad2d": [[353, null]], "torch.nn.ConstantPad3d": [[354, null]], "torch.nn.Conv1d": [[355, null]], "torch.nn.Conv2d": [[356, null]], "torch.nn.Conv3d": [[357, null]], "torch.nn.ConvTranspose1d": [[358, null]], "torch.nn.ConvTranspose2d": [[359, null]], "torch.nn.ConvTranspose3d": [[360, null]], "torch.nn.CosineEmbeddingLoss": [[361, null]], "torch.nn.CosineSimilarity": [[362, null]], "torch.nn.CrossEntropyLoss": [[363, null]], "torch.nn.DataParallel": [[364, null]], "torch.nn.Dropout": [[365, null]], "torch.nn.Dropout1d": [[366, null]], "torch.nn.Dropout2d": [[367, null]], "torch.nn.Dropout3d": [[368, null]], "torch.nn.ELU": [[369, null]], "torch.nn.Embedding": [[370, null]], "torch.nn.EmbeddingBag": [[371, null]], "torch.nn.FeatureAlphaDropout": [[372, null]], "torch.nn.Flatten": [[373, null]], "torch.nn.Fold": [[374, null]], "torch.nn.FractionalMaxPool2d": [[375, null]], "torch.nn.FractionalMaxPool3d": [[376, null]], "torch.nn.GELU": [[377, null]], "torch.nn.GLU": [[378, null]], "torch.nn.GRU": [[379, null]], "torch.nn.GRUCell": [[380, null]], "torch.nn.GaussianNLLLoss": [[381, null]], "torch.nn.GroupNorm": [[382, null]], "torch.nn.Hardshrink": [[383, null]], "torch.nn.Hardsigmoid": [[384, null]], "torch.nn.Hardswish": [[385, null]], "torch.nn.Hardtanh": [[386, null]], "torch.nn.HingeEmbeddingLoss": [[387, null]], "torch.nn.HuberLoss": [[388, null]], "torch.nn.Identity": [[389, null]], "torch.nn.InstanceNorm1d": [[390, null]], "torch.nn.InstanceNorm2d": [[391, null]], "torch.nn.InstanceNorm3d": [[392, null]], "torch.nn.KLDivLoss": [[393, null]], "torch.nn.L1Loss": [[394, null]], "torch.nn.LPPool1d": [[395, null]], "torch.nn.LPPool2d": [[396, null]], "torch.nn.LPPool3d": [[397, null]], "torch.nn.LSTM": [[398, null]], "torch.nn.LSTMCell": [[399, null]], "torch.nn.LayerNorm": [[400, null]], "torch.nn.LazyBatchNorm1d": [[401, null]], "torch.nn.LazyBatchNorm2d": [[402, null]], "torch.nn.LazyBatchNorm3d": [[403, null]], "torch.nn.LazyConv1d": [[404, null]], "torch.nn.LazyConv2d": [[405, null]], "torch.nn.LazyConv3d": [[406, null]], "torch.nn.LazyConvTranspose1d": [[407, null]], "torch.nn.LazyConvTranspose2d": [[408, null]], "torch.nn.LazyConvTranspose3d": [[409, null]], "torch.nn.LazyInstanceNorm1d": [[410, null]], "torch.nn.LazyInstanceNorm2d": [[411, null]], "torch.nn.LazyInstanceNorm3d": [[412, null]], "torch.nn.LazyLinear": [[413, null]], "torch.nn.LeakyReLU": [[414, null]], "torch.nn.Linear": [[415, null]], "torch.nn.LocalResponseNorm": [[416, null]], "torch.nn.LogSigmoid": [[417, null]], "torch.nn.LogSoftmax": [[418, null]], "torch.nn.MSELoss": [[419, null]], "torch.nn.MarginRankingLoss": [[420, null]], "torch.nn.MaxPool1d": [[421, null]], "torch.nn.MaxPool2d": [[422, null]], "torch.nn.MaxPool3d": [[423, null]], "torch.nn.MaxUnpool1d": [[424, null]], "torch.nn.MaxUnpool2d": [[425, null]], "torch.nn.MaxUnpool3d": [[426, null]], "torch.nn.Mish": [[427, null]], "torch.nn.Module": [[428, null]], "torch.nn.ModuleDict": [[429, null]], "torch.nn.ModuleList": [[430, null]], "torch.nn.MultiLabelMarginLoss": [[431, null]], "torch.nn.MultiLabelSoftMarginLoss": [[432, null]], "torch.nn.MultiMarginLoss": [[433, null]], "torch.nn.MultiheadAttention": [[434, null]], "torch.nn.NLLLoss": [[435, null]], "torch.nn.PReLU": [[436, null]], "torch.nn.PairwiseDistance": [[437, null]], "torch.nn.ParameterDict": [[438, null]], "torch.nn.ParameterList": [[439, null]], "torch.nn.PixelShuffle": [[440, null]], "torch.nn.PixelUnshuffle": [[441, null]], "torch.nn.PoissonNLLLoss": [[442, null]], "torch.nn.RMSNorm": [[443, null]], "torch.nn.RNN": [[444, null]], "torch.nn.RNNBase": [[445, null]], "torch.nn.RNNCell": [[446, null]], "torch.nn.RReLU": [[447, null]], "torch.nn.ReLU": [[448, null]], "torch.nn.ReLU6": [[449, null]], "torch.nn.ReflectionPad1d": [[450, null]], "torch.nn.ReflectionPad2d": [[451, null]], "torch.nn.ReflectionPad3d": [[452, null]], "torch.nn.ReplicationPad1d": [[453, null]], "torch.nn.ReplicationPad2d": [[454, null]], "torch.nn.ReplicationPad3d": [[455, null]], "torch.nn.SELU": [[456, null]], "torch.nn.Sequential": [[457, null]], "torch.nn.SiLU": [[458, null]], "torch.nn.Sigmoid": [[459, null]], "torch.nn.SmoothL1Loss": [[460, null]], "torch.nn.SoftMarginLoss": [[461, null]], "torch.nn.Softmax": [[462, null]], "torch.nn.Softmax2d": [[463, null]], "torch.nn.Softmin": [[464, null]], "torch.nn.Softplus": [[465, null]], "torch.nn.Softshrink": [[466, null]], "torch.nn.Softsign": [[467, null]], "torch.nn.SyncBatchNorm": [[468, null]], "torch.nn.Tanh": [[469, null]], "torch.nn.Tanhshrink": [[470, null]], "torch.nn.Threshold": [[471, null]], "torch.nn.Transformer": [[472, null]], "torch.nn.TransformerDecoder": [[473, null]], "torch.nn.TransformerDecoderLayer": [[474, null]], "torch.nn.TransformerEncoder": [[475, null]], "torch.nn.TransformerEncoderLayer": [[476, null]], "torch.nn.TripletMarginLoss": [[477, null]], "torch.nn.TripletMarginWithDistanceLoss": [[478, null]], "torch.nn.Unflatten": [[479, null]], "torch.nn.Unfold": [[480, null]], "torch.nn.Upsample": [[481, null]], "torch.nn.UpsamplingBilinear2d": [[482, null]], "torch.nn.UpsamplingNearest2d": [[483, null]], "torch.nn.ZeroPad1d": [[484, null]], "torch.nn.ZeroPad2d": [[485, null]], "torch.nn.ZeroPad3d": [[486, null]], "torch.nn.modules.lazy.LazyModuleMixin": [[487, null]], "torch.nn.modules.normalization.RMSNorm": [[496, null]], "torch.nn.parallel.DistributedDataParallel": [[497, null]], "torch.nn.parameter.Buffer": [[498, null]], "torch.nn.parameter.Parameter": [[499, null]], "torch.nn.parameter.UninitializedBuffer": [[500, null]], "torch.nn.parameter.UninitializedParameter": [[501, null]], "torch.nn.utils.parametrize.ParametrizationList": [[515, null]], "torch.quasirandom.SobolEngine": [[579, null]], "trace": [[670, null]], "transpose": [[671, null]], "trapezoid": [[672, null]], "trapz": [[673, null]], "triangular_solve": [[674, null]], "tril": [[675, null]], "tril_indices": [[676, null]], "triu": [[677, null]], "triu_indices": [[678, null]], "true_divide": [[679, null]], "trunc": [[680, null]], "unbind": [[681, null]], "unflatten": [[682, null]], "unique": [[683, null]], "unique_consecutive": [[684, null]], "unpack_sequence": [[544, null]], "unpad_sequence": [[545, null]], "unravel_index": [[685, null]], "unsqueeze": [[686, null]], "use_deterministic_algorithms": [[687, null]], "vander": [[688, null]], "var": [[689, null]], "var_mean": [[690, null]], "vdot": [[691, null]], "vector_to_parameters": [[549, null]], "view_as_complex": [[692, null]], "view_as_real": [[693, null]], "vmap": [[694, null]], "vsplit": [[695, null]], "vstack": [[696, null]], "weight_norm": [[514, null], [550, null]], "where": [[697, null]], "xlogy": [[698, null]], "zeros": [[699, null]], "zeros_like": [[700, null]]}, "docnames": ["admonitions", "generated/torch.Event", "generated/torch.Generator", "generated/torch.Stream", "generated/torch._assert", "generated/torch._foreach_abs", "generated/torch._foreach_abs_", "generated/torch._foreach_acos", "generated/torch._foreach_acos_", "generated/torch._foreach_asin", "generated/torch._foreach_asin_", "generated/torch._foreach_atan", "generated/torch._foreach_atan_", "generated/torch._foreach_ceil", "generated/torch._foreach_ceil_", "generated/torch._foreach_cos", "generated/torch._foreach_cos_", "generated/torch._foreach_cosh", "generated/torch._foreach_cosh_", "generated/torch._foreach_erf", "generated/torch._foreach_erf_", "generated/torch._foreach_erfc", "generated/torch._foreach_erfc_", "generated/torch._foreach_exp", "generated/torch._foreach_exp_", "generated/torch._foreach_expm1", "generated/torch._foreach_expm1_", "generated/torch._foreach_floor", "generated/torch._foreach_floor_", "generated/torch._foreach_frac", "generated/torch._foreach_frac_", "generated/torch._foreach_lgamma", "generated/torch._foreach_lgamma_", "generated/torch._foreach_log", "generated/torch._foreach_log10", "generated/torch._foreach_log10_", "generated/torch._foreach_log1p", "generated/torch._foreach_log1p_", "generated/torch._foreach_log2", "generated/torch._foreach_log2_", "generated/torch._foreach_log_", "generated/torch._foreach_neg", "generated/torch._foreach_neg_", "generated/torch._foreach_reciprocal", "generated/torch._foreach_reciprocal_", "generated/torch._foreach_round", "generated/torch._foreach_round_", "generated/torch._foreach_sigmoid", "generated/torch._foreach_sigmoid_", "generated/torch._foreach_sin", "generated/torch._foreach_sin_", "generated/torch._foreach_sinh", "generated/torch._foreach_sinh_", "generated/torch._foreach_sqrt", "generated/torch._foreach_sqrt_", "generated/torch._foreach_tan", "generated/torch._foreach_tan_", "generated/torch._foreach_trunc", "generated/torch._foreach_trunc_", "generated/torch._foreach_zero_", "generated/torch.abs", "generated/torch.absolute", "generated/torch.acos", "generated/torch.acosh", "generated/torch.add", "generated/torch.addbmm", "generated/torch.addcdiv", "generated/torch.addcmul", "generated/torch.addmm", "generated/torch.addmv", "generated/torch.addr", "generated/torch.adjoint", "generated/torch.all", "generated/torch.allclose", "generated/torch.amax", "generated/torch.amin", "generated/torch.aminmax", "generated/torch.angle", "generated/torch.any", "generated/torch.arange", "generated/torch.arccos", "generated/torch.arccosh", "generated/torch.arcsin", "generated/torch.arcsinh", "generated/torch.arctan", "generated/torch.arctan2", "generated/torch.arctanh", "generated/torch.are_deterministic_algorithms_enabled", "generated/torch.argmax", "generated/torch.argmin", "generated/torch.argsort", "generated/torch.argwhere", "generated/torch.as_strided", "generated/torch.as_tensor", "generated/torch.asarray", "generated/torch.asin", "generated/torch.asinh", "generated/torch.atan", "generated/torch.atan2", "generated/torch.atanh", "generated/torch.atleast_1d", "generated/torch.atleast_2d", "generated/torch.atleast_3d", "generated/torch.autograd.grad_mode.inference_mode", "generated/torch.autograd.grad_mode.set_grad_enabled", "generated/torch.baddbmm", "generated/torch.bartlett_window", "generated/torch.bernoulli", "generated/torch.bincount", "generated/torch.bitwise_and", "generated/torch.bitwise_left_shift", "generated/torch.bitwise_not", "generated/torch.bitwise_or", "generated/torch.bitwise_right_shift", "generated/torch.bitwise_xor", "generated/torch.blackman_window", "generated/torch.block_diag", "generated/torch.bmm", "generated/torch.broadcast_shapes", "generated/torch.broadcast_tensors", "generated/torch.broadcast_to", "generated/torch.bucketize", "generated/torch.can_cast", "generated/torch.cartesian_prod", "generated/torch.cat", "generated/torch.cdist", "generated/torch.ceil", "generated/torch.chain_matmul", "generated/torch.cholesky", "generated/torch.cholesky_inverse", "generated/torch.cholesky_solve", "generated/torch.chunk", "generated/torch.clamp", "generated/torch.clip", "generated/torch.clone", "generated/torch.column_stack", "generated/torch.combinations", "generated/torch.compile", "generated/torch.compiled_with_cxx11_abi", "generated/torch.complex", "generated/torch.concat", "generated/torch.concatenate", "generated/torch.cond", "generated/torch.conj", "generated/torch.conj_physical", "generated/torch.copysign", "generated/torch.corrcoef", "generated/torch.cos", "generated/torch.cosh", "generated/torch.count_nonzero", "generated/torch.cov", "generated/torch.cross", "generated/torch.cummax", "generated/torch.cummin", "generated/torch.cumprod", "generated/torch.cumsum", "generated/torch.cumulative_trapezoid", "generated/torch.deg2rad", "generated/torch.dequantize", "generated/torch.det", "generated/torch.diag", "generated/torch.diag_embed", "generated/torch.diagflat", "generated/torch.diagonal", "generated/torch.diagonal_scatter", "generated/torch.diff", "generated/torch.digamma", "generated/torch.dist", "generated/torch.div", "generated/torch.divide", "generated/torch.dot", "generated/torch.dsplit", "generated/torch.dstack", "generated/torch.einsum", "generated/torch.empty", "generated/torch.empty_like", "generated/torch.empty_strided", "generated/torch.enable_grad", "generated/torch.eq", "generated/torch.equal", "generated/torch.erf", "generated/torch.erfc", "generated/torch.erfinv", "generated/torch.exp", "generated/torch.exp2", "generated/torch.expm1", "generated/torch.eye", "generated/torch.fake_quantize_per_channel_affine", "generated/torch.fake_quantize_per_tensor_affine", "generated/torch.fix", "generated/torch.flatten", "generated/torch.flip", "generated/torch.fliplr", "generated/torch.flipud", "generated/torch.float_power", "generated/torch.floor", "generated/torch.floor_divide", "generated/torch.fmax", "generated/torch.fmin", "generated/torch.fmod", "generated/torch.frac", "generated/torch.frexp", "generated/torch.from_dlpack", "generated/torch.from_file", "generated/torch.from_numpy", "generated/torch.frombuffer", "generated/torch.full", "generated/torch.full_like", "generated/torch.gather", "generated/torch.gcd", "generated/torch.ge", "generated/torch.geqrf", "generated/torch.ger", "generated/torch.get_default_device", "generated/torch.get_default_dtype", "generated/torch.get_deterministic_debug_mode", "generated/torch.get_device_module", "generated/torch.get_float32_matmul_precision", "generated/torch.get_num_interop_threads", "generated/torch.get_num_threads", "generated/torch.get_rng_state", "generated/torch.gradient", "generated/torch.greater", "generated/torch.greater_equal", "generated/torch.gt", "generated/torch.hamming_window", "generated/torch.hann_window", "generated/torch.heaviside", "generated/torch.histc", "generated/torch.histogram", "generated/torch.histogramdd", "generated/torch.hsplit", "generated/torch.hstack", "generated/torch.hypot", "generated/torch.i0", "generated/torch.igamma", "generated/torch.igammac", "generated/torch.imag", "generated/torch.index_add", "generated/torch.index_copy", "generated/torch.index_reduce", "generated/torch.index_select", "generated/torch.initial_seed", "generated/torch.inner", "generated/torch.inverse", "generated/torch.is_complex", "generated/torch.is_conj", "generated/torch.is_deterministic_algorithms_warn_only_enabled", "generated/torch.is_floating_point", "generated/torch.is_grad_enabled", "generated/torch.is_inference_mode_enabled", "generated/torch.is_nonzero", "generated/torch.is_storage", "generated/torch.is_tensor", "generated/torch.is_warn_always_enabled", "generated/torch.isclose", "generated/torch.isfinite", "generated/torch.isin", "generated/torch.isinf", "generated/torch.isnan", "generated/torch.isneginf", "generated/torch.isposinf", "generated/torch.isreal", "generated/torch.istft", "generated/torch.kaiser_window", "generated/torch.kron", "generated/torch.kthvalue", "generated/torch.lcm", "generated/torch.ldexp", "generated/torch.le", "generated/torch.lerp", "generated/torch.less", "generated/torch.less_equal", "generated/torch.lgamma", "generated/torch.linspace", "generated/torch.load", "generated/torch.lobpcg", "generated/torch.log", "generated/torch.log10", "generated/torch.log1p", "generated/torch.log2", "generated/torch.logaddexp", "generated/torch.logaddexp2", "generated/torch.logcumsumexp", "generated/torch.logdet", "generated/torch.logical_and", "generated/torch.logical_not", "generated/torch.logical_or", "generated/torch.logical_xor", "generated/torch.logit", "generated/torch.logspace", "generated/torch.logsumexp", "generated/torch.lt", "generated/torch.lu", "generated/torch.lu_solve", "generated/torch.lu_unpack", "generated/torch.manual_seed", "generated/torch.masked_select", "generated/torch.matmul", "generated/torch.matrix_exp", "generated/torch.matrix_power", "generated/torch.max", "generated/torch.maximum", "generated/torch.mean", "generated/torch.median", "generated/torch.meshgrid", "generated/torch.min", "generated/torch.minimum", "generated/torch.mm", "generated/torch.mode", "generated/torch.moveaxis", "generated/torch.movedim", "generated/torch.msort", "generated/torch.mul", "generated/torch.multinomial", "generated/torch.multiply", "generated/torch.mv", "generated/torch.mvlgamma", "generated/torch.nan_to_num", "generated/torch.nanmean", "generated/torch.nanmedian", "generated/torch.nanquantile", "generated/torch.nansum", "generated/torch.narrow", "generated/torch.narrow_copy", "generated/torch.ne", "generated/torch.neg", "generated/torch.negative", "generated/torch.nextafter", "generated/torch.nn.AdaptiveAvgPool1d", "generated/torch.nn.AdaptiveAvgPool2d", "generated/torch.nn.AdaptiveAvgPool3d", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss", "generated/torch.nn.AdaptiveMaxPool1d", "generated/torch.nn.AdaptiveMaxPool2d", "generated/torch.nn.AdaptiveMaxPool3d", "generated/torch.nn.AlphaDropout", "generated/torch.nn.AvgPool1d", "generated/torch.nn.AvgPool2d", "generated/torch.nn.AvgPool3d", "generated/torch.nn.BCELoss", "generated/torch.nn.BCEWithLogitsLoss", "generated/torch.nn.BatchNorm1d", "generated/torch.nn.BatchNorm2d", "generated/torch.nn.BatchNorm3d", "generated/torch.nn.Bilinear", "generated/torch.nn.CELU", "generated/torch.nn.CTCLoss", "generated/torch.nn.ChannelShuffle", "generated/torch.nn.CircularPad1d", "generated/torch.nn.CircularPad2d", "generated/torch.nn.CircularPad3d", "generated/torch.nn.ConstantPad1d", "generated/torch.nn.ConstantPad2d", "generated/torch.nn.ConstantPad3d", "generated/torch.nn.Conv1d", "generated/torch.nn.Conv2d", "generated/torch.nn.Conv3d", "generated/torch.nn.ConvTranspose1d", "generated/torch.nn.ConvTranspose2d", "generated/torch.nn.ConvTranspose3d", "generated/torch.nn.CosineEmbeddingLoss", "generated/torch.nn.CosineSimilarity", "generated/torch.nn.CrossEntropyLoss", "generated/torch.nn.DataParallel", "generated/torch.nn.Dropout", "generated/torch.nn.Dropout1d", "generated/torch.nn.Dropout2d", "generated/torch.nn.Dropout3d", "generated/torch.nn.ELU", "generated/torch.nn.Embedding", "generated/torch.nn.EmbeddingBag", "generated/torch.nn.FeatureAlphaDropout", "generated/torch.nn.Flatten", "generated/torch.nn.Fold", "generated/torch.nn.FractionalMaxPool2d", "generated/torch.nn.FractionalMaxPool3d", "generated/torch.nn.GELU", "generated/torch.nn.GLU", "generated/torch.nn.GRU", "generated/torch.nn.GRUCell", "generated/torch.nn.GaussianNLLLoss", "generated/torch.nn.GroupNorm", "generated/torch.nn.Hardshrink", "generated/torch.nn.Hardsigmoid", "generated/torch.nn.Hardswish", "generated/torch.nn.Hardtanh", "generated/torch.nn.HingeEmbeddingLoss", "generated/torch.nn.HuberLoss", "generated/torch.nn.Identity", "generated/torch.nn.InstanceNorm1d", "generated/torch.nn.InstanceNorm2d", "generated/torch.nn.InstanceNorm3d", "generated/torch.nn.KLDivLoss", "generated/torch.nn.L1Loss", "generated/torch.nn.LPPool1d", "generated/torch.nn.LPPool2d", "generated/torch.nn.LPPool3d", "generated/torch.nn.LSTM", "generated/torch.nn.LSTMCell", "generated/torch.nn.LayerNorm", "generated/torch.nn.LazyBatchNorm1d", "generated/torch.nn.LazyBatchNorm2d", "generated/torch.nn.LazyBatchNorm3d", "generated/torch.nn.LazyConv1d", "generated/torch.nn.LazyConv2d", "generated/torch.nn.LazyConv3d", "generated/torch.nn.LazyConvTranspose1d", "generated/torch.nn.LazyConvTranspose2d", "generated/torch.nn.LazyConvTranspose3d", "generated/torch.nn.LazyInstanceNorm1d", "generated/torch.nn.LazyInstanceNorm2d", "generated/torch.nn.LazyInstanceNorm3d", "generated/torch.nn.LazyLinear", "generated/torch.nn.LeakyReLU", "generated/torch.nn.Linear", "generated/torch.nn.LocalResponseNorm", "generated/torch.nn.LogSigmoid", "generated/torch.nn.LogSoftmax", "generated/torch.nn.MSELoss", "generated/torch.nn.MarginRankingLoss", "generated/torch.nn.MaxPool1d", "generated/torch.nn.MaxPool2d", "generated/torch.nn.MaxPool3d", "generated/torch.nn.MaxUnpool1d", "generated/torch.nn.MaxUnpool2d", "generated/torch.nn.MaxUnpool3d", "generated/torch.nn.Mish", "generated/torch.nn.Module", "generated/torch.nn.ModuleDict", "generated/torch.nn.ModuleList", "generated/torch.nn.MultiLabelMarginLoss", "generated/torch.nn.MultiLabelSoftMarginLoss", "generated/torch.nn.MultiMarginLoss", "generated/torch.nn.MultiheadAttention", "generated/torch.nn.NLLLoss", "generated/torch.nn.PReLU", "generated/torch.nn.PairwiseDistance", "generated/torch.nn.ParameterDict", "generated/torch.nn.ParameterList", "generated/torch.nn.PixelShuffle", "generated/torch.nn.PixelUnshuffle", "generated/torch.nn.PoissonNLLLoss", "generated/torch.nn.RMSNorm", "generated/torch.nn.RNN", "generated/torch.nn.RNNBase", "generated/torch.nn.RNNCell", "generated/torch.nn.RReLU", "generated/torch.nn.ReLU", "generated/torch.nn.ReLU6", "generated/torch.nn.ReflectionPad1d", "generated/torch.nn.ReflectionPad2d", "generated/torch.nn.ReflectionPad3d", "generated/torch.nn.ReplicationPad1d", "generated/torch.nn.ReplicationPad2d", "generated/torch.nn.ReplicationPad3d", "generated/torch.nn.SELU", "generated/torch.nn.Sequential", "generated/torch.nn.SiLU", "generated/torch.nn.Sigmoid", "generated/torch.nn.SmoothL1Loss", "generated/torch.nn.SoftMarginLoss", "generated/torch.nn.Softmax", "generated/torch.nn.Softmax2d", "generated/torch.nn.Softmin", "generated/torch.nn.Softplus", "generated/torch.nn.Softshrink", "generated/torch.nn.Softsign", "generated/torch.nn.SyncBatchNorm", "generated/torch.nn.Tanh", "generated/torch.nn.Tanhshrink", "generated/torch.nn.Threshold", "generated/torch.nn.Transformer", "generated/torch.nn.TransformerDecoder", "generated/torch.nn.TransformerDecoderLayer", "generated/torch.nn.TransformerEncoder", "generated/torch.nn.TransformerEncoderLayer", "generated/torch.nn.TripletMarginLoss", "generated/torch.nn.TripletMarginWithDistanceLoss", "generated/torch.nn.Unflatten", "generated/torch.nn.Unfold", "generated/torch.nn.Upsample", "generated/torch.nn.UpsamplingBilinear2d", "generated/torch.nn.UpsamplingNearest2d", "generated/torch.nn.ZeroPad1d", "generated/torch.nn.ZeroPad2d", "generated/torch.nn.ZeroPad3d", "generated/torch.nn.modules.lazy.LazyModuleMixin", "generated/torch.nn.modules.module.register_module_backward_hook", "generated/torch.nn.modules.module.register_module_buffer_registration_hook", "generated/torch.nn.modules.module.register_module_forward_hook", "generated/torch.nn.modules.module.register_module_forward_pre_hook", "generated/torch.nn.modules.module.register_module_full_backward_hook", "generated/torch.nn.modules.module.register_module_full_backward_pre_hook", "generated/torch.nn.modules.module.register_module_module_registration_hook", "generated/torch.nn.modules.module.register_module_parameter_registration_hook", "generated/torch.nn.modules.normalization.RMSNorm", "generated/torch.nn.parallel.DistributedDataParallel", "generated/torch.nn.parameter.Buffer", "generated/torch.nn.parameter.Parameter", "generated/torch.nn.parameter.UninitializedBuffer", "generated/torch.nn.parameter.UninitializedParameter", "generated/torch.nn.utils.clip_grad_norm", "generated/torch.nn.utils.clip_grad_norm_", "generated/torch.nn.utils.clip_grad_value_", "generated/torch.nn.utils.convert_conv2d_weight_memory_format", "generated/torch.nn.utils.convert_conv3d_weight_memory_format", "generated/torch.nn.utils.fuse_conv_bn_eval", "generated/torch.nn.utils.fuse_conv_bn_weights", "generated/torch.nn.utils.fuse_linear_bn_eval", "generated/torch.nn.utils.fuse_linear_bn_weights", "generated/torch.nn.utils.parameters_to_vector", "generated/torch.nn.utils.parametrizations.orthogonal", "generated/torch.nn.utils.parametrizations.spectral_norm", "generated/torch.nn.utils.parametrizations.weight_norm", "generated/torch.nn.utils.parametrize.ParametrizationList", "generated/torch.nn.utils.parametrize.cached", "generated/torch.nn.utils.parametrize.is_parametrized", "generated/torch.nn.utils.parametrize.register_parametrization", "generated/torch.nn.utils.parametrize.remove_parametrizations", "generated/torch.nn.utils.prune.BasePruningMethod", "generated/torch.nn.utils.prune.CustomFromMask", "generated/torch.nn.utils.prune.Identity", "generated/torch.nn.utils.prune.L1Unstructured", "generated/torch.nn.utils.prune.LnStructured", "generated/torch.nn.utils.prune.PruningContainer", "generated/torch.nn.utils.prune.RandomStructured", "generated/torch.nn.utils.prune.RandomUnstructured", "generated/torch.nn.utils.prune.custom_from_mask", "generated/torch.nn.utils.prune.global_unstructured", "generated/torch.nn.utils.prune.identity", "generated/torch.nn.utils.prune.is_pruned", "generated/torch.nn.utils.prune.l1_unstructured", "generated/torch.nn.utils.prune.ln_structured", "generated/torch.nn.utils.prune.random_structured", "generated/torch.nn.utils.prune.random_unstructured", "generated/torch.nn.utils.prune.remove", "generated/torch.nn.utils.remove_spectral_norm", "generated/torch.nn.utils.remove_weight_norm", "generated/torch.nn.utils.rnn.PackedSequence", "generated/torch.nn.utils.rnn.pack_padded_sequence", "generated/torch.nn.utils.rnn.pack_sequence", "generated/torch.nn.utils.rnn.pad_packed_sequence", "generated/torch.nn.utils.rnn.pad_sequence", "generated/torch.nn.utils.rnn.unpack_sequence", "generated/torch.nn.utils.rnn.unpad_sequence", "generated/torch.nn.utils.skip_init", "generated/torch.nn.utils.spectral_norm", "generated/torch.nn.utils.stateless.functional_call", "generated/torch.nn.utils.vector_to_parameters", "generated/torch.nn.utils.weight_norm", "generated/torch.no_grad", "generated/torch.nonzero", "generated/torch.norm", "generated/torch.normal", "generated/torch.not_equal", "generated/torch.numel", "generated/torch.ones", "generated/torch.ones_like", "generated/torch.orgqr", "generated/torch.ormqr", "generated/torch.outer", "generated/torch.pca_lowrank", "generated/torch.permute", "generated/torch.pinverse", "generated/torch.poisson", "generated/torch.polar", "generated/torch.polygamma", "generated/torch.positive", "generated/torch.pow", "generated/torch.prod", "generated/torch.promote_types", "generated/torch.qr", "generated/torch.quantile", "generated/torch.quantize_per_channel", "generated/torch.quantize_per_tensor", "generated/torch.quantized_batch_norm", "generated/torch.quantized_max_pool1d", "generated/torch.quantized_max_pool2d", "generated/torch.quasirandom.SobolEngine", "generated/torch.rad2deg", "generated/torch.rand", "generated/torch.rand_like", "generated/torch.randint", "generated/torch.randint_like", "generated/torch.randn", "generated/torch.randn_like", "generated/torch.randperm", "generated/torch.range", "generated/torch.ravel", "generated/torch.real", "generated/torch.reciprocal", "generated/torch.remainder", "generated/torch.renorm", "generated/torch.repeat_interleave", "generated/torch.reshape", "generated/torch.resolve_conj", "generated/torch.resolve_neg", "generated/torch.result_type", "generated/torch.roll", "generated/torch.rot90", "generated/torch.round", "generated/torch.row_stack", "generated/torch.rsqrt", "generated/torch.save", "generated/torch.scatter", "generated/torch.scatter_add", "generated/torch.scatter_reduce", "generated/torch.searchsorted", "generated/torch.seed", "generated/torch.select", "generated/torch.select_scatter", "generated/torch.set_default_device", "generated/torch.set_default_dtype", "generated/torch.set_default_tensor_type", "generated/torch.set_deterministic_debug_mode", "generated/torch.set_float32_matmul_precision", "generated/torch.set_flush_denormal", "generated/torch.set_num_interop_threads", "generated/torch.set_num_threads", "generated/torch.set_printoptions", "generated/torch.set_rng_state", "generated/torch.set_warn_always", "generated/torch.sgn", "generated/torch.sigmoid", "generated/torch.sign", "generated/torch.signbit", "generated/torch.sin", "generated/torch.sinc", "generated/torch.sinh", "generated/torch.slice_scatter", "generated/torch.slogdet", "generated/torch.softmax", "generated/torch.sort", "generated/torch.sparse_bsc_tensor", "generated/torch.sparse_bsr_tensor", "generated/torch.sparse_coo_tensor", "generated/torch.sparse_csc_tensor", "generated/torch.sparse_csr_tensor", "generated/torch.split", "generated/torch.sqrt", "generated/torch.square", "generated/torch.squeeze", "generated/torch.stack", "generated/torch.std", "generated/torch.std_mean", "generated/torch.stft", "generated/torch.sub", "generated/torch.subtract", "generated/torch.sum", "generated/torch.svd", "generated/torch.svd_lowrank", "generated/torch.swapaxes", "generated/torch.swapdims", "generated/torch.sym_float", "generated/torch.sym_int", "generated/torch.sym_ite", "generated/torch.sym_max", "generated/torch.sym_min", "generated/torch.sym_not", "generated/torch.t", "generated/torch.take", "generated/torch.take_along_dim", "generated/torch.tan", "generated/torch.tanh", "generated/torch.tensor", "generated/torch.tensor_split", "generated/torch.tensordot", "generated/torch.tile", "generated/torch.topk", "generated/torch.trace", "generated/torch.transpose", "generated/torch.trapezoid", "generated/torch.trapz", "generated/torch.triangular_solve", "generated/torch.tril", "generated/torch.tril_indices", "generated/torch.triu", "generated/torch.triu_indices", "generated/torch.true_divide", "generated/torch.trunc", "generated/torch.unbind", "generated/torch.unflatten", "generated/torch.unique", "generated/torch.unique_consecutive", "generated/torch.unravel_index", "generated/torch.unsqueeze", "generated/torch.use_deterministic_algorithms", "generated/torch.vander", "generated/torch.var", "generated/torch.var_mean", "generated/torch.vdot", "generated/torch.view_as_complex", "generated/torch.view_as_real", "generated/torch.vmap", "generated/torch.vsplit", "generated/torch.vstack", "generated/torch.where", "generated/torch.xlogy", "generated/torch.zeros", "generated/torch.zeros_like", "index", "intro/subintro-page", "intro/subintro/page1", "intro/subintro/page2", "intro/test1", "intro/test2", "nn", "page1", "page2", "page3", "tensor_attributes", "torch", "tutorials", "tutorials/tutorial1", "tutorials/tutorial2"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1}, "filenames": ["admonitions.rst", "generated/torch.Event.rst", "generated/torch.Generator.rst", "generated/torch.Stream.rst", "generated/torch._assert.rst", "generated/torch._foreach_abs.rst", "generated/torch._foreach_abs_.rst", "generated/torch._foreach_acos.rst", "generated/torch._foreach_acos_.rst", "generated/torch._foreach_asin.rst", "generated/torch._foreach_asin_.rst", "generated/torch._foreach_atan.rst", "generated/torch._foreach_atan_.rst", "generated/torch._foreach_ceil.rst", "generated/torch._foreach_ceil_.rst", "generated/torch._foreach_cos.rst", "generated/torch._foreach_cos_.rst", "generated/torch._foreach_cosh.rst", "generated/torch._foreach_cosh_.rst", "generated/torch._foreach_erf.rst", "generated/torch._foreach_erf_.rst", "generated/torch._foreach_erfc.rst", "generated/torch._foreach_erfc_.rst", "generated/torch._foreach_exp.rst", "generated/torch._foreach_exp_.rst", "generated/torch._foreach_expm1.rst", "generated/torch._foreach_expm1_.rst", "generated/torch._foreach_floor.rst", "generated/torch._foreach_floor_.rst", "generated/torch._foreach_frac.rst", "generated/torch._foreach_frac_.rst", "generated/torch._foreach_lgamma.rst", "generated/torch._foreach_lgamma_.rst", "generated/torch._foreach_log.rst", "generated/torch._foreach_log10.rst", "generated/torch._foreach_log10_.rst", "generated/torch._foreach_log1p.rst", "generated/torch._foreach_log1p_.rst", "generated/torch._foreach_log2.rst", "generated/torch._foreach_log2_.rst", "generated/torch._foreach_log_.rst", "generated/torch._foreach_neg.rst", "generated/torch._foreach_neg_.rst", "generated/torch._foreach_reciprocal.rst", "generated/torch._foreach_reciprocal_.rst", "generated/torch._foreach_round.rst", "generated/torch._foreach_round_.rst", "generated/torch._foreach_sigmoid.rst", "generated/torch._foreach_sigmoid_.rst", "generated/torch._foreach_sin.rst", "generated/torch._foreach_sin_.rst", "generated/torch._foreach_sinh.rst", "generated/torch._foreach_sinh_.rst", "generated/torch._foreach_sqrt.rst", "generated/torch._foreach_sqrt_.rst", "generated/torch._foreach_tan.rst", "generated/torch._foreach_tan_.rst", "generated/torch._foreach_trunc.rst", "generated/torch._foreach_trunc_.rst", "generated/torch._foreach_zero_.rst", "generated/torch.abs.rst", "generated/torch.absolute.rst", "generated/torch.acos.rst", "generated/torch.acosh.rst", "generated/torch.add.rst", "generated/torch.addbmm.rst", "generated/torch.addcdiv.rst", "generated/torch.addcmul.rst", "generated/torch.addmm.rst", "generated/torch.addmv.rst", "generated/torch.addr.rst", "generated/torch.adjoint.rst", "generated/torch.all.rst", "generated/torch.allclose.rst", "generated/torch.amax.rst", "generated/torch.amin.rst", "generated/torch.aminmax.rst", "generated/torch.angle.rst", "generated/torch.any.rst", "generated/torch.arange.rst", "generated/torch.arccos.rst", "generated/torch.arccosh.rst", "generated/torch.arcsin.rst", "generated/torch.arcsinh.rst", "generated/torch.arctan.rst", "generated/torch.arctan2.rst", "generated/torch.arctanh.rst", "generated/torch.are_deterministic_algorithms_enabled.rst", "generated/torch.argmax.rst", "generated/torch.argmin.rst", "generated/torch.argsort.rst", "generated/torch.argwhere.rst", "generated/torch.as_strided.rst", "generated/torch.as_tensor.rst", "generated/torch.asarray.rst", "generated/torch.asin.rst", "generated/torch.asinh.rst", "generated/torch.atan.rst", "generated/torch.atan2.rst", "generated/torch.atanh.rst", "generated/torch.atleast_1d.rst", "generated/torch.atleast_2d.rst", "generated/torch.atleast_3d.rst", "generated/torch.autograd.grad_mode.inference_mode.rst", "generated/torch.autograd.grad_mode.set_grad_enabled.rst", "generated/torch.baddbmm.rst", "generated/torch.bartlett_window.rst", "generated/torch.bernoulli.rst", "generated/torch.bincount.rst", "generated/torch.bitwise_and.rst", "generated/torch.bitwise_left_shift.rst", "generated/torch.bitwise_not.rst", "generated/torch.bitwise_or.rst", "generated/torch.bitwise_right_shift.rst", "generated/torch.bitwise_xor.rst", "generated/torch.blackman_window.rst", "generated/torch.block_diag.rst", "generated/torch.bmm.rst", "generated/torch.broadcast_shapes.rst", "generated/torch.broadcast_tensors.rst", "generated/torch.broadcast_to.rst", "generated/torch.bucketize.rst", "generated/torch.can_cast.rst", "generated/torch.cartesian_prod.rst", "generated/torch.cat.rst", "generated/torch.cdist.rst", "generated/torch.ceil.rst", "generated/torch.chain_matmul.rst", "generated/torch.cholesky.rst", "generated/torch.cholesky_inverse.rst", "generated/torch.cholesky_solve.rst", "generated/torch.chunk.rst", "generated/torch.clamp.rst", "generated/torch.clip.rst", "generated/torch.clone.rst", "generated/torch.column_stack.rst", "generated/torch.combinations.rst", "generated/torch.compile.rst", "generated/torch.compiled_with_cxx11_abi.rst", "generated/torch.complex.rst", "generated/torch.concat.rst", "generated/torch.concatenate.rst", "generated/torch.cond.rst", "generated/torch.conj.rst", "generated/torch.conj_physical.rst", "generated/torch.copysign.rst", "generated/torch.corrcoef.rst", "generated/torch.cos.rst", "generated/torch.cosh.rst", "generated/torch.count_nonzero.rst", "generated/torch.cov.rst", "generated/torch.cross.rst", "generated/torch.cummax.rst", "generated/torch.cummin.rst", "generated/torch.cumprod.rst", "generated/torch.cumsum.rst", "generated/torch.cumulative_trapezoid.rst", "generated/torch.deg2rad.rst", "generated/torch.dequantize.rst", "generated/torch.det.rst", "generated/torch.diag.rst", "generated/torch.diag_embed.rst", "generated/torch.diagflat.rst", "generated/torch.diagonal.rst", "generated/torch.diagonal_scatter.rst", "generated/torch.diff.rst", "generated/torch.digamma.rst", "generated/torch.dist.rst", "generated/torch.div.rst", "generated/torch.divide.rst", "generated/torch.dot.rst", "generated/torch.dsplit.rst", "generated/torch.dstack.rst", "generated/torch.einsum.rst", "generated/torch.empty.rst", "generated/torch.empty_like.rst", "generated/torch.empty_strided.rst", "generated/torch.enable_grad.rst", "generated/torch.eq.rst", "generated/torch.equal.rst", "generated/torch.erf.rst", "generated/torch.erfc.rst", "generated/torch.erfinv.rst", "generated/torch.exp.rst", "generated/torch.exp2.rst", "generated/torch.expm1.rst", "generated/torch.eye.rst", "generated/torch.fake_quantize_per_channel_affine.rst", "generated/torch.fake_quantize_per_tensor_affine.rst", "generated/torch.fix.rst", "generated/torch.flatten.rst", "generated/torch.flip.rst", "generated/torch.fliplr.rst", "generated/torch.flipud.rst", "generated/torch.float_power.rst", "generated/torch.floor.rst", "generated/torch.floor_divide.rst", "generated/torch.fmax.rst", "generated/torch.fmin.rst", "generated/torch.fmod.rst", "generated/torch.frac.rst", "generated/torch.frexp.rst", "generated/torch.from_dlpack.rst", "generated/torch.from_file.rst", "generated/torch.from_numpy.rst", "generated/torch.frombuffer.rst", "generated/torch.full.rst", "generated/torch.full_like.rst", "generated/torch.gather.rst", "generated/torch.gcd.rst", "generated/torch.ge.rst", "generated/torch.geqrf.rst", "generated/torch.ger.rst", "generated/torch.get_default_device.rst", "generated/torch.get_default_dtype.rst", "generated/torch.get_deterministic_debug_mode.rst", "generated/torch.get_device_module.rst", "generated/torch.get_float32_matmul_precision.rst", "generated/torch.get_num_interop_threads.rst", "generated/torch.get_num_threads.rst", "generated/torch.get_rng_state.rst", "generated/torch.gradient.rst", "generated/torch.greater.rst", "generated/torch.greater_equal.rst", "generated/torch.gt.rst", "generated/torch.hamming_window.rst", "generated/torch.hann_window.rst", "generated/torch.heaviside.rst", "generated/torch.histc.rst", "generated/torch.histogram.rst", "generated/torch.histogramdd.rst", "generated/torch.hsplit.rst", "generated/torch.hstack.rst", "generated/torch.hypot.rst", "generated/torch.i0.rst", "generated/torch.igamma.rst", "generated/torch.igammac.rst", "generated/torch.imag.rst", "generated/torch.index_add.rst", "generated/torch.index_copy.rst", "generated/torch.index_reduce.rst", "generated/torch.index_select.rst", "generated/torch.initial_seed.rst", "generated/torch.inner.rst", "generated/torch.inverse.rst", "generated/torch.is_complex.rst", "generated/torch.is_conj.rst", "generated/torch.is_deterministic_algorithms_warn_only_enabled.rst", "generated/torch.is_floating_point.rst", "generated/torch.is_grad_enabled.rst", "generated/torch.is_inference_mode_enabled.rst", "generated/torch.is_nonzero.rst", "generated/torch.is_storage.rst", "generated/torch.is_tensor.rst", "generated/torch.is_warn_always_enabled.rst", "generated/torch.isclose.rst", "generated/torch.isfinite.rst", "generated/torch.isin.rst", "generated/torch.isinf.rst", "generated/torch.isnan.rst", "generated/torch.isneginf.rst", "generated/torch.isposinf.rst", "generated/torch.isreal.rst", "generated/torch.istft.rst", "generated/torch.kaiser_window.rst", "generated/torch.kron.rst", "generated/torch.kthvalue.rst", "generated/torch.lcm.rst", "generated/torch.ldexp.rst", "generated/torch.le.rst", "generated/torch.lerp.rst", "generated/torch.less.rst", "generated/torch.less_equal.rst", "generated/torch.lgamma.rst", "generated/torch.linspace.rst", "generated/torch.load.rst", "generated/torch.lobpcg.rst", "generated/torch.log.rst", "generated/torch.log10.rst", "generated/torch.log1p.rst", "generated/torch.log2.rst", "generated/torch.logaddexp.rst", "generated/torch.logaddexp2.rst", "generated/torch.logcumsumexp.rst", "generated/torch.logdet.rst", "generated/torch.logical_and.rst", "generated/torch.logical_not.rst", "generated/torch.logical_or.rst", "generated/torch.logical_xor.rst", "generated/torch.logit.rst", "generated/torch.logspace.rst", "generated/torch.logsumexp.rst", "generated/torch.lt.rst", "generated/torch.lu.rst", "generated/torch.lu_solve.rst", "generated/torch.lu_unpack.rst", "generated/torch.manual_seed.rst", "generated/torch.masked_select.rst", "generated/torch.matmul.rst", "generated/torch.matrix_exp.rst", "generated/torch.matrix_power.rst", "generated/torch.max.rst", "generated/torch.maximum.rst", "generated/torch.mean.rst", "generated/torch.median.rst", "generated/torch.meshgrid.rst", "generated/torch.min.rst", "generated/torch.minimum.rst", "generated/torch.mm.rst", "generated/torch.mode.rst", "generated/torch.moveaxis.rst", "generated/torch.movedim.rst", "generated/torch.msort.rst", "generated/torch.mul.rst", "generated/torch.multinomial.rst", "generated/torch.multiply.rst", "generated/torch.mv.rst", "generated/torch.mvlgamma.rst", "generated/torch.nan_to_num.rst", "generated/torch.nanmean.rst", "generated/torch.nanmedian.rst", "generated/torch.nanquantile.rst", "generated/torch.nansum.rst", "generated/torch.narrow.rst", "generated/torch.narrow_copy.rst", "generated/torch.ne.rst", "generated/torch.neg.rst", "generated/torch.negative.rst", "generated/torch.nextafter.rst", "generated/torch.nn.AdaptiveAvgPool1d.rst", "generated/torch.nn.AdaptiveAvgPool2d.rst", "generated/torch.nn.AdaptiveAvgPool3d.rst", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss.rst", "generated/torch.nn.AdaptiveMaxPool1d.rst", "generated/torch.nn.AdaptiveMaxPool2d.rst", "generated/torch.nn.AdaptiveMaxPool3d.rst", "generated/torch.nn.AlphaDropout.rst", "generated/torch.nn.AvgPool1d.rst", "generated/torch.nn.AvgPool2d.rst", "generated/torch.nn.AvgPool3d.rst", "generated/torch.nn.BCELoss.rst", "generated/torch.nn.BCEWithLogitsLoss.rst", "generated/torch.nn.BatchNorm1d.rst", "generated/torch.nn.BatchNorm2d.rst", "generated/torch.nn.BatchNorm3d.rst", "generated/torch.nn.Bilinear.rst", "generated/torch.nn.CELU.rst", "generated/torch.nn.CTCLoss.rst", "generated/torch.nn.ChannelShuffle.rst", "generated/torch.nn.CircularPad1d.rst", "generated/torch.nn.CircularPad2d.rst", "generated/torch.nn.CircularPad3d.rst", "generated/torch.nn.ConstantPad1d.rst", "generated/torch.nn.ConstantPad2d.rst", "generated/torch.nn.ConstantPad3d.rst", "generated/torch.nn.Conv1d.rst", "generated/torch.nn.Conv2d.rst", "generated/torch.nn.Conv3d.rst", "generated/torch.nn.ConvTranspose1d.rst", "generated/torch.nn.ConvTranspose2d.rst", "generated/torch.nn.ConvTranspose3d.rst", "generated/torch.nn.CosineEmbeddingLoss.rst", "generated/torch.nn.CosineSimilarity.rst", "generated/torch.nn.CrossEntropyLoss.rst", "generated/torch.nn.DataParallel.rst", "generated/torch.nn.Dropout.rst", "generated/torch.nn.Dropout1d.rst", "generated/torch.nn.Dropout2d.rst", "generated/torch.nn.Dropout3d.rst", "generated/torch.nn.ELU.rst", "generated/torch.nn.Embedding.rst", "generated/torch.nn.EmbeddingBag.rst", "generated/torch.nn.FeatureAlphaDropout.rst", "generated/torch.nn.Flatten.rst", "generated/torch.nn.Fold.rst", "generated/torch.nn.FractionalMaxPool2d.rst", "generated/torch.nn.FractionalMaxPool3d.rst", "generated/torch.nn.GELU.rst", "generated/torch.nn.GLU.rst", "generated/torch.nn.GRU.rst", "generated/torch.nn.GRUCell.rst", "generated/torch.nn.GaussianNLLLoss.rst", "generated/torch.nn.GroupNorm.rst", "generated/torch.nn.Hardshrink.rst", "generated/torch.nn.Hardsigmoid.rst", "generated/torch.nn.Hardswish.rst", "generated/torch.nn.Hardtanh.rst", "generated/torch.nn.HingeEmbeddingLoss.rst", "generated/torch.nn.HuberLoss.rst", "generated/torch.nn.Identity.rst", "generated/torch.nn.InstanceNorm1d.rst", "generated/torch.nn.InstanceNorm2d.rst", "generated/torch.nn.InstanceNorm3d.rst", "generated/torch.nn.KLDivLoss.rst", "generated/torch.nn.L1Loss.rst", "generated/torch.nn.LPPool1d.rst", "generated/torch.nn.LPPool2d.rst", "generated/torch.nn.LPPool3d.rst", "generated/torch.nn.LSTM.rst", "generated/torch.nn.LSTMCell.rst", "generated/torch.nn.LayerNorm.rst", "generated/torch.nn.LazyBatchNorm1d.rst", "generated/torch.nn.LazyBatchNorm2d.rst", "generated/torch.nn.LazyBatchNorm3d.rst", "generated/torch.nn.LazyConv1d.rst", "generated/torch.nn.LazyConv2d.rst", "generated/torch.nn.LazyConv3d.rst", "generated/torch.nn.LazyConvTranspose1d.rst", "generated/torch.nn.LazyConvTranspose2d.rst", "generated/torch.nn.LazyConvTranspose3d.rst", "generated/torch.nn.LazyInstanceNorm1d.rst", "generated/torch.nn.LazyInstanceNorm2d.rst", "generated/torch.nn.LazyInstanceNorm3d.rst", "generated/torch.nn.LazyLinear.rst", "generated/torch.nn.LeakyReLU.rst", "generated/torch.nn.Linear.rst", "generated/torch.nn.LocalResponseNorm.rst", "generated/torch.nn.LogSigmoid.rst", "generated/torch.nn.LogSoftmax.rst", "generated/torch.nn.MSELoss.rst", "generated/torch.nn.MarginRankingLoss.rst", "generated/torch.nn.MaxPool1d.rst", "generated/torch.nn.MaxPool2d.rst", "generated/torch.nn.MaxPool3d.rst", "generated/torch.nn.MaxUnpool1d.rst", "generated/torch.nn.MaxUnpool2d.rst", "generated/torch.nn.MaxUnpool3d.rst", "generated/torch.nn.Mish.rst", "generated/torch.nn.Module.rst", "generated/torch.nn.ModuleDict.rst", "generated/torch.nn.ModuleList.rst", "generated/torch.nn.MultiLabelMarginLoss.rst", "generated/torch.nn.MultiLabelSoftMarginLoss.rst", "generated/torch.nn.MultiMarginLoss.rst", "generated/torch.nn.MultiheadAttention.rst", "generated/torch.nn.NLLLoss.rst", "generated/torch.nn.PReLU.rst", "generated/torch.nn.PairwiseDistance.rst", "generated/torch.nn.ParameterDict.rst", "generated/torch.nn.ParameterList.rst", "generated/torch.nn.PixelShuffle.rst", "generated/torch.nn.PixelUnshuffle.rst", "generated/torch.nn.PoissonNLLLoss.rst", "generated/torch.nn.RMSNorm.rst", "generated/torch.nn.RNN.rst", "generated/torch.nn.RNNBase.rst", "generated/torch.nn.RNNCell.rst", "generated/torch.nn.RReLU.rst", "generated/torch.nn.ReLU.rst", "generated/torch.nn.ReLU6.rst", "generated/torch.nn.ReflectionPad1d.rst", "generated/torch.nn.ReflectionPad2d.rst", "generated/torch.nn.ReflectionPad3d.rst", "generated/torch.nn.ReplicationPad1d.rst", "generated/torch.nn.ReplicationPad2d.rst", "generated/torch.nn.ReplicationPad3d.rst", "generated/torch.nn.SELU.rst", "generated/torch.nn.Sequential.rst", "generated/torch.nn.SiLU.rst", "generated/torch.nn.Sigmoid.rst", "generated/torch.nn.SmoothL1Loss.rst", "generated/torch.nn.SoftMarginLoss.rst", "generated/torch.nn.Softmax.rst", "generated/torch.nn.Softmax2d.rst", "generated/torch.nn.Softmin.rst", "generated/torch.nn.Softplus.rst", "generated/torch.nn.Softshrink.rst", "generated/torch.nn.Softsign.rst", "generated/torch.nn.SyncBatchNorm.rst", "generated/torch.nn.Tanh.rst", "generated/torch.nn.Tanhshrink.rst", "generated/torch.nn.Threshold.rst", "generated/torch.nn.Transformer.rst", "generated/torch.nn.TransformerDecoder.rst", "generated/torch.nn.TransformerDecoderLayer.rst", "generated/torch.nn.TransformerEncoder.rst", "generated/torch.nn.TransformerEncoderLayer.rst", "generated/torch.nn.TripletMarginLoss.rst", "generated/torch.nn.TripletMarginWithDistanceLoss.rst", "generated/torch.nn.Unflatten.rst", "generated/torch.nn.Unfold.rst", "generated/torch.nn.Upsample.rst", "generated/torch.nn.UpsamplingBilinear2d.rst", "generated/torch.nn.UpsamplingNearest2d.rst", "generated/torch.nn.ZeroPad1d.rst", "generated/torch.nn.ZeroPad2d.rst", "generated/torch.nn.ZeroPad3d.rst", "generated/torch.nn.modules.lazy.LazyModuleMixin.rst", "generated/torch.nn.modules.module.register_module_backward_hook.rst", "generated/torch.nn.modules.module.register_module_buffer_registration_hook.rst", "generated/torch.nn.modules.module.register_module_forward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_module_registration_hook.rst", "generated/torch.nn.modules.module.register_module_parameter_registration_hook.rst", "generated/torch.nn.modules.normalization.RMSNorm.rst", "generated/torch.nn.parallel.DistributedDataParallel.rst", "generated/torch.nn.parameter.Buffer.rst", "generated/torch.nn.parameter.Parameter.rst", "generated/torch.nn.parameter.UninitializedBuffer.rst", "generated/torch.nn.parameter.UninitializedParameter.rst", "generated/torch.nn.utils.clip_grad_norm.rst", "generated/torch.nn.utils.clip_grad_norm_.rst", "generated/torch.nn.utils.clip_grad_value_.rst", "generated/torch.nn.utils.convert_conv2d_weight_memory_format.rst", "generated/torch.nn.utils.convert_conv3d_weight_memory_format.rst", "generated/torch.nn.utils.fuse_conv_bn_eval.rst", "generated/torch.nn.utils.fuse_conv_bn_weights.rst", "generated/torch.nn.utils.fuse_linear_bn_eval.rst", "generated/torch.nn.utils.fuse_linear_bn_weights.rst", "generated/torch.nn.utils.parameters_to_vector.rst", "generated/torch.nn.utils.parametrizations.orthogonal.rst", "generated/torch.nn.utils.parametrizations.spectral_norm.rst", "generated/torch.nn.utils.parametrizations.weight_norm.rst", "generated/torch.nn.utils.parametrize.ParametrizationList.rst", "generated/torch.nn.utils.parametrize.cached.rst", "generated/torch.nn.utils.parametrize.is_parametrized.rst", "generated/torch.nn.utils.parametrize.register_parametrization.rst", "generated/torch.nn.utils.parametrize.remove_parametrizations.rst", "generated/torch.nn.utils.prune.BasePruningMethod.rst", "generated/torch.nn.utils.prune.CustomFromMask.rst", "generated/torch.nn.utils.prune.Identity.rst", "generated/torch.nn.utils.prune.L1Unstructured.rst", "generated/torch.nn.utils.prune.LnStructured.rst", "generated/torch.nn.utils.prune.PruningContainer.rst", "generated/torch.nn.utils.prune.RandomStructured.rst", "generated/torch.nn.utils.prune.RandomUnstructured.rst", "generated/torch.nn.utils.prune.custom_from_mask.rst", "generated/torch.nn.utils.prune.global_unstructured.rst", "generated/torch.nn.utils.prune.identity.rst", "generated/torch.nn.utils.prune.is_pruned.rst", "generated/torch.nn.utils.prune.l1_unstructured.rst", "generated/torch.nn.utils.prune.ln_structured.rst", "generated/torch.nn.utils.prune.random_structured.rst", "generated/torch.nn.utils.prune.random_unstructured.rst", "generated/torch.nn.utils.prune.remove.rst", "generated/torch.nn.utils.remove_spectral_norm.rst", "generated/torch.nn.utils.remove_weight_norm.rst", "generated/torch.nn.utils.rnn.PackedSequence.rst", "generated/torch.nn.utils.rnn.pack_padded_sequence.rst", "generated/torch.nn.utils.rnn.pack_sequence.rst", "generated/torch.nn.utils.rnn.pad_packed_sequence.rst", "generated/torch.nn.utils.rnn.pad_sequence.rst", "generated/torch.nn.utils.rnn.unpack_sequence.rst", "generated/torch.nn.utils.rnn.unpad_sequence.rst", "generated/torch.nn.utils.skip_init.rst", "generated/torch.nn.utils.spectral_norm.rst", "generated/torch.nn.utils.stateless.functional_call.rst", "generated/torch.nn.utils.vector_to_parameters.rst", "generated/torch.nn.utils.weight_norm.rst", "generated/torch.no_grad.rst", "generated/torch.nonzero.rst", "generated/torch.norm.rst", "generated/torch.normal.rst", "generated/torch.not_equal.rst", "generated/torch.numel.rst", "generated/torch.ones.rst", "generated/torch.ones_like.rst", "generated/torch.orgqr.rst", "generated/torch.ormqr.rst", "generated/torch.outer.rst", "generated/torch.pca_lowrank.rst", "generated/torch.permute.rst", "generated/torch.pinverse.rst", "generated/torch.poisson.rst", "generated/torch.polar.rst", "generated/torch.polygamma.rst", "generated/torch.positive.rst", "generated/torch.pow.rst", "generated/torch.prod.rst", "generated/torch.promote_types.rst", "generated/torch.qr.rst", "generated/torch.quantile.rst", "generated/torch.quantize_per_channel.rst", "generated/torch.quantize_per_tensor.rst", "generated/torch.quantized_batch_norm.rst", "generated/torch.quantized_max_pool1d.rst", "generated/torch.quantized_max_pool2d.rst", "generated/torch.quasirandom.SobolEngine.rst", "generated/torch.rad2deg.rst", "generated/torch.rand.rst", "generated/torch.rand_like.rst", "generated/torch.randint.rst", "generated/torch.randint_like.rst", "generated/torch.randn.rst", "generated/torch.randn_like.rst", "generated/torch.randperm.rst", "generated/torch.range.rst", "generated/torch.ravel.rst", "generated/torch.real.rst", "generated/torch.reciprocal.rst", "generated/torch.remainder.rst", "generated/torch.renorm.rst", "generated/torch.repeat_interleave.rst", "generated/torch.reshape.rst", "generated/torch.resolve_conj.rst", "generated/torch.resolve_neg.rst", "generated/torch.result_type.rst", "generated/torch.roll.rst", "generated/torch.rot90.rst", "generated/torch.round.rst", "generated/torch.row_stack.rst", "generated/torch.rsqrt.rst", "generated/torch.save.rst", "generated/torch.scatter.rst", "generated/torch.scatter_add.rst", "generated/torch.scatter_reduce.rst", "generated/torch.searchsorted.rst", "generated/torch.seed.rst", "generated/torch.select.rst", "generated/torch.select_scatter.rst", "generated/torch.set_default_device.rst", "generated/torch.set_default_dtype.rst", "generated/torch.set_default_tensor_type.rst", "generated/torch.set_deterministic_debug_mode.rst", "generated/torch.set_float32_matmul_precision.rst", "generated/torch.set_flush_denormal.rst", "generated/torch.set_num_interop_threads.rst", "generated/torch.set_num_threads.rst", "generated/torch.set_printoptions.rst", "generated/torch.set_rng_state.rst", "generated/torch.set_warn_always.rst", "generated/torch.sgn.rst", "generated/torch.sigmoid.rst", "generated/torch.sign.rst", "generated/torch.signbit.rst", "generated/torch.sin.rst", "generated/torch.sinc.rst", "generated/torch.sinh.rst", "generated/torch.slice_scatter.rst", "generated/torch.slogdet.rst", "generated/torch.softmax.rst", "generated/torch.sort.rst", "generated/torch.sparse_bsc_tensor.rst", "generated/torch.sparse_bsr_tensor.rst", "generated/torch.sparse_coo_tensor.rst", "generated/torch.sparse_csc_tensor.rst", "generated/torch.sparse_csr_tensor.rst", "generated/torch.split.rst", "generated/torch.sqrt.rst", "generated/torch.square.rst", "generated/torch.squeeze.rst", "generated/torch.stack.rst", "generated/torch.std.rst", "generated/torch.std_mean.rst", "generated/torch.stft.rst", "generated/torch.sub.rst", "generated/torch.subtract.rst", "generated/torch.sum.rst", "generated/torch.svd.rst", "generated/torch.svd_lowrank.rst", "generated/torch.swapaxes.rst", "generated/torch.swapdims.rst", "generated/torch.sym_float.rst", "generated/torch.sym_int.rst", "generated/torch.sym_ite.rst", "generated/torch.sym_max.rst", "generated/torch.sym_min.rst", "generated/torch.sym_not.rst", "generated/torch.t.rst", "generated/torch.take.rst", "generated/torch.take_along_dim.rst", "generated/torch.tan.rst", "generated/torch.tanh.rst", "generated/torch.tensor.rst", "generated/torch.tensor_split.rst", "generated/torch.tensordot.rst", "generated/torch.tile.rst", "generated/torch.topk.rst", "generated/torch.trace.rst", "generated/torch.transpose.rst", "generated/torch.trapezoid.rst", "generated/torch.trapz.rst", "generated/torch.triangular_solve.rst", "generated/torch.tril.rst", "generated/torch.tril_indices.rst", "generated/torch.triu.rst", "generated/torch.triu_indices.rst", "generated/torch.true_divide.rst", "generated/torch.trunc.rst", "generated/torch.unbind.rst", "generated/torch.unflatten.rst", "generated/torch.unique.rst", "generated/torch.unique_consecutive.rst", "generated/torch.unravel_index.rst", "generated/torch.unsqueeze.rst", "generated/torch.use_deterministic_algorithms.rst", "generated/torch.vander.rst", "generated/torch.var.rst", "generated/torch.var_mean.rst", "generated/torch.vdot.rst", "generated/torch.view_as_complex.rst", "generated/torch.view_as_real.rst", "generated/torch.vmap.rst", "generated/torch.vsplit.rst", "generated/torch.vstack.rst", "generated/torch.where.rst", "generated/torch.xlogy.rst", "generated/torch.zeros.rst", "generated/torch.zeros_like.rst", "index.rst", "intro/subintro-page.rst", "intro/subintro/page1.rst", "intro/subintro/page2.rst", "intro/test1.rst", "intro/test2.rst", "nn.rst", "page1.rst", "page2.rst", "page3.md", "tensor_attributes.rst", "torch.rst", "tutorials.rst", "tutorials/tutorial1.rst", "tutorials/tutorial2.rst"], "indexentries": {"_assert() (in module torch)": [[4, "torch._assert", false]], "_foreach_abs() (in module torch)": [[5, "torch._foreach_abs", false]], "_foreach_abs_() (in module torch)": [[6, "torch._foreach_abs_", false]], "_foreach_acos() (in module torch)": [[7, "torch._foreach_acos", false]], "_foreach_acos_() (in module torch)": [[8, "torch._foreach_acos_", false]], "_foreach_asin() (in module torch)": [[9, "torch._foreach_asin", false]], "_foreach_asin_() (in module torch)": [[10, "torch._foreach_asin_", false]], "_foreach_atan() (in module torch)": [[11, "torch._foreach_atan", false]], "_foreach_atan_() (in module torch)": [[12, "torch._foreach_atan_", false]], "_foreach_ceil() (in module torch)": [[13, "torch._foreach_ceil", false]], "_foreach_ceil_() (in module torch)": [[14, "torch._foreach_ceil_", false]], "_foreach_cos() (in module torch)": [[15, "torch._foreach_cos", false]], "_foreach_cos_() (in module torch)": [[16, "torch._foreach_cos_", false]], "_foreach_cosh() (in module torch)": [[17, "torch._foreach_cosh", false]], "_foreach_cosh_() (in module torch)": [[18, "torch._foreach_cosh_", false]], "_foreach_erf() (in module torch)": [[19, "torch._foreach_erf", false]], "_foreach_erf_() (in module torch)": [[20, "torch._foreach_erf_", false]], "_foreach_erfc() (in module torch)": [[21, "torch._foreach_erfc", false]], "_foreach_erfc_() (in module torch)": [[22, "torch._foreach_erfc_", false]], "_foreach_exp() (in module torch)": [[23, "torch._foreach_exp", false]], "_foreach_exp_() (in module torch)": [[24, "torch._foreach_exp_", false]], "_foreach_expm1() (in module torch)": [[25, "torch._foreach_expm1", false]], "_foreach_expm1_() (in module torch)": [[26, "torch._foreach_expm1_", false]], "_foreach_floor() (in module torch)": [[27, "torch._foreach_floor", false]], "_foreach_floor_() (in module torch)": [[28, "torch._foreach_floor_", false]], "_foreach_frac() (in module torch)": [[29, "torch._foreach_frac", false]], "_foreach_frac_() (in module torch)": [[30, "torch._foreach_frac_", false]], "_foreach_lgamma() (in module torch)": [[31, "torch._foreach_lgamma", false]], "_foreach_lgamma_() (in module torch)": [[32, "torch._foreach_lgamma_", false]], "_foreach_log() (in module torch)": [[33, "torch._foreach_log", false]], "_foreach_log10() (in module torch)": [[34, "torch._foreach_log10", false]], "_foreach_log10_() (in module torch)": [[35, "torch._foreach_log10_", false]], "_foreach_log1p() (in module torch)": [[36, "torch._foreach_log1p", false]], "_foreach_log1p_() (in module torch)": [[37, "torch._foreach_log1p_", false]], "_foreach_log2() (in module torch)": [[38, "torch._foreach_log2", false]], "_foreach_log2_() (in module torch)": [[39, "torch._foreach_log2_", false]], "_foreach_log_() (in module torch)": [[40, "torch._foreach_log_", false]], "_foreach_neg() (in module torch)": [[41, "torch._foreach_neg", false]], "_foreach_neg_() (in module torch)": [[42, "torch._foreach_neg_", false]], "_foreach_reciprocal() (in module torch)": [[43, "torch._foreach_reciprocal", false]], "_foreach_reciprocal_() (in module torch)": [[44, "torch._foreach_reciprocal_", false]], "_foreach_round() (in module torch)": [[45, "torch._foreach_round", false]], "_foreach_round_() (in module torch)": [[46, "torch._foreach_round_", false]], "_foreach_sigmoid() (in module torch)": [[47, "torch._foreach_sigmoid", false]], "_foreach_sigmoid_() (in module torch)": [[48, "torch._foreach_sigmoid_", false]], "_foreach_sin() (in module torch)": [[49, "torch._foreach_sin", false]], "_foreach_sin_() (in module torch)": [[50, "torch._foreach_sin_", false]], "_foreach_sinh() (in module torch)": [[51, "torch._foreach_sinh", false]], "_foreach_sinh_() (in module torch)": [[52, "torch._foreach_sinh_", false]], "_foreach_sqrt() (in module torch)": [[53, "torch._foreach_sqrt", false]], "_foreach_sqrt_() (in module torch)": [[54, "torch._foreach_sqrt_", false]], "_foreach_tan() (in module torch)": [[55, "torch._foreach_tan", false]], "_foreach_tan_() (in module torch)": [[56, "torch._foreach_tan_", false]], "_foreach_trunc() (in module torch)": [[57, "torch._foreach_trunc", false]], "_foreach_trunc_() (in module torch)": [[58, "torch._foreach_trunc_", false]], "_foreach_zero_() (in module torch)": [[59, "torch._foreach_zero_", false]], "abs() (in module torch)": [[60, "torch.abs", false]], "absolute() (in module torch)": [[61, "torch.absolute", false]], "acos() (in module torch)": [[62, "torch.acos", false]], "acosh() (in module torch)": [[63, "torch.acosh", false]], "adaptiveavgpool1d() (in module torch.nn)": [[329, "torch.nn.AdaptiveAvgPool1d", false]], "adaptiveavgpool2d() (in module torch.nn)": [[330, "torch.nn.AdaptiveAvgPool2d", false]], "adaptiveavgpool3d() (in module torch.nn)": [[331, "torch.nn.AdaptiveAvgPool3d", false]], "adaptivelogsoftmaxwithloss() (in module torch.nn)": [[332, "torch.nn.AdaptiveLogSoftmaxWithLoss", false]], "adaptivemaxpool1d() (in module torch.nn)": [[333, "torch.nn.AdaptiveMaxPool1d", false]], "adaptivemaxpool2d() (in module torch.nn)": [[334, "torch.nn.AdaptiveMaxPool2d", false]], "adaptivemaxpool3d() (in module torch.nn)": [[335, "torch.nn.AdaptiveMaxPool3d", false]], "add() (in module torch)": [[64, "torch.add", false]], "add_pruning_method() (torch.nn.utils.prune.pruningcontainer method)": [[525, "torch.nn.utils.prune.PruningContainer.add_pruning_method", false]], "addbmm() (in module torch)": [[65, "torch.addbmm", false]], "addcdiv() (in module torch)": [[66, "torch.addcdiv", false]], "addcmul() (in module torch)": [[67, "torch.addcmul", false]], "addmm() (in module torch)": [[68, "torch.addmm", false]], "addmv() (in module torch)": [[69, "torch.addmv", false]], "addr() (in module torch)": [[70, "torch.addr", false]], "adjoint() (in module torch)": [[71, "torch.adjoint", false]], "all() (in module torch)": [[72, "torch.all", false]], "allclose() (in module torch)": [[73, "torch.allclose", false]], "alphadropout() (in module torch.nn)": [[336, "torch.nn.AlphaDropout", false]], "amax() (in module torch)": [[74, "torch.amax", false]], "amin() (in module torch)": [[75, "torch.amin", false]], "aminmax() (in module torch)": [[76, "torch.aminmax", false]], "angle() (in module torch)": [[77, "torch.angle", false]], "any() (in module torch)": [[78, "torch.any", false]], "apply() (torch.nn.utils.prune.basepruningmethod class method)": [[520, "torch.nn.utils.prune.BasePruningMethod.apply", false]], "apply() (torch.nn.utils.prune.customfrommask class method)": [[521, "torch.nn.utils.prune.CustomFromMask.apply", false]], "apply() (torch.nn.utils.prune.identity class method)": [[522, "torch.nn.utils.prune.Identity.apply", false]], "apply() (torch.nn.utils.prune.l1unstructured class method)": [[523, "torch.nn.utils.prune.L1Unstructured.apply", false]], "apply() (torch.nn.utils.prune.lnstructured class method)": [[524, "torch.nn.utils.prune.LnStructured.apply", false]], "apply() (torch.nn.utils.prune.pruningcontainer class method)": [[525, "torch.nn.utils.prune.PruningContainer.apply", false]], "apply() (torch.nn.utils.prune.randomstructured class method)": [[526, "torch.nn.utils.prune.RandomStructured.apply", false]], "apply() (torch.nn.utils.prune.randomunstructured class method)": [[527, "torch.nn.utils.prune.RandomUnstructured.apply", false]], "apply_mask() (torch.nn.utils.prune.basepruningmethod method)": [[520, "torch.nn.utils.prune.BasePruningMethod.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.customfrommask method)": [[521, "torch.nn.utils.prune.CustomFromMask.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.identity method)": [[522, "torch.nn.utils.prune.Identity.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.l1unstructured method)": [[523, "torch.nn.utils.prune.L1Unstructured.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.lnstructured method)": [[524, "torch.nn.utils.prune.LnStructured.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.pruningcontainer method)": [[525, "torch.nn.utils.prune.PruningContainer.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.randomstructured method)": [[526, "torch.nn.utils.prune.RandomStructured.apply_mask", false]], "apply_mask() (torch.nn.utils.prune.randomunstructured method)": [[527, "torch.nn.utils.prune.RandomUnstructured.apply_mask", false]], "arange() (in module torch)": [[79, "torch.arange", false]], "arccos() (in module torch)": [[80, "torch.arccos", false]], "arccosh() (in module torch)": [[81, "torch.arccosh", false]], "arcsin() (in module torch)": [[82, "torch.arcsin", false]], "arcsinh() (in module torch)": [[83, "torch.arcsinh", false]], "arctan() (in module torch)": [[84, "torch.arctan", false]], "arctan2() (in module torch)": [[85, "torch.arctan2", false]], "arctanh() (in module torch)": [[86, "torch.arctanh", false]], "are_deterministic_algorithms_enabled() (in module torch)": [[87, "torch.are_deterministic_algorithms_enabled", false]], "argmax() (in module torch)": [[88, "torch.argmax", false]], "argmin() (in module torch)": [[89, "torch.argmin", false]], "argsort() (in module torch)": [[90, "torch.argsort", false]], "argwhere() (in module torch)": [[91, "torch.argwhere", false]], "as_integer_ratio() (torch.symfloat method)": [[712, "torch.SymFloat.as_integer_ratio", false]], "as_integer_ratio() (torch.symint method)": [[712, "torch.SymInt.as_integer_ratio", false]], "as_strided() (in module torch)": [[92, "torch.as_strided", false]], "as_tensor() (in module torch)": [[93, "torch.as_tensor", false]], "asarray() (in module torch)": [[94, "torch.asarray", false]], "asin() (in module torch)": [[95, "torch.asin", false]], "asinh() (in module torch)": [[96, "torch.asinh", false]], "atan() (in module torch)": [[97, "torch.atan", false]], "atan2() (in module torch)": [[98, "torch.atan2", false]], "atanh() (in module torch)": [[99, "torch.atanh", false]], "atleast_1d() (in module torch)": [[100, "torch.atleast_1d", false]], "atleast_2d() (in module torch)": [[101, "torch.atleast_2d", false]], "atleast_3d() (in module torch)": [[102, "torch.atleast_3d", false]], "avgpool1d() (in module torch.nn)": [[337, "torch.nn.AvgPool1d", false]], "avgpool2d() (in module torch.nn)": [[338, "torch.nn.AvgPool2d", false]], "avgpool3d() (in module torch.nn)": [[339, "torch.nn.AvgPool3d", false]], "baddbmm() (in module torch)": [[105, "torch.baddbmm", false]], "bartlett_window() (in module torch)": [[106, "torch.bartlett_window", false]], "basepruningmethod (class in torch.nn.utils.prune)": [[520, "torch.nn.utils.prune.BasePruningMethod", false]], "batch_sizes (torch.nn.utils.rnn.packedsequence attribute)": [[539, "id0", false], [539, "torch.nn.utils.rnn.PackedSequence.batch_sizes", false]], "batchnorm1d() (in module torch.nn)": [[342, "torch.nn.BatchNorm1d", false]], "batchnorm2d() (in module torch.nn)": [[343, "torch.nn.BatchNorm2d", false]], "batchnorm3d() (in module torch.nn)": [[344, "torch.nn.BatchNorm3d", false]], "bceloss() (in module torch.nn)": [[340, "torch.nn.BCELoss", false]], "bcewithlogitsloss() (in module torch.nn)": [[341, "torch.nn.BCEWithLogitsLoss", false]], "bernoulli() (in module torch)": [[107, "torch.bernoulli", false]], "bias (in module torch.nn)": [[345, "torch.nn.bias", false], [355, "torch.nn.bias", false], [356, "torch.nn.bias", false], [357, "torch.nn.bias", false], [358, "torch.nn.bias", false], [359, "torch.nn.bias", false], [360, "torch.nn.bias", false], [400, "torch.nn.bias", false], [413, "torch.nn.bias", false], [415, "torch.nn.bias", false]], "bias_hh (in module torch.nn)": [[380, "torch.nn.bias_hh", false], [399, "torch.nn.bias_hh", false], [446, "torch.nn.bias_hh", false]], "bias_hh_l (in module torch.nn)": [[379, "torch.nn.bias_hh_l", false], [398, "torch.nn.bias_hh_l", false], [444, "torch.nn.bias_hh_l", false]], "bias_ih (in module torch.nn)": [[380, "torch.nn.bias_ih", false], [399, "torch.nn.bias_ih", false], [446, "torch.nn.bias_ih", false]], "bias_ih_l (in module torch.nn)": [[379, "torch.nn.bias_ih_l", false], [398, "torch.nn.bias_ih_l", false], [444, "torch.nn.bias_ih_l", false]], "bilinear() (in module torch.nn)": [[345, "torch.nn.Bilinear", false]], "bincount() (in module torch)": [[108, "torch.bincount", false]], "bitwise_and() (in module torch)": [[109, "torch.bitwise_and", false]], "bitwise_left_shift() (in module torch)": [[110, "torch.bitwise_left_shift", false]], "bitwise_not() (in module torch)": [[111, "torch.bitwise_not", false]], "bitwise_or() (in module torch)": [[112, "torch.bitwise_or", false]], "bitwise_right_shift() (in module torch)": [[113, "torch.bitwise_right_shift", false]], "bitwise_xor() (in module torch)": [[114, "torch.bitwise_xor", false]], "blackman_window() (in module torch)": [[115, "torch.blackman_window", false]], "block_diag() (in module torch)": [[116, "torch.block_diag", false]], "bmm() (in module torch)": [[117, "torch.bmm", false]], "broadcast_shapes() (in module torch)": [[118, "torch.broadcast_shapes", false]], "broadcast_tensors() (in module torch)": [[119, "torch.broadcast_tensors", false]], "broadcast_to() (in module torch)": [[120, "torch.broadcast_to", false]], "bucketize() (in module torch)": [[121, "torch.bucketize", false]], "buffer() (in module torch.nn.parameter)": [[498, "torch.nn.parameter.Buffer", false]], "cached() (in module torch.nn.utils.parametrize)": [[516, "torch.nn.utils.parametrize.cached", false]], "can_cast() (in module torch)": [[122, "torch.can_cast", false]], "cartesian_prod() (in module torch)": [[123, "torch.cartesian_prod", false]], "cat() (in module torch)": [[124, "torch.cat", false]], "cdist() (in module torch)": [[125, "torch.cdist", false]], "ceil() (in module torch)": [[126, "torch.ceil", false]], "celu() (in module torch.nn)": [[346, "torch.nn.CELU", false]], "chain_matmul() (in module torch)": [[127, "torch.chain_matmul", false]], "channelshuffle() (in module torch.nn)": [[348, "torch.nn.ChannelShuffle", false]], "cholesky() (in module torch)": [[128, "torch.cholesky", false]], "cholesky_inverse() (in module torch)": [[129, "torch.cholesky_inverse", false]], "cholesky_solve() (in module torch)": [[130, "torch.cholesky_solve", false]], "chunk() (in module torch)": [[131, "torch.chunk", false]], "circularpad1d() (in module torch.nn)": [[349, "torch.nn.CircularPad1d", false]], "circularpad2d() (in module torch.nn)": [[350, "torch.nn.CircularPad2d", false]], "circularpad3d() (in module torch.nn)": [[351, "torch.nn.CircularPad3d", false]], "clamp() (in module torch)": [[132, "torch.clamp", false]], "clip() (in module torch)": [[133, "torch.clip", false]], "clip_grad_norm() (in module torch.nn.utils)": [[502, "torch.nn.utils.clip_grad_norm", false]], "clip_grad_norm_() (in module torch.nn.utils)": [[503, "torch.nn.utils.clip_grad_norm_", false]], "clip_grad_value_() (in module torch.nn.utils)": [[504, "torch.nn.utils.clip_grad_value_", false]], "clone() (in module torch)": [[134, "torch.clone", false]], "clone() (torch.autograd.grad_mode.inference_mode method)": [[103, "torch.autograd.grad_mode.inference_mode.clone", false]], "clone() (torch.autograd.grad_mode.set_grad_enabled method)": [[104, "torch.autograd.grad_mode.set_grad_enabled.clone", false]], "clone_state() (torch.generator method)": [[2, "torch.Generator.clone_state", false]], "column_stack() (in module torch)": [[135, "torch.column_stack", false]], "combinations() (in module torch)": [[136, "torch.combinations", false]], "compile() (in module torch)": [[137, "torch.compile", false]], "compiled_with_cxx11_abi() (in module torch)": [[138, "torch.compiled_with_cxx11_abi", false]], "complex() (in module torch)": [[139, "torch.complex", false]], "compute_mask() (torch.nn.utils.prune.basepruningmethod method)": [[520, "torch.nn.utils.prune.BasePruningMethod.compute_mask", false]], "compute_mask() (torch.nn.utils.prune.lnstructured method)": [[524, "torch.nn.utils.prune.LnStructured.compute_mask", false]], "compute_mask() (torch.nn.utils.prune.pruningcontainer method)": [[525, "torch.nn.utils.prune.PruningContainer.compute_mask", false]], "compute_mask() (torch.nn.utils.prune.randomstructured method)": [[526, "torch.nn.utils.prune.RandomStructured.compute_mask", false]], "concat() (in module torch)": [[140, "torch.concat", false]], "concatenate() (in module torch)": [[141, "torch.concatenate", false]], "cond() (in module torch)": [[142, "torch.cond", false]], "conj() (in module torch)": [[143, "torch.conj", false]], "conj_physical() (in module torch)": [[144, "torch.conj_physical", false]], "constantpad1d() (in module torch.nn)": [[352, "torch.nn.ConstantPad1d", false]], "constantpad2d() (in module torch.nn)": [[353, "torch.nn.ConstantPad2d", false]], "constantpad3d() (in module torch.nn)": [[354, "torch.nn.ConstantPad3d", false]], "conv1d() (in module torch.nn)": [[355, "torch.nn.Conv1d", false]], "conv2d() (in module torch.nn)": [[356, "torch.nn.Conv2d", false]], "conv3d() (in module torch.nn)": [[357, "torch.nn.Conv3d", false]], "convert_conv2d_weight_memory_format() (in module torch.nn.utils)": [[505, "torch.nn.utils.convert_conv2d_weight_memory_format", false]], "convert_conv3d_weight_memory_format() (in module torch.nn.utils)": [[506, "torch.nn.utils.convert_conv3d_weight_memory_format", false]], "convtranspose1d() (in module torch.nn)": [[358, "torch.nn.ConvTranspose1d", false]], "convtranspose2d() (in module torch.nn)": [[359, "torch.nn.ConvTranspose2d", false]], "convtranspose3d() (in module torch.nn)": [[360, "torch.nn.ConvTranspose3d", false]], "copysign() (in module torch)": [[145, "torch.copysign", false]], "corrcoef() (in module torch)": [[146, "torch.corrcoef", false]], "cos() (in module torch)": [[147, "torch.cos", false]], "cosh() (in module torch)": [[148, "torch.cosh", false]], "cosineembeddingloss() (in module torch.nn)": [[361, "torch.nn.CosineEmbeddingLoss", false]], "cosinesimilarity() (in module torch.nn)": [[362, "torch.nn.CosineSimilarity", false]], "count() (torch.nn.utils.rnn.packedsequence method)": [[539, "torch.nn.utils.rnn.PackedSequence.count", false]], "count_nonzero() (in module torch)": [[149, "torch.count_nonzero", false]], "cov() (in module torch)": [[150, "torch.cov", false]], "cross() (in module torch)": [[151, "torch.cross", false]], "crossentropyloss() (in module torch.nn)": [[363, "torch.nn.CrossEntropyLoss", false]], "ctcloss() (in module torch.nn)": [[347, "torch.nn.CTCLoss", false]], "cummax() (in module torch)": [[152, "torch.cummax", false]], "cummin() (in module torch)": [[153, "torch.cummin", false]], "cumprod() (in module torch)": [[154, "torch.cumprod", false]], "cumsum() (in module torch)": [[155, "torch.cumsum", false]], "cumulative_trapezoid() (in module torch)": [[156, "torch.cumulative_trapezoid", false]], "custom_from_mask() (in module torch.nn.utils.prune)": [[528, "torch.nn.utils.prune.custom_from_mask", false]], "customfrommask (class in torch.nn.utils.prune)": [[521, "torch.nn.utils.prune.CustomFromMask", false]], "data (torch.nn.utils.rnn.packedsequence attribute)": [[539, "id1", false], [539, "torch.nn.utils.rnn.PackedSequence.data", false]], "dataparallel() (in module torch.nn)": [[364, "torch.nn.DataParallel", false]], "default_generator (torch.torch attribute)": [[712, "torch.torch.default_generator", false]], "deg2rad() (in module torch)": [[157, "torch.deg2rad", false]], "dequantize() (in module torch)": [[158, "torch.dequantize", false]], "det() (in module torch)": [[159, "torch.det", false]], "device (class in torch)": [[711, "torch.device", false]], "device (torch.generator attribute)": [[2, "torch.Generator.device", false]], "diag() (in module torch)": [[160, "torch.diag", false]], "diag_embed() (in module torch)": [[161, "torch.diag_embed", false]], "diagflat() (in module torch)": [[162, "torch.diagflat", false]], "diagonal() (in module torch)": [[163, "torch.diagonal", false]], "diagonal_scatter() (in module torch)": [[164, "torch.diagonal_scatter", false]], "diff() (in module torch)": [[165, "torch.diff", false]], "digamma() (in module torch)": [[166, "torch.digamma", false]], "dist() (in module torch)": [[167, "torch.dist", false]], "distributeddataparallel() (in module torch.nn.parallel)": [[497, "torch.nn.parallel.DistributedDataParallel", false]], "div() (in module torch)": [[168, "torch.div", false]], "divide() (in module torch)": [[169, "torch.divide", false]], "dot() (in module torch)": [[170, "torch.dot", false]], "dropout() (in module torch.nn)": [[365, "torch.nn.Dropout", false]], "dropout1d() (in module torch.nn)": [[366, "torch.nn.Dropout1d", false]], "dropout2d() (in module torch.nn)": [[367, "torch.nn.Dropout2d", false]], "dropout3d() (in module torch.nn)": [[368, "torch.nn.Dropout3d", false]], "dsplit() (in module torch)": [[171, "torch.dsplit", false]], "dstack() (in module torch)": [[172, "torch.dstack", false]], "dtype (class in torch)": [[711, "torch.dtype", false]], "einsum() (in module torch)": [[173, "torch.einsum", false]], "elapsed_time() (torch.event method)": [[1, "torch.Event.elapsed_time", false]], "elu() (in module torch.nn)": [[369, "torch.nn.ELU", false]], "embedding() (in module torch.nn)": [[370, "torch.nn.Embedding", false]], "embeddingbag() (in module torch.nn)": [[371, "torch.nn.EmbeddingBag", false]], "empty() (in module torch)": [[174, "torch.empty", false]], "empty_like() (in module torch)": [[175, "torch.empty_like", false]], "empty_strided() (in module torch)": [[176, "torch.empty_strided", false]], "enable_grad (class in torch)": [[177, "torch.enable_grad", false]], "eq() (in module torch)": [[178, "torch.eq", false]], "equal() (in module torch)": [[179, "torch.equal", false]], "erf() (in module torch)": [[180, "torch.erf", false]], "erfc() (in module torch)": [[181, "torch.erfc", false]], "erfinv() (in module torch)": [[182, "torch.erfinv", false]], "event (class in torch)": [[1, "torch.Event", false]], "exp() (in module torch)": [[183, "torch.exp", false]], "exp2() (in module torch)": [[184, "torch.exp2", false]], "expm1() (in module torch)": [[185, "torch.expm1", false]], "eye() (in module torch)": [[186, "torch.eye", false]], "fake_quantize_per_channel_affine() (in module torch)": [[187, "torch.fake_quantize_per_channel_affine", false]], "fake_quantize_per_tensor_affine() (in module torch)": [[188, "torch.fake_quantize_per_tensor_affine", false]], "featurealphadropout() (in module torch.nn)": [[372, "torch.nn.FeatureAlphaDropout", false]], "fix() (in module torch)": [[189, "torch.fix", false]], "flatten() (in module torch)": [[190, "torch.flatten", false]], "flatten() (in module torch.nn)": [[373, "torch.nn.Flatten", false]], "flip() (in module torch)": [[191, "torch.flip", false]], "fliplr() (in module torch)": [[192, "torch.fliplr", false]], "flipud() (in module torch)": [[193, "torch.flipud", false]], "float_power() (in module torch)": [[194, "torch.float_power", false]], "floor() (in module torch)": [[195, "torch.floor", false]], "floor_divide() (in module torch)": [[196, "torch.floor_divide", false]], "fmax() (in module torch)": [[197, "torch.fmax", false]], "fmin() (in module torch)": [[198, "torch.fmin", false]], "fmod() (in module torch)": [[199, "torch.fmod", false]], "fold() (in module torch.nn)": [[374, "torch.nn.Fold", false]], "frac() (in module torch)": [[200, "torch.frac", false]], "fractionalmaxpool2d() (in module torch.nn)": [[375, "torch.nn.FractionalMaxPool2d", false]], "fractionalmaxpool3d() (in module torch.nn)": [[376, "torch.nn.FractionalMaxPool3d", false]], "frexp() (in module torch)": [[201, "torch.frexp", false]], "from_dlpack() (in module torch)": [[202, "torch.from_dlpack", false]], "from_file() (in module torch)": [[203, "torch.from_file", false]], "from_numpy() (in module torch)": [[204, "torch.from_numpy", false]], "frombuffer() (in module torch)": [[205, "torch.frombuffer", false]], "full() (in module torch)": [[206, "torch.full", false]], "full_like() (in module torch)": [[207, "torch.full_like", false]], "functional_call() (in module torch.nn.utils.stateless)": [[548, "torch.nn.utils.stateless.functional_call", false]], "fuse_conv_bn_eval() (in module torch.nn.utils)": [[507, "torch.nn.utils.fuse_conv_bn_eval", false]], "fuse_conv_bn_weights() (in module torch.nn.utils)": [[508, "torch.nn.utils.fuse_conv_bn_weights", false]], "fuse_linear_bn_eval() (in module torch.nn.utils)": [[509, "torch.nn.utils.fuse_linear_bn_eval", false]], "fuse_linear_bn_weights() (in module torch.nn.utils)": [[510, "torch.nn.utils.fuse_linear_bn_weights", false]], "gather() (in module torch)": [[208, "torch.gather", false]], "gaussiannllloss() (in module torch.nn)": [[381, "torch.nn.GaussianNLLLoss", false]], "gcd() (in module torch)": [[209, "torch.gcd", false]], "ge() (in module torch)": [[210, "torch.ge", false]], "gelu() (in module torch.nn)": [[377, "torch.nn.GELU", false]], "generator (class in torch)": [[2, "torch.Generator", false]], "geqrf() (in module torch)": [[211, "torch.geqrf", false]], "ger() (in module torch)": [[212, "torch.ger", false]], "get_default_device() (in module torch)": [[213, "torch.get_default_device", false]], "get_default_dtype() (in module torch)": [[214, "torch.get_default_dtype", false]], "get_deterministic_debug_mode() (in module torch)": [[215, "torch.get_deterministic_debug_mode", false]], "get_device_module() (in module torch)": [[216, "torch.get_device_module", false]], "get_float32_matmul_precision() (in module torch)": [[217, "torch.get_float32_matmul_precision", false]], "get_num_interop_threads() (in module torch)": [[218, "torch.get_num_interop_threads", false]], "get_num_threads() (in module torch)": [[219, "torch.get_num_threads", false]], "get_rng_state() (in module torch)": [[220, "torch.get_rng_state", false]], "get_state() (torch.generator method)": [[2, "torch.Generator.get_state", false]], "global_unstructured() (in module torch.nn.utils.prune)": [[529, "torch.nn.utils.prune.global_unstructured", false]], "glu() (in module torch.nn)": [[378, "torch.nn.GLU", false]], "gradient() (in module torch)": [[221, "torch.gradient", false]], "graphsafe_get_state() (torch.generator method)": [[2, "torch.Generator.graphsafe_get_state", false]], "graphsafe_set_state() (torch.generator method)": [[2, "torch.Generator.graphsafe_set_state", false]], "greater() (in module torch)": [[222, "torch.greater", false]], "greater_equal() (in module torch)": [[223, "torch.greater_equal", false]], "groupnorm() (in module torch.nn)": [[382, "torch.nn.GroupNorm", false]], "gru() (in module torch.nn)": [[379, "torch.nn.GRU", false]], "grucell() (in module torch.nn)": [[380, "torch.nn.GRUCell", false]], "gt() (in module torch)": [[224, "torch.gt", false]], "hamming_window() (in module torch)": [[225, "torch.hamming_window", false]], "hann_window() (in module torch)": [[226, "torch.hann_window", false]], "hardshrink() (in module torch.nn)": [[383, "torch.nn.Hardshrink", false]], "hardsigmoid() (in module torch.nn)": [[384, "torch.nn.Hardsigmoid", false]], "hardswish() (in module torch.nn)": [[385, "torch.nn.Hardswish", false]], "hardtanh() (in module torch.nn)": [[386, "torch.nn.Hardtanh", false]], "heaviside() (in module torch)": [[227, "torch.heaviside", false]], "hingeembeddingloss() (in module torch.nn)": [[387, "torch.nn.HingeEmbeddingLoss", false]], "histc() (in module torch)": [[228, "torch.histc", false]], "histogram() (in module torch)": [[229, "torch.histogram", false]], "histogramdd() (in module torch)": [[230, "torch.histogramdd", false]], "hsplit() (in module torch)": [[231, "torch.hsplit", false]], "hstack() (in module torch)": [[232, "torch.hstack", false]], "huberloss() (in module torch.nn)": [[388, "torch.nn.HuberLoss", false]], "hypot() (in module torch)": [[233, "torch.hypot", false]], "i0() (in module torch)": [[234, "torch.i0", false]], "identity (class in torch.nn.utils.prune)": [[522, "torch.nn.utils.prune.Identity", false]], "identity() (in module torch.nn)": [[389, "torch.nn.Identity", false]], "identity() (in module torch.nn.utils.prune)": [[530, "torch.nn.utils.prune.identity", false]], "igamma() (in module torch)": [[235, "torch.igamma", false]], "igammac() (in module torch)": [[236, "torch.igammac", false]], "imag() (in module torch)": [[237, "torch.imag", false]], "index() (torch.nn.utils.rnn.packedsequence method)": [[539, "torch.nn.utils.rnn.PackedSequence.index", false]], "index_add() (in module torch)": [[238, "torch.index_add", false]], "index_copy() (in module torch)": [[239, "torch.index_copy", false]], "index_reduce() (in module torch)": [[240, "torch.index_reduce", false]], "index_select() (in module torch)": [[241, "torch.index_select", false]], "inference_mode (class in torch.autograd.grad_mode)": [[103, "torch.autograd.grad_mode.inference_mode", false]], "initial_seed() (in module torch)": [[242, "torch.initial_seed", false]], "initial_seed() (torch.generator method)": [[2, "torch.Generator.initial_seed", false]], "inner() (in module torch)": [[243, "torch.inner", false]], "instancenorm1d() (in module torch.nn)": [[390, "torch.nn.InstanceNorm1d", false]], "instancenorm2d() (in module torch.nn)": [[391, "torch.nn.InstanceNorm2d", false]], "instancenorm3d() (in module torch.nn)": [[392, "torch.nn.InstanceNorm3d", false]], "inverse() (in module torch)": [[244, "torch.inverse", false]], "is_complex() (in module torch)": [[245, "torch.is_complex", false]], "is_conj() (in module torch)": [[246, "torch.is_conj", false]], "is_cuda (torch.nn.utils.rnn.packedsequence property)": [[539, "torch.nn.utils.rnn.PackedSequence.is_cuda", false]], "is_deterministic_algorithms_warn_only_enabled() (in module torch)": [[247, "torch.is_deterministic_algorithms_warn_only_enabled", false]], "is_floating_point() (in module torch)": [[248, "torch.is_floating_point", false]], "is_grad_enabled() (in module torch)": [[249, "torch.is_grad_enabled", false]], "is_inference_mode_enabled() (in module torch)": [[250, "torch.is_inference_mode_enabled", false]], "is_integer() (torch.symfloat method)": [[712, "torch.SymFloat.is_integer", false]], "is_nonzero() (in module torch)": [[251, "torch.is_nonzero", false]], "is_parametrized() (in module torch.nn.utils.parametrize)": [[517, "torch.nn.utils.parametrize.is_parametrized", false]], "is_pinned() (torch.nn.utils.rnn.packedsequence method)": [[539, "torch.nn.utils.rnn.PackedSequence.is_pinned", false]], "is_pruned() (in module torch.nn.utils.prune)": [[531, "torch.nn.utils.prune.is_pruned", false]], "is_storage() (in module torch)": [[252, "torch.is_storage", false]], "is_tensor() (in module torch)": [[253, "torch.is_tensor", false]], "is_warn_always_enabled() (in module torch)": [[254, "torch.is_warn_always_enabled", false]], "isclose() (in module torch)": [[255, "torch.isclose", false]], "isfinite() (in module torch)": [[256, "torch.isfinite", false]], "isin() (in module torch)": [[257, "torch.isin", false]], "isinf() (in module torch)": [[258, "torch.isinf", false]], "isnan() (in module torch)": [[259, "torch.isnan", false]], "isneginf() (in module torch)": [[260, "torch.isneginf", false]], "isposinf() (in module torch)": [[261, "torch.isposinf", false]], "isreal() (in module torch)": [[262, "torch.isreal", false]], "istft() (in module torch)": [[263, "torch.istft", false]], "kaiser_window() (in module torch)": [[264, "torch.kaiser_window", false]], "kldivloss() (in module torch.nn)": [[393, "torch.nn.KLDivLoss", false]], "kron() (in module torch)": [[265, "torch.kron", false]], "kthvalue() (in module torch)": [[266, "torch.kthvalue", false]], "l1_unstructured() (in module torch.nn.utils.prune)": [[532, "torch.nn.utils.prune.l1_unstructured", false]], "l1loss() (in module torch.nn)": [[394, "torch.nn.L1Loss", false]], "l1unstructured (class in torch.nn.utils.prune)": [[523, "torch.nn.utils.prune.L1Unstructured", false]], "layernorm() (in module torch.nn)": [[400, "torch.nn.LayerNorm", false]], "layout (class in torch)": [[711, "torch.layout", false]], "lazybatchnorm1d() (in module torch.nn)": [[401, "torch.nn.LazyBatchNorm1d", false]], "lazybatchnorm2d() (in module torch.nn)": [[402, "torch.nn.LazyBatchNorm2d", false]], "lazybatchnorm3d() (in module torch.nn)": [[403, "torch.nn.LazyBatchNorm3d", false]], "lazyconv1d() (in module torch.nn)": [[404, "torch.nn.LazyConv1d", false]], "lazyconv2d() (in module torch.nn)": [[405, "torch.nn.LazyConv2d", false]], "lazyconv3d() (in module torch.nn)": [[406, "torch.nn.LazyConv3d", false]], "lazyconvtranspose1d() (in module torch.nn)": [[407, "torch.nn.LazyConvTranspose1d", false]], "lazyconvtranspose2d() (in module torch.nn)": [[408, "torch.nn.LazyConvTranspose2d", false]], "lazyconvtranspose3d() (in module torch.nn)": [[409, "torch.nn.LazyConvTranspose3d", false]], "lazyinstancenorm1d() (in module torch.nn)": [[410, "torch.nn.LazyInstanceNorm1d", false]], "lazyinstancenorm2d() (in module torch.nn)": [[411, "torch.nn.LazyInstanceNorm2d", false]], "lazyinstancenorm3d() (in module torch.nn)": [[412, "torch.nn.LazyInstanceNorm3d", false]], "lazylinear() (in module torch.nn)": [[413, "torch.nn.LazyLinear", false]], "lazymodulemixin() (in module torch.nn.modules.lazy)": [[487, "torch.nn.modules.lazy.LazyModuleMixin", false]], "lcm() (in module torch)": [[267, "torch.lcm", false]], "ldexp() (in module torch)": [[268, "torch.ldexp", false]], "le() (in module torch)": [[269, "torch.le", false]], "leakyrelu() (in module torch.nn)": [[414, "torch.nn.LeakyReLU", false]], "lerp() (in module torch)": [[270, "torch.lerp", false]], "less() (in module torch)": [[271, "torch.less", false]], "less_equal() (in module torch)": [[272, "torch.less_equal", false]], "lgamma() (in module torch)": [[273, "torch.lgamma", false]], "linear() (in module torch.nn)": [[415, "torch.nn.Linear", false]], "linspace() (in module torch)": [[274, "torch.linspace", false]], "ln_structured() (in module torch.nn.utils.prune)": [[533, "torch.nn.utils.prune.ln_structured", false]], "lnstructured (class in torch.nn.utils.prune)": [[524, "torch.nn.utils.prune.LnStructured", false]], "load() (in module torch)": [[275, "torch.load", false]], "lobpcg() (in module torch)": [[276, "torch.lobpcg", false]], "localresponsenorm() (in module torch.nn)": [[416, "torch.nn.LocalResponseNorm", false]], "log() (in module torch)": [[277, "torch.log", false]], "log10() (in module torch)": [[278, "torch.log10", false]], "log1p() (in module torch)": [[279, "torch.log1p", false]], "log2() (in module torch)": [[280, "torch.log2", false]], "logaddexp() (in module torch)": [[281, "torch.logaddexp", false]], "logaddexp2() (in module torch)": [[282, "torch.logaddexp2", false]], "logcumsumexp() (in module torch)": [[283, "torch.logcumsumexp", false]], "logdet() (in module torch)": [[284, "torch.logdet", false]], "logical_and() (in module torch)": [[285, "torch.logical_and", false]], "logical_not() (in module torch)": [[286, "torch.logical_not", false]], "logical_or() (in module torch)": [[287, "torch.logical_or", false]], "logical_xor() (in module torch)": [[288, "torch.logical_xor", false]], "logit() (in module torch)": [[289, "torch.logit", false]], "logsigmoid() (in module torch.nn)": [[417, "torch.nn.LogSigmoid", false]], "logsoftmax() (in module torch.nn)": [[418, "torch.nn.LogSoftmax", false]], "logspace() (in module torch)": [[290, "torch.logspace", false]], "logsumexp() (in module torch)": [[291, "torch.logsumexp", false]], "lppool1d() (in module torch.nn)": [[395, "torch.nn.LPPool1d", false]], "lppool2d() (in module torch.nn)": [[396, "torch.nn.LPPool2d", false]], "lppool3d() (in module torch.nn)": [[397, "torch.nn.LPPool3d", false]], "lstm() (in module torch.nn)": [[398, "torch.nn.LSTM", false]], "lstmcell() (in module torch.nn)": [[399, "torch.nn.LSTMCell", false]], "lt() (in module torch)": [[292, "torch.lt", false]], "lu() (in module torch)": [[293, "torch.lu", false]], "lu_solve() (in module torch)": [[294, "torch.lu_solve", false]], "lu_unpack() (in module torch)": [[295, "torch.lu_unpack", false]], "manual_seed() (in module torch)": [[296, "torch.manual_seed", false]], "manual_seed() (torch.generator method)": [[2, "torch.Generator.manual_seed", false]], "marginrankingloss() (in module torch.nn)": [[420, "torch.nn.MarginRankingLoss", false]], "masked_select() (in module torch)": [[297, "torch.masked_select", false]], "matmul() (in module torch)": [[298, "torch.matmul", false]], "matrix_exp() (in module torch)": [[299, "torch.matrix_exp", false]], "matrix_power() (in module torch)": [[300, "torch.matrix_power", false]], "max() (in module torch)": [[301, "torch.max", false]], "maximum() (in module torch)": [[302, "torch.maximum", false]], "maxpool1d() (in module torch.nn)": [[421, "torch.nn.MaxPool1d", false]], "maxpool2d() (in module torch.nn)": [[422, "torch.nn.MaxPool2d", false]], "maxpool3d() (in module torch.nn)": [[423, "torch.nn.MaxPool3d", false]], "maxunpool1d() (in module torch.nn)": [[424, "torch.nn.MaxUnpool1d", false]], "maxunpool2d() (in module torch.nn)": [[425, "torch.nn.MaxUnpool2d", false]], "maxunpool3d() (in module torch.nn)": [[426, "torch.nn.MaxUnpool3d", false]], "mean() (in module torch)": [[303, "torch.mean", false]], "median() (in module torch)": [[304, "torch.median", false]], "memory_format (class in torch)": [[711, "torch.memory_format", false]], "meshgrid() (in module torch)": [[305, "torch.meshgrid", false]], "min() (in module torch)": [[306, "torch.min", false]], "minimum() (in module torch)": [[307, "torch.minimum", false]], "mish() (in module torch.nn)": [[427, "torch.nn.Mish", false]], "mm() (in module torch)": [[308, "torch.mm", false]], "mode() (in module torch)": [[309, "torch.mode", false]], "module": [[707, "module-torch.nn", false], [707, "module-torch.nn.backends", false], [707, "module-torch.nn.backends.thnn", false], [707, "module-torch.nn.common_types", false], [707, "module-torch.nn.cpp", false], [707, "module-torch.nn.functional", false], [707, "module-torch.nn.grad", false], [707, "module-torch.nn.init", false], [707, "module-torch.nn.modules", false], [707, "module-torch.nn.modules.activation", false], [707, "module-torch.nn.modules.adaptive", false], [707, "module-torch.nn.modules.batchnorm", false], [707, "module-torch.nn.modules.channelshuffle", false], [707, "module-torch.nn.modules.container", false], [707, "module-torch.nn.modules.conv", false], [707, "module-torch.nn.modules.distance", false], [707, "module-torch.nn.modules.dropout", false], [707, "module-torch.nn.modules.flatten", false], [707, "module-torch.nn.modules.fold", false], [707, "module-torch.nn.modules.instancenorm", false], [707, "module-torch.nn.modules.lazy", false], [707, "module-torch.nn.modules.linear", false], [707, "module-torch.nn.modules.loss", false], [707, "module-torch.nn.modules.module", false], [707, "module-torch.nn.modules.normalization", false], [707, "module-torch.nn.modules.padding", false], [707, "module-torch.nn.modules.pixelshuffle", false], [707, "module-torch.nn.modules.pooling", false], [707, "module-torch.nn.modules.rnn", false], [707, "module-torch.nn.modules.sparse", false], [707, "module-torch.nn.modules.transformer", false], [707, "module-torch.nn.modules.upsampling", false], [707, "module-torch.nn.modules.utils", false], [707, "module-torch.nn.parallel", false], [707, "module-torch.nn.parallel.comm", false], [707, "module-torch.nn.parallel.distributed", false], [707, "module-torch.nn.parallel.parallel_apply", false], [707, "module-torch.nn.parallel.replicate", false], [707, "module-torch.nn.parallel.scatter_gather", false], [707, "module-torch.nn.parameter", false], [707, "module-torch.nn.utils", false], [707, "module-torch.nn.utils.clip_grad", false], [707, "module-torch.nn.utils.convert_parameters", false], [707, "module-torch.nn.utils.fusion", false], [707, "module-torch.nn.utils.init", false], [707, "module-torch.nn.utils.memory_format", false], [707, "module-torch.nn.utils.parametrizations", false], [707, "module-torch.nn.utils.parametrize", false], [707, "module-torch.nn.utils.prune", false], [707, "module-torch.nn.utils.rnn", false], [707, "module-torch.nn.utils.stateless", false], [710, "module-torch", false], [712, "module-torch", false], [712, "module-torch.contrib", false], [712, "module-torch.functional", false], [712, "module-torch.quasirandom", false], [712, "module-torch.return_types", false], [712, "module-torch.serialization", false], [712, "module-torch.signal.windows.windows", false], [712, "module-torch.sparse.semi_structured", false], [712, "module-torch.storage", false], [712, "module-torch.torch_version", false], [712, "module-torch.types", false], [712, "module-torch.utils.backcompat", false], [712, "module-torch.utils.hipify", false], [712, "module-torch.utils.model_dump", false], [712, "module-torch.utils.viz", false], [712, "module-torch.version", false]], "module (in module torch.nn)": [[364, "torch.nn.module", false]], "module (in module torch.nn.parallel)": [[497, "torch.nn.parallel.module", false]], "module() (in module torch.nn)": [[428, "torch.nn.Module", false]], "moduledict() (in module torch.nn)": [[429, "torch.nn.ModuleDict", false]], "modulelist() (in module torch.nn)": [[430, "torch.nn.ModuleList", false]], "moveaxis() (in module torch)": [[310, "torch.moveaxis", false]], "movedim() (in module torch)": [[311, "torch.movedim", false]], "mseloss() (in module torch.nn)": [[419, "torch.nn.MSELoss", false]], "msort() (in module torch)": [[312, "torch.msort", false]], "mul() (in module torch)": [[313, "torch.mul", false]], "multiheadattention() (in module torch.nn)": [[434, "torch.nn.MultiheadAttention", false]], "multilabelmarginloss() (in module torch.nn)": [[431, "torch.nn.MultiLabelMarginLoss", false]], "multilabelsoftmarginloss() (in module torch.nn)": [[432, "torch.nn.MultiLabelSoftMarginLoss", false]], "multimarginloss() (in module torch.nn)": [[433, "torch.nn.MultiMarginLoss", false]], "multinomial() (in module torch)": [[314, "torch.multinomial", false]], "multiply() (in module torch)": [[315, "torch.multiply", false]], "mv() (in module torch)": [[316, "torch.mv", false]], "mvlgamma() (in module torch)": [[317, "torch.mvlgamma", false]], "name (torch.tag property)": [[712, "torch.Tag.name", false]], "nan_to_num() (in module torch)": [[318, "torch.nan_to_num", false]], "nanmean() (in module torch)": [[319, "torch.nanmean", false]], "nanmedian() (in module torch)": [[320, "torch.nanmedian", false]], "nanquantile() (in module torch)": [[321, "torch.nanquantile", false]], "nansum() (in module torch)": [[322, "torch.nansum", false]], "narrow() (in module torch)": [[323, "torch.narrow", false]], "narrow_copy() (in module torch)": [[324, "torch.narrow_copy", false]], "ne() (in module torch)": [[325, "torch.ne", false]], "neg() (in module torch)": [[326, "torch.neg", false]], "negative() (in module torch)": [[327, "torch.negative", false]], "nextafter() (in module torch)": [[328, "torch.nextafter", false]], "nllloss() (in module torch.nn)": [[435, "torch.nn.NLLLoss", false]], "no_grad (class in torch)": [[551, "torch.no_grad", false]], "nonzero() (in module torch)": [[552, "torch.nonzero", false]], "norm() (in module torch)": [[553, "torch.norm", false]], "normal() (in module torch)": [[554, "torch.normal", false]], "not_equal() (in module torch)": [[555, "torch.not_equal", false]], "numel() (in module torch)": [[556, "torch.numel", false]], "ones() (in module torch)": [[557, "torch.ones", false]], "ones_like() (in module torch)": [[558, "torch.ones_like", false]], "orgqr() (in module torch)": [[559, "torch.orgqr", false]], "ormqr() (in module torch)": [[560, "torch.ormqr", false]], "orthogonal() (in module torch.nn.utils.parametrizations)": [[512, "torch.nn.utils.parametrizations.orthogonal", false]], "outer() (in module torch)": [[561, "torch.outer", false]], "pack_padded_sequence() (in module torch.nn.utils.rnn)": [[540, "torch.nn.utils.rnn.pack_padded_sequence", false]], "pack_sequence() (in module torch.nn.utils.rnn)": [[541, "torch.nn.utils.rnn.pack_sequence", false]], "packedsequence (class in torch.nn.utils.rnn)": [[539, "torch.nn.utils.rnn.PackedSequence", false]], "pad_packed_sequence() (in module torch.nn.utils.rnn)": [[542, "torch.nn.utils.rnn.pad_packed_sequence", false]], "pad_sequence() (in module torch.nn.utils.rnn)": [[543, "torch.nn.utils.rnn.pad_sequence", false]], "pairwisedistance() (in module torch.nn)": [[437, "torch.nn.PairwiseDistance", false]], "parameter() (in module torch.nn.parameter)": [[499, "torch.nn.parameter.Parameter", false]], "parameterdict() (in module torch.nn)": [[438, "torch.nn.ParameterDict", false]], "parameterlist() (in module torch.nn)": [[439, "torch.nn.ParameterList", false]], "parameters_to_vector() (in module torch.nn.utils)": [[511, "torch.nn.utils.parameters_to_vector", false]], "parametrizationlist() (in module torch.nn.utils.parametrize)": [[515, "torch.nn.utils.parametrize.ParametrizationList", false]], "pca_lowrank() (in module torch)": [[562, "torch.pca_lowrank", false]], "permute() (in module torch)": [[563, "torch.permute", false]], "pinverse() (in module torch)": [[564, "torch.pinverse", false]], "pixelshuffle() (in module torch.nn)": [[440, "torch.nn.PixelShuffle", false]], "pixelunshuffle() (in module torch.nn)": [[441, "torch.nn.PixelUnshuffle", false]], "poisson() (in module torch)": [[565, "torch.poisson", false]], "poissonnllloss() (in module torch.nn)": [[442, "torch.nn.PoissonNLLLoss", false]], "polar() (in module torch)": [[566, "torch.polar", false]], "polygamma() (in module torch)": [[567, "torch.polygamma", false]], "positive() (in module torch)": [[568, "torch.positive", false]], "pow() (in module torch)": [[569, "torch.pow", false]], "prelu() (in module torch.nn)": [[436, "torch.nn.PReLU", false]], "prod() (in module torch)": [[570, "torch.prod", false]], "promote_types() (in module torch)": [[571, "torch.promote_types", false]], "prune() (torch.nn.utils.prune.basepruningmethod method)": [[520, "torch.nn.utils.prune.BasePruningMethod.prune", false]], "prune() (torch.nn.utils.prune.customfrommask method)": [[521, "torch.nn.utils.prune.CustomFromMask.prune", false]], "prune() (torch.nn.utils.prune.identity method)": [[522, "torch.nn.utils.prune.Identity.prune", false]], "prune() (torch.nn.utils.prune.l1unstructured method)": [[523, "torch.nn.utils.prune.L1Unstructured.prune", false]], "prune() (torch.nn.utils.prune.lnstructured method)": [[524, "torch.nn.utils.prune.LnStructured.prune", false]], "prune() (torch.nn.utils.prune.pruningcontainer method)": [[525, "torch.nn.utils.prune.PruningContainer.prune", false]], "prune() (torch.nn.utils.prune.randomstructured method)": [[526, "torch.nn.utils.prune.RandomStructured.prune", false]], "prune() (torch.nn.utils.prune.randomunstructured method)": [[527, "torch.nn.utils.prune.RandomUnstructured.prune", false]], "pruningcontainer (class in torch.nn.utils.prune)": [[525, "torch.nn.utils.prune.PruningContainer", false]], "qr() (in module torch)": [[572, "torch.qr", false]], "quantile() (in module torch)": [[573, "torch.quantile", false]], "quantize_per_channel() (in module torch)": [[574, "torch.quantize_per_channel", false]], "quantize_per_tensor() (in module torch)": [[575, "torch.quantize_per_tensor", false]], "quantized_batch_norm() (in module torch)": [[576, "torch.quantized_batch_norm", false]], "quantized_max_pool1d() (in module torch)": [[577, "torch.quantized_max_pool1d", false]], "quantized_max_pool2d() (in module torch)": [[578, "torch.quantized_max_pool2d", false]], "query() (torch.event method)": [[1, "torch.Event.query", false]], "query() (torch.stream method)": [[3, "torch.Stream.query", false]], "rad2deg() (in module torch)": [[580, "torch.rad2deg", false]], "rand() (in module torch)": [[581, "torch.rand", false]], "rand_like() (in module torch)": [[582, "torch.rand_like", false]], "randint() (in module torch)": [[583, "torch.randint", false]], "randint_like() (in module torch)": [[584, "torch.randint_like", false]], "randn() (in module torch)": [[585, "torch.randn", false]], "randn_like() (in module torch)": [[586, "torch.randn_like", false]], "random_structured() (in module torch.nn.utils.prune)": [[534, "torch.nn.utils.prune.random_structured", false]], "random_unstructured() (in module torch.nn.utils.prune)": [[535, "torch.nn.utils.prune.random_unstructured", false]], "randomstructured (class in torch.nn.utils.prune)": [[526, "torch.nn.utils.prune.RandomStructured", false]], "randomunstructured (class in torch.nn.utils.prune)": [[527, "torch.nn.utils.prune.RandomUnstructured", false]], "randperm() (in module torch)": [[587, "torch.randperm", false]], "range() (in module torch)": [[588, "torch.range", false]], "ravel() (in module torch)": [[589, "torch.ravel", false]], "real() (in module torch)": [[590, "torch.real", false]], "reciprocal() (in module torch)": [[591, "torch.reciprocal", false]], "record() (torch.event method)": [[1, "torch.Event.record", false]], "record_event() (torch.stream method)": [[3, "torch.Stream.record_event", false]], "reflectionpad1d() (in module torch.nn)": [[450, "torch.nn.ReflectionPad1d", false]], "reflectionpad2d() (in module torch.nn)": [[451, "torch.nn.ReflectionPad2d", false]], "reflectionpad3d() (in module torch.nn)": [[452, "torch.nn.ReflectionPad3d", false]], "register_module_backward_hook() (in module torch.nn.modules.module)": [[488, "torch.nn.modules.module.register_module_backward_hook", false]], "register_module_buffer_registration_hook() (in module torch.nn.modules.module)": [[489, "torch.nn.modules.module.register_module_buffer_registration_hook", false]], "register_module_forward_hook() (in module torch.nn.modules.module)": [[490, "torch.nn.modules.module.register_module_forward_hook", false]], "register_module_forward_pre_hook() (in module torch.nn.modules.module)": [[491, "torch.nn.modules.module.register_module_forward_pre_hook", false]], "register_module_full_backward_hook() (in module torch.nn.modules.module)": [[492, "torch.nn.modules.module.register_module_full_backward_hook", false]], "register_module_full_backward_pre_hook() (in module torch.nn.modules.module)": [[493, "torch.nn.modules.module.register_module_full_backward_pre_hook", false]], "register_module_module_registration_hook() (in module torch.nn.modules.module)": [[494, "torch.nn.modules.module.register_module_module_registration_hook", false]], "register_module_parameter_registration_hook() (in module torch.nn.modules.module)": [[495, "torch.nn.modules.module.register_module_parameter_registration_hook", false]], "register_parametrization() (in module torch.nn.utils.parametrize)": [[518, "torch.nn.utils.parametrize.register_parametrization", false]], "relu() (in module torch.nn)": [[448, "torch.nn.ReLU", false]], "relu6() (in module torch.nn)": [[449, "torch.nn.ReLU6", false]], "remainder() (in module torch)": [[592, "torch.remainder", false]], "remove() (in module torch.nn.utils.prune)": [[536, "torch.nn.utils.prune.remove", false]], "remove() (torch.nn.utils.prune.basepruningmethod method)": [[520, "torch.nn.utils.prune.BasePruningMethod.remove", false]], "remove() (torch.nn.utils.prune.customfrommask method)": [[521, "torch.nn.utils.prune.CustomFromMask.remove", false]], "remove() (torch.nn.utils.prune.identity method)": [[522, "torch.nn.utils.prune.Identity.remove", false]], "remove() (torch.nn.utils.prune.l1unstructured method)": [[523, "torch.nn.utils.prune.L1Unstructured.remove", false]], "remove() (torch.nn.utils.prune.lnstructured method)": [[524, "torch.nn.utils.prune.LnStructured.remove", false]], "remove() (torch.nn.utils.prune.pruningcontainer method)": [[525, "torch.nn.utils.prune.PruningContainer.remove", false]], "remove() (torch.nn.utils.prune.randomstructured method)": [[526, "torch.nn.utils.prune.RandomStructured.remove", false]], "remove() (torch.nn.utils.prune.randomunstructured method)": [[527, "torch.nn.utils.prune.RandomUnstructured.remove", false]], "remove_parametrizations() (in module torch.nn.utils.parametrize)": [[519, "torch.nn.utils.parametrize.remove_parametrizations", false]], "remove_spectral_norm() (in module torch.nn.utils)": [[537, "torch.nn.utils.remove_spectral_norm", false]], "remove_weight_norm() (in module torch.nn.utils)": [[538, "torch.nn.utils.remove_weight_norm", false]], "renorm() (in module torch)": [[593, "torch.renorm", false]], "repeat_interleave() (in module torch)": [[594, "torch.repeat_interleave", false]], "replicationpad1d() (in module torch.nn)": [[453, "torch.nn.ReplicationPad1d", false]], "replicationpad2d() (in module torch.nn)": [[454, "torch.nn.ReplicationPad2d", false]], "replicationpad3d() (in module torch.nn)": [[455, "torch.nn.ReplicationPad3d", false]], "reshape() (in module torch)": [[595, "torch.reshape", false]], "resolve_conj() (in module torch)": [[596, "torch.resolve_conj", false]], "resolve_neg() (in module torch)": [[597, "torch.resolve_neg", false]], "result_type() (in module torch)": [[598, "torch.result_type", false]], "rmsnorm() (in module torch.nn)": [[443, "torch.nn.RMSNorm", false]], "rmsnorm() (in module torch.nn.modules.normalization)": [[496, "torch.nn.modules.normalization.RMSNorm", false]], "rnn() (in module torch.nn)": [[444, "torch.nn.RNN", false]], "rnnbase() (in module torch.nn)": [[445, "torch.nn.RNNBase", false]], "rnncell() (in module torch.nn)": [[446, "torch.nn.RNNCell", false]], "roll() (in module torch)": [[599, "torch.roll", false]], "rot90() (in module torch)": [[600, "torch.rot90", false]], "round() (in module torch)": [[601, "torch.round", false]], "row_stack() (in module torch)": [[602, "torch.row_stack", false]], "rrelu() (in module torch.nn)": [[447, "torch.nn.RReLU", false]], "rsqrt() (in module torch)": [[603, "torch.rsqrt", false]], "save() (in module torch)": [[604, "torch.save", false]], "scatter() (in module torch)": [[605, "torch.scatter", false]], "scatter_add() (in module torch)": [[606, "torch.scatter_add", false]], "scatter_reduce() (in module torch)": [[607, "torch.scatter_reduce", false]], "searchsorted() (in module torch)": [[608, "torch.searchsorted", false]], "seed() (in module torch)": [[609, "torch.seed", false]], "seed() (torch.generator method)": [[2, "torch.Generator.seed", false]], "select() (in module torch)": [[610, "torch.select", false]], "select_scatter() (in module torch)": [[611, "torch.select_scatter", false]], "selu() (in module torch.nn)": [[456, "torch.nn.SELU", false]], "sequential() (in module torch.nn)": [[457, "torch.nn.Sequential", false]], "set_default_device() (in module torch)": [[612, "torch.set_default_device", false]], "set_default_dtype() (in module torch)": [[613, "torch.set_default_dtype", false]], "set_default_tensor_type() (in module torch)": [[614, "torch.set_default_tensor_type", false]], "set_deterministic_debug_mode() (in module torch)": [[615, "torch.set_deterministic_debug_mode", false]], "set_float32_matmul_precision() (in module torch)": [[616, "torch.set_float32_matmul_precision", false]], "set_flush_denormal() (in module torch)": [[617, "torch.set_flush_denormal", false]], "set_grad_enabled (class in torch.autograd.grad_mode)": [[104, "torch.autograd.grad_mode.set_grad_enabled", false]], "set_num_interop_threads() (in module torch)": [[618, "torch.set_num_interop_threads", false]], "set_num_threads() (in module torch)": [[619, "torch.set_num_threads", false]], "set_printoptions() (in module torch)": [[620, "torch.set_printoptions", false]], "set_rng_state() (in module torch)": [[621, "torch.set_rng_state", false]], "set_state() (torch.generator method)": [[2, "torch.Generator.set_state", false]], "set_warn_always() (in module torch)": [[622, "torch.set_warn_always", false]], "sgn() (in module torch)": [[623, "torch.sgn", false]], "sigmoid() (in module torch)": [[624, "torch.sigmoid", false]], "sigmoid() (in module torch.nn)": [[459, "torch.nn.Sigmoid", false]], "sign() (in module torch)": [[625, "torch.sign", false]], "signbit() (in module torch)": [[626, "torch.signbit", false]], "silu() (in module torch.nn)": [[458, "torch.nn.SiLU", false]], "sin() (in module torch)": [[627, "torch.sin", false]], "sinc() (in module torch)": [[628, "torch.sinc", false]], "sinh() (in module torch)": [[629, "torch.sinh", false]], "skip_init() (in module torch.nn.utils)": [[546, "torch.nn.utils.skip_init", false]], "slice_scatter() (in module torch)": [[630, "torch.slice_scatter", false]], "slogdet() (in module torch)": [[631, "torch.slogdet", false]], "smoothl1loss() (in module torch.nn)": [[460, "torch.nn.SmoothL1Loss", false]], "sobolengine() (in module torch.quasirandom)": [[579, "torch.quasirandom.SobolEngine", false]], "softmarginloss() (in module torch.nn)": [[461, "torch.nn.SoftMarginLoss", false]], "softmax() (in module torch)": [[632, "torch.softmax", false]], "softmax() (in module torch.nn)": [[462, "torch.nn.Softmax", false]], "softmax2d() (in module torch.nn)": [[463, "torch.nn.Softmax2d", false]], "softmin() (in module torch.nn)": [[464, "torch.nn.Softmin", false]], "softplus() (in module torch.nn)": [[465, "torch.nn.Softplus", false]], "softshrink() (in module torch.nn)": [[466, "torch.nn.Softshrink", false]], "softsign() (in module torch.nn)": [[467, "torch.nn.Softsign", false]], "sort() (in module torch)": [[633, "torch.sort", false]], "sorted_indices (torch.nn.utils.rnn.packedsequence attribute)": [[539, "id2", false], [539, "torch.nn.utils.rnn.PackedSequence.sorted_indices", false]], "sparse_bsc_tensor() (in module torch)": [[634, "torch.sparse_bsc_tensor", false]], "sparse_bsr_tensor() (in module torch)": [[635, "torch.sparse_bsr_tensor", false]], "sparse_coo_tensor() (in module torch)": [[636, "torch.sparse_coo_tensor", false]], "sparse_csc_tensor() (in module torch)": [[637, "torch.sparse_csc_tensor", false]], "sparse_csr_tensor() (in module torch)": [[638, "torch.sparse_csr_tensor", false]], "spectral_norm() (in module torch.nn.utils)": [[547, "torch.nn.utils.spectral_norm", false]], "spectral_norm() (in module torch.nn.utils.parametrizations)": [[513, "torch.nn.utils.parametrizations.spectral_norm", false]], "split() (in module torch)": [[639, "torch.split", false]], "sqrt() (in module torch)": [[640, "torch.sqrt", false]], "square() (in module torch)": [[641, "torch.square", false]], "squeeze() (in module torch)": [[642, "torch.squeeze", false]], "stack() (in module torch)": [[643, "torch.stack", false]], "std() (in module torch)": [[644, "torch.std", false]], "std_mean() (in module torch)": [[645, "torch.std_mean", false]], "stft() (in module torch)": [[646, "torch.stft", false]], "stream (class in torch)": [[3, "torch.Stream", false]], "sub() (in module torch)": [[647, "torch.sub", false]], "subtract() (in module torch)": [[648, "torch.subtract", false]], "sum() (in module torch)": [[649, "torch.sum", false]], "svd() (in module torch)": [[650, "torch.svd", false]], "svd_lowrank() (in module torch)": [[651, "torch.svd_lowrank", false]], "swapaxes() (in module torch)": [[652, "torch.swapaxes", false]], "swapdims() (in module torch)": [[653, "torch.swapdims", false]], "sym_float() (in module torch)": [[654, "torch.sym_float", false]], "sym_int() (in module torch)": [[655, "torch.sym_int", false]], "sym_ite() (in module torch)": [[656, "torch.sym_ite", false]], "sym_max() (in module torch)": [[657, "torch.sym_max", false]], "sym_min() (in module torch)": [[658, "torch.sym_min", false]], "sym_not() (in module torch)": [[659, "torch.sym_not", false]], "symbool (class in torch)": [[712, "torch.SymBool", false]], "symfloat (class in torch)": [[712, "torch.SymFloat", false]], "symint (class in torch)": [[712, "torch.SymInt", false]], "syncbatchnorm() (in module torch.nn)": [[468, "torch.nn.SyncBatchNorm", false]], "synchronize() (torch.event method)": [[1, "torch.Event.synchronize", false]], "synchronize() (torch.stream method)": [[3, "torch.Stream.synchronize", false]], "t() (in module torch)": [[660, "torch.t", false]], "tag (class in torch)": [[712, "torch.Tag", false]], "take() (in module torch)": [[661, "torch.take", false]], "take_along_dim() (in module torch)": [[662, "torch.take_along_dim", false]], "tan() (in module torch)": [[663, "torch.tan", false]], "tanh() (in module torch)": [[664, "torch.tanh", false]], "tanh() (in module torch.nn)": [[469, "torch.nn.Tanh", false]], "tanhshrink() (in module torch.nn)": [[470, "torch.nn.Tanhshrink", false]], "tensor() (in module torch)": [[665, "torch.tensor", false]], "tensor_split() (in module torch)": [[666, "torch.tensor_split", false]], "tensordot() (in module torch)": [[667, "torch.tensordot", false]], "threshold() (in module torch.nn)": [[471, "torch.nn.Threshold", false]], "tile() (in module torch)": [[668, "torch.tile", false]], "to() (torch.nn.utils.rnn.packedsequence method)": [[539, "torch.nn.utils.rnn.PackedSequence.to", false]], "topk() (in module torch)": [[669, "torch.topk", false]], "torch": [[710, "module-torch", false], [712, "module-torch", false]], "torch.contrib": [[712, "module-torch.contrib", false]], "torch.functional": [[712, "module-torch.functional", false]], "torch.nn": [[707, "module-torch.nn", false]], "torch.nn.backends": [[707, "module-torch.nn.backends", false]], "torch.nn.backends.thnn": [[707, "module-torch.nn.backends.thnn", false]], "torch.nn.common_types": [[707, "module-torch.nn.common_types", false]], "torch.nn.cpp": [[707, "module-torch.nn.cpp", false]], "torch.nn.functional": [[707, "module-torch.nn.functional", false]], "torch.nn.grad": [[707, "module-torch.nn.grad", false]], "torch.nn.init": [[707, "module-torch.nn.init", false]], "torch.nn.modules": [[707, "module-torch.nn.modules", false]], "torch.nn.modules.activation": [[707, "module-torch.nn.modules.activation", false]], "torch.nn.modules.adaptive": [[707, "module-torch.nn.modules.adaptive", false]], "torch.nn.modules.batchnorm": [[707, "module-torch.nn.modules.batchnorm", false]], "torch.nn.modules.channelshuffle": [[707, "module-torch.nn.modules.channelshuffle", false]], "torch.nn.modules.container": [[707, "module-torch.nn.modules.container", false]], "torch.nn.modules.conv": [[707, "module-torch.nn.modules.conv", false]], "torch.nn.modules.distance": [[707, "module-torch.nn.modules.distance", false]], "torch.nn.modules.dropout": [[707, "module-torch.nn.modules.dropout", false]], "torch.nn.modules.flatten": [[707, "module-torch.nn.modules.flatten", false]], "torch.nn.modules.fold": [[707, "module-torch.nn.modules.fold", false]], "torch.nn.modules.instancenorm": [[707, "module-torch.nn.modules.instancenorm", false]], "torch.nn.modules.lazy": [[707, "module-torch.nn.modules.lazy", false]], "torch.nn.modules.linear": [[707, "module-torch.nn.modules.linear", false]], "torch.nn.modules.loss": [[707, "module-torch.nn.modules.loss", false]], "torch.nn.modules.module": [[707, "module-torch.nn.modules.module", false]], "torch.nn.modules.normalization": [[707, "module-torch.nn.modules.normalization", false]], "torch.nn.modules.padding": [[707, "module-torch.nn.modules.padding", false]], "torch.nn.modules.pixelshuffle": [[707, "module-torch.nn.modules.pixelshuffle", false]], "torch.nn.modules.pooling": [[707, "module-torch.nn.modules.pooling", false]], "torch.nn.modules.rnn": [[707, "module-torch.nn.modules.rnn", false]], "torch.nn.modules.sparse": [[707, "module-torch.nn.modules.sparse", false]], "torch.nn.modules.transformer": [[707, "module-torch.nn.modules.transformer", false]], "torch.nn.modules.upsampling": [[707, "module-torch.nn.modules.upsampling", false]], "torch.nn.modules.utils": [[707, "module-torch.nn.modules.utils", false]], "torch.nn.parallel": [[707, "module-torch.nn.parallel", false]], "torch.nn.parallel.comm": [[707, "module-torch.nn.parallel.comm", false]], "torch.nn.parallel.distributed": [[707, "module-torch.nn.parallel.distributed", false]], "torch.nn.parallel.parallel_apply": [[707, "module-torch.nn.parallel.parallel_apply", false]], "torch.nn.parallel.replicate": [[707, "module-torch.nn.parallel.replicate", false]], "torch.nn.parallel.scatter_gather": [[707, "module-torch.nn.parallel.scatter_gather", false]], "torch.nn.parameter": [[707, "module-torch.nn.parameter", false]], "torch.nn.utils": [[707, "module-torch.nn.utils", false]], "torch.nn.utils.clip_grad": [[707, "module-torch.nn.utils.clip_grad", false]], "torch.nn.utils.convert_parameters": [[707, "module-torch.nn.utils.convert_parameters", false]], "torch.nn.utils.fusion": [[707, "module-torch.nn.utils.fusion", false]], "torch.nn.utils.init": [[707, "module-torch.nn.utils.init", false]], "torch.nn.utils.memory_format": [[707, "module-torch.nn.utils.memory_format", false]], "torch.nn.utils.parametrizations": [[707, "module-torch.nn.utils.parametrizations", false]], "torch.nn.utils.parametrize": [[707, "module-torch.nn.utils.parametrize", false]], "torch.nn.utils.prune": [[707, "module-torch.nn.utils.prune", false]], "torch.nn.utils.rnn": [[707, "module-torch.nn.utils.rnn", false]], "torch.nn.utils.stateless": [[707, "module-torch.nn.utils.stateless", false]], "torch.quasirandom": [[712, "module-torch.quasirandom", false]], "torch.return_types": [[712, "module-torch.return_types", false]], "torch.serialization": [[712, "module-torch.serialization", false]], "torch.signal.windows.windows": [[712, "module-torch.signal.windows.windows", false]], "torch.sparse.semi_structured": [[712, "module-torch.sparse.semi_structured", false]], "torch.storage": [[712, "module-torch.storage", false]], "torch.torch_version": [[712, "module-torch.torch_version", false]], "torch.types": [[712, "module-torch.types", false]], "torch.utils.backcompat": [[712, "module-torch.utils.backcompat", false]], "torch.utils.hipify": [[712, "module-torch.utils.hipify", false]], "torch.utils.model_dump": [[712, "module-torch.utils.model_dump", false]], "torch.utils.viz": [[712, "module-torch.utils.viz", false]], "torch.version": [[712, "module-torch.version", false]], "trace() (in module torch)": [[670, "torch.trace", false]], "transformer() (in module torch.nn)": [[472, "torch.nn.Transformer", false]], "transformerdecoder() (in module torch.nn)": [[473, "torch.nn.TransformerDecoder", false]], "transformerdecoderlayer() (in module torch.nn)": [[474, "torch.nn.TransformerDecoderLayer", false]], "transformerencoder() (in module torch.nn)": [[475, "torch.nn.TransformerEncoder", false]], "transformerencoderlayer() (in module torch.nn)": [[476, "torch.nn.TransformerEncoderLayer", false]], "transpose() (in module torch)": [[671, "torch.transpose", false]], "trapezoid() (in module torch)": [[672, "torch.trapezoid", false]], "trapz() (in module torch)": [[673, "torch.trapz", false]], "triangular_solve() (in module torch)": [[674, "torch.triangular_solve", false]], "tril() (in module torch)": [[675, "torch.tril", false]], "tril_indices() (in module torch)": [[676, "torch.tril_indices", false]], "tripletmarginloss() (in module torch.nn)": [[477, "torch.nn.TripletMarginLoss", false]], "tripletmarginwithdistanceloss() (in module torch.nn)": [[478, "torch.nn.TripletMarginWithDistanceLoss", false]], "triu() (in module torch)": [[677, "torch.triu", false]], "triu_indices() (in module torch)": [[678, "torch.triu_indices", false]], "true_divide() (in module torch)": [[679, "torch.true_divide", false]], "trunc() (in module torch)": [[680, "torch.trunc", false]], "unbind() (in module torch)": [[681, "torch.unbind", false]], "unflatten() (in module torch)": [[682, "torch.unflatten", false]], "unflatten() (in module torch.nn)": [[479, "torch.nn.Unflatten", false]], "unfold() (in module torch.nn)": [[480, "torch.nn.Unfold", false]], "uninitializedbuffer() (in module torch.nn.parameter)": [[500, "torch.nn.parameter.UninitializedBuffer", false]], "uninitializedparameter() (in module torch.nn.parameter)": [[501, "torch.nn.parameter.UninitializedParameter", false]], "unique() (in module torch)": [[683, "torch.unique", false]], "unique_consecutive() (in module torch)": [[684, "torch.unique_consecutive", false]], "unpack_sequence() (in module torch.nn.utils.rnn)": [[544, "torch.nn.utils.rnn.unpack_sequence", false]], "unpad_sequence() (in module torch.nn.utils.rnn)": [[545, "torch.nn.utils.rnn.unpad_sequence", false]], "unravel_index() (in module torch)": [[685, "torch.unravel_index", false]], "unsorted_indices (torch.nn.utils.rnn.packedsequence attribute)": [[539, "id3", false], [539, "torch.nn.utils.rnn.PackedSequence.unsorted_indices", false]], "unsqueeze() (in module torch)": [[686, "torch.unsqueeze", false]], "upsample() (in module torch.nn)": [[481, "torch.nn.Upsample", false]], "upsamplingbilinear2d() (in module torch.nn)": [[482, "torch.nn.UpsamplingBilinear2d", false]], "upsamplingnearest2d() (in module torch.nn)": [[483, "torch.nn.UpsamplingNearest2d", false]], "use_deterministic_algorithms() (in module torch)": [[687, "torch.use_deterministic_algorithms", false]], "vander() (in module torch)": [[688, "torch.vander", false]], "var() (in module torch)": [[689, "torch.var", false]], "var_mean() (in module torch)": [[690, "torch.var_mean", false]], "vdot() (in module torch)": [[691, "torch.vdot", false]], "vector_to_parameters() (in module torch.nn.utils)": [[549, "torch.nn.utils.vector_to_parameters", false]], "view_as_complex() (in module torch)": [[692, "torch.view_as_complex", false]], "view_as_real() (in module torch)": [[693, "torch.view_as_real", false]], "vmap() (in module torch)": [[694, "torch.vmap", false]], "vsplit() (in module torch)": [[695, "torch.vsplit", false]], "vstack() (in module torch)": [[696, "torch.vstack", false]], "wait() (torch.event method)": [[1, "torch.Event.wait", false]], "wait_event() (torch.stream method)": [[3, "torch.Stream.wait_event", false]], "wait_stream() (torch.stream method)": [[3, "torch.Stream.wait_stream", false]], "weight (in module torch.nn)": [[345, "torch.nn.weight", false], [355, "torch.nn.weight", false], [356, "torch.nn.weight", false], [357, "torch.nn.weight", false], [358, "torch.nn.weight", false], [359, "torch.nn.weight", false], [360, "torch.nn.weight", false], [370, "torch.nn.weight", false], [371, "torch.nn.weight", false], [400, "torch.nn.weight", false], [413, "torch.nn.weight", false], [415, "torch.nn.weight", false], [436, "torch.nn.weight", false]], "weight_hh (in module torch.nn)": [[380, "torch.nn.weight_hh", false], [399, "torch.nn.weight_hh", false], [446, "torch.nn.weight_hh", false]], "weight_hh_l (in module torch.nn)": [[379, "torch.nn.weight_hh_l", false], [398, "torch.nn.weight_hh_l", false], [444, "torch.nn.weight_hh_l", false]], "weight_hr_l (in module torch.nn)": [[398, "torch.nn.weight_hr_l", false]], "weight_ih (in module torch.nn)": [[380, "torch.nn.weight_ih", false], [399, "torch.nn.weight_ih", false], [446, "torch.nn.weight_ih", false]], "weight_ih_l (in module torch.nn)": [[379, "torch.nn.weight_ih_l", false], [398, "torch.nn.weight_ih_l", false], [444, "torch.nn.weight_ih_l", false]], "weight_norm() (in module torch.nn.utils)": [[550, "torch.nn.utils.weight_norm", false]], "weight_norm() (in module torch.nn.utils.parametrizations)": [[514, "torch.nn.utils.parametrizations.weight_norm", false]], "where() (in module torch)": [[697, "torch.where", false]], "xlogy() (in module torch)": [[698, "torch.xlogy", false]], "zeropad1d() (in module torch.nn)": [[484, "torch.nn.ZeroPad1d", false]], "zeropad2d() (in module torch.nn)": [[485, "torch.nn.ZeroPad2d", false]], "zeropad3d() (in module torch.nn)": [[486, "torch.nn.ZeroPad3d", false]], "zeros() (in module torch)": [[699, "torch.zeros", false]], "zeros_like() (in module torch)": [[700, "torch.zeros_like", false]]}, "objects": {"": [[712, 0, 0, "-", "torch"]], "torch": [[1, 1, 1, "", "Event"], [2, 1, 1, "", "Generator"], [3, 1, 1, "", "Stream"], [712, 1, 1, "", "SymBool"], [712, 1, 1, "", "SymFloat"], [712, 1, 1, "", "SymInt"], [712, 1, 1, "", "Tag"], [4, 5, 1, "", "_assert"], [5, 5, 1, "", "_foreach_abs"], [6, 5, 1, "", "_foreach_abs_"], [7, 5, 1, "", "_foreach_acos"], [8, 5, 1, "", "_foreach_acos_"], [9, 5, 1, "", "_foreach_asin"], [10, 5, 1, "", "_foreach_asin_"], [11, 5, 1, "", "_foreach_atan"], [12, 5, 1, "", "_foreach_atan_"], [13, 5, 1, "", "_foreach_ceil"], [14, 5, 1, "", "_foreach_ceil_"], [15, 5, 1, "", "_foreach_cos"], [16, 5, 1, "", "_foreach_cos_"], [17, 5, 1, "", "_foreach_cosh"], [18, 5, 1, "", "_foreach_cosh_"], [19, 5, 1, "", "_foreach_erf"], [20, 5, 1, "", "_foreach_erf_"], [21, 5, 1, "", "_foreach_erfc"], [22, 5, 1, "", "_foreach_erfc_"], [23, 5, 1, "", "_foreach_exp"], [24, 5, 1, "", "_foreach_exp_"], [25, 5, 1, "", "_foreach_expm1"], [26, 5, 1, "", "_foreach_expm1_"], [27, 5, 1, "", "_foreach_floor"], [28, 5, 1, "", "_foreach_floor_"], [29, 5, 1, "", "_foreach_frac"], [30, 5, 1, "", "_foreach_frac_"], [31, 5, 1, "", "_foreach_lgamma"], [32, 5, 1, "", "_foreach_lgamma_"], [33, 5, 1, "", "_foreach_log"], [34, 5, 1, "", "_foreach_log10"], [35, 5, 1, "", "_foreach_log10_"], [36, 5, 1, "", "_foreach_log1p"], [37, 5, 1, "", "_foreach_log1p_"], [38, 5, 1, "", "_foreach_log2"], [39, 5, 1, "", "_foreach_log2_"], [40, 5, 1, "", "_foreach_log_"], [41, 5, 1, "", "_foreach_neg"], [42, 5, 1, "", "_foreach_neg_"], [43, 5, 1, "", "_foreach_reciprocal"], [44, 5, 1, "", "_foreach_reciprocal_"], [45, 5, 1, "", "_foreach_round"], [46, 5, 1, "", "_foreach_round_"], [47, 5, 1, "", "_foreach_sigmoid"], [48, 5, 1, "", "_foreach_sigmoid_"], [49, 5, 1, "", "_foreach_sin"], [50, 5, 1, "", "_foreach_sin_"], [51, 5, 1, "", "_foreach_sinh"], [52, 5, 1, "", "_foreach_sinh_"], [53, 5, 1, "", "_foreach_sqrt"], [54, 5, 1, "", "_foreach_sqrt_"], [55, 5, 1, "", "_foreach_tan"], [56, 5, 1, "", "_foreach_tan_"], [57, 5, 1, "", "_foreach_trunc"], [58, 5, 1, "", "_foreach_trunc_"], [59, 5, 1, "", "_foreach_zero_"], [60, 5, 1, "", "abs"], [61, 5, 1, "", "absolute"], [62, 5, 1, "", "acos"], [63, 5, 1, "", "acosh"], [64, 5, 1, "", "add"], [65, 5, 1, "", "addbmm"], [66, 5, 1, "", "addcdiv"], [67, 5, 1, "", "addcmul"], [68, 5, 1, "", "addmm"], [69, 5, 1, "", "addmv"], [70, 5, 1, "", "addr"], [71, 5, 1, "", "adjoint"], [72, 5, 1, "", "all"], [73, 5, 1, "", "allclose"], [74, 5, 1, "", "amax"], [75, 5, 1, "", "amin"], [76, 5, 1, "", "aminmax"], [77, 5, 1, "", "angle"], [78, 5, 1, "", "any"], [79, 5, 1, "", "arange"], [80, 5, 1, "", "arccos"], [81, 5, 1, "", "arccosh"], [82, 5, 1, "", "arcsin"], [83, 5, 1, "", "arcsinh"], [84, 5, 1, "", "arctan"], [85, 5, 1, "", "arctan2"], [86, 5, 1, "", "arctanh"], [87, 5, 1, "", "are_deterministic_algorithms_enabled"], [88, 5, 1, "", "argmax"], [89, 5, 1, "", "argmin"], [90, 5, 1, "", "argsort"], [91, 5, 1, "", "argwhere"], [92, 5, 1, "", "as_strided"], [93, 5, 1, "", "as_tensor"], [94, 5, 1, "", "asarray"], [95, 5, 1, "", "asin"], [96, 5, 1, "", "asinh"], [97, 5, 1, "", "atan"], [98, 5, 1, "", "atan2"], [99, 5, 1, "", "atanh"], [100, 5, 1, "", "atleast_1d"], [101, 5, 1, "", "atleast_2d"], [102, 5, 1, "", "atleast_3d"], [105, 5, 1, "", "baddbmm"], [106, 5, 1, "", "bartlett_window"], [107, 5, 1, "", "bernoulli"], [108, 5, 1, "", "bincount"], [109, 5, 1, "", "bitwise_and"], [110, 5, 1, "", "bitwise_left_shift"], [111, 5, 1, "", "bitwise_not"], [112, 5, 1, "", "bitwise_or"], [113, 5, 1, "", "bitwise_right_shift"], [114, 5, 1, "", "bitwise_xor"], [115, 5, 1, "", "blackman_window"], [116, 5, 1, "", "block_diag"], [117, 5, 1, "", "bmm"], [118, 5, 1, "", "broadcast_shapes"], [119, 5, 1, "", "broadcast_tensors"], [120, 5, 1, "", "broadcast_to"], [121, 5, 1, "", "bucketize"], [122, 5, 1, "", "can_cast"], [123, 5, 1, "", "cartesian_prod"], [124, 5, 1, "", "cat"], [125, 5, 1, "", "cdist"], [126, 5, 1, "", "ceil"], [127, 5, 1, "", "chain_matmul"], [128, 5, 1, "", "cholesky"], [129, 5, 1, "", "cholesky_inverse"], [130, 5, 1, "", "cholesky_solve"], [131, 5, 1, "", "chunk"], [132, 5, 1, "", "clamp"], [133, 5, 1, "", "clip"], [134, 5, 1, "", "clone"], [135, 5, 1, "", "column_stack"], [136, 5, 1, "", "combinations"], [137, 5, 1, "", "compile"], [138, 5, 1, "", "compiled_with_cxx11_abi"], [139, 5, 1, "", "complex"], [140, 5, 1, "", "concat"], [141, 5, 1, "", "concatenate"], [142, 5, 1, "", "cond"], [143, 5, 1, "", "conj"], [144, 5, 1, "", "conj_physical"], [712, 0, 0, "-", "contrib"], [145, 5, 1, "", "copysign"], [146, 5, 1, "", "corrcoef"], [147, 5, 1, "", "cos"], [148, 5, 1, "", "cosh"], [149, 5, 1, "", "count_nonzero"], [150, 5, 1, "", "cov"], [151, 5, 1, "", "cross"], [152, 5, 1, "", "cummax"], [153, 5, 1, "", "cummin"], [154, 5, 1, "", "cumprod"], [155, 5, 1, "", "cumsum"], [156, 5, 1, "", "cumulative_trapezoid"], [157, 5, 1, "", "deg2rad"], [158, 5, 1, "", "dequantize"], [159, 5, 1, "", "det"], [711, 1, 1, "", "device"], [160, 5, 1, "", "diag"], [161, 5, 1, "", "diag_embed"], [162, 5, 1, "", "diagflat"], [163, 5, 1, "", "diagonal"], [164, 5, 1, "", "diagonal_scatter"], [165, 5, 1, "", "diff"], [166, 5, 1, "", "digamma"], [167, 5, 1, "", "dist"], [168, 5, 1, "", "div"], [169, 5, 1, "", "divide"], [170, 5, 1, "", "dot"], [171, 5, 1, "", "dsplit"], [172, 5, 1, "", "dstack"], [711, 1, 1, "", "dtype"], [173, 5, 1, "", "einsum"], [174, 5, 1, "", "empty"], [175, 5, 1, "", "empty_like"], [176, 5, 1, "", "empty_strided"], [177, 1, 1, "", "enable_grad"], [178, 5, 1, "", "eq"], [179, 5, 1, "", "equal"], [180, 5, 1, "", "erf"], [181, 5, 1, "", "erfc"], [182, 5, 1, "", "erfinv"], [183, 5, 1, "", "exp"], [184, 5, 1, "", "exp2"], [185, 5, 1, "", "expm1"], [186, 5, 1, "", "eye"], [187, 5, 1, "", "fake_quantize_per_channel_affine"], [188, 5, 1, "", "fake_quantize_per_tensor_affine"], [189, 5, 1, "", "fix"], [190, 5, 1, "", "flatten"], [191, 5, 1, "", "flip"], [192, 5, 1, "", "fliplr"], [193, 5, 1, "", "flipud"], [194, 5, 1, "", "float_power"], [195, 5, 1, "", "floor"], [196, 5, 1, "", "floor_divide"], [197, 5, 1, "", "fmax"], [198, 5, 1, "", "fmin"], [199, 5, 1, "", "fmod"], [200, 5, 1, "", "frac"], [201, 5, 1, "", "frexp"], [202, 5, 1, "", "from_dlpack"], [203, 5, 1, "", "from_file"], [204, 5, 1, "", "from_numpy"], [205, 5, 1, "", "frombuffer"], [206, 5, 1, "", "full"], [207, 5, 1, "", "full_like"], [712, 0, 0, "-", "functional"], [208, 5, 1, "", "gather"], [209, 5, 1, "", "gcd"], [210, 5, 1, "", "ge"], [211, 5, 1, "", "geqrf"], [212, 5, 1, "", "ger"], [213, 5, 1, "", "get_default_device"], [214, 5, 1, "", "get_default_dtype"], [215, 5, 1, "", "get_deterministic_debug_mode"], [216, 5, 1, "", "get_device_module"], [217, 5, 1, "", "get_float32_matmul_precision"], [218, 5, 1, "", "get_num_interop_threads"], [219, 5, 1, "", "get_num_threads"], [220, 5, 1, "", "get_rng_state"], [221, 5, 1, "", "gradient"], [222, 5, 1, "", "greater"], [223, 5, 1, "", "greater_equal"], [224, 5, 1, "", "gt"], [225, 5, 1, "", "hamming_window"], [226, 5, 1, "", "hann_window"], [227, 5, 1, "", "heaviside"], [228, 5, 1, "", "histc"], [229, 5, 1, "", "histogram"], [230, 5, 1, "", "histogramdd"], [231, 5, 1, "", "hsplit"], [232, 5, 1, "", "hstack"], [233, 5, 1, "", "hypot"], [234, 5, 1, "", "i0"], [235, 5, 1, "", "igamma"], [236, 5, 1, "", "igammac"], [237, 5, 1, "", "imag"], [238, 5, 1, "", "index_add"], [239, 5, 1, "", "index_copy"], [240, 5, 1, "", "index_reduce"], [241, 5, 1, "", "index_select"], [242, 5, 1, "", "initial_seed"], [243, 5, 1, "", "inner"], [244, 5, 1, "", "inverse"], [245, 5, 1, "", "is_complex"], [246, 5, 1, "", "is_conj"], [247, 5, 1, "", "is_deterministic_algorithms_warn_only_enabled"], [248, 5, 1, "", "is_floating_point"], [249, 5, 1, "", "is_grad_enabled"], [250, 5, 1, "", "is_inference_mode_enabled"], [251, 5, 1, "", "is_nonzero"], [252, 5, 1, "", "is_storage"], [253, 5, 1, "", "is_tensor"], [254, 5, 1, "", "is_warn_always_enabled"], [255, 5, 1, "", "isclose"], [256, 5, 1, "", "isfinite"], [257, 5, 1, "", "isin"], [258, 5, 1, "", "isinf"], [259, 5, 1, "", "isnan"], [260, 5, 1, "", "isneginf"], [261, 5, 1, "", "isposinf"], [262, 5, 1, "", "isreal"], [263, 5, 1, "", "istft"], [264, 5, 1, "", "kaiser_window"], [265, 5, 1, "", "kron"], [266, 5, 1, "", "kthvalue"], [711, 1, 1, "", "layout"], [267, 5, 1, "", "lcm"], [268, 5, 1, "", "ldexp"], [269, 5, 1, "", "le"], [270, 5, 1, "", "lerp"], [271, 5, 1, "", "less"], [272, 5, 1, "", "less_equal"], [273, 5, 1, "", "lgamma"], [274, 5, 1, "", "linspace"], [275, 5, 1, "", "load"], [276, 5, 1, "", "lobpcg"], [277, 5, 1, "", "log"], [278, 5, 1, "", "log10"], [279, 5, 1, "", "log1p"], [280, 5, 1, "", "log2"], [281, 5, 1, "", "logaddexp"], [282, 5, 1, "", "logaddexp2"], [283, 5, 1, "", "logcumsumexp"], [284, 5, 1, "", "logdet"], [285, 5, 1, "", "logical_and"], [286, 5, 1, "", "logical_not"], [287, 5, 1, "", "logical_or"], [288, 5, 1, "", "logical_xor"], [289, 5, 1, "", "logit"], [290, 5, 1, "", "logspace"], [291, 5, 1, "", "logsumexp"], [292, 5, 1, "", "lt"], [293, 5, 1, "", "lu"], [294, 5, 1, "", "lu_solve"], [295, 5, 1, "", "lu_unpack"], [296, 5, 1, "", "manual_seed"], [297, 5, 1, "", "masked_select"], [298, 5, 1, "", "matmul"], [299, 5, 1, "", "matrix_exp"], [300, 5, 1, "", "matrix_power"], [301, 5, 1, "", "max"], [302, 5, 1, "", "maximum"], [303, 5, 1, "", "mean"], [304, 5, 1, "", "median"], [711, 1, 1, "", "memory_format"], [305, 5, 1, "", "meshgrid"], [306, 5, 1, "", "min"], [307, 5, 1, "", "minimum"], [308, 5, 1, "", "mm"], [309, 5, 1, "", "mode"], [310, 5, 1, "", "moveaxis"], [311, 5, 1, "", "movedim"], [312, 5, 1, "", "msort"], [313, 5, 1, "", "mul"], [314, 5, 1, "", "multinomial"], [315, 5, 1, "", "multiply"], [316, 5, 1, "", "mv"], [317, 5, 1, "", "mvlgamma"], [318, 5, 1, "", "nan_to_num"], [319, 5, 1, "", "nanmean"], [320, 5, 1, "", "nanmedian"], [321, 5, 1, "", "nanquantile"], [322, 5, 1, "", "nansum"], [323, 5, 1, "", "narrow"], [324, 5, 1, "", "narrow_copy"], [325, 5, 1, "", "ne"], [326, 5, 1, "", "neg"], [327, 5, 1, "", "negative"], [328, 5, 1, "", "nextafter"], [707, 0, 0, "-", "nn"], [551, 1, 1, "", "no_grad"], [552, 5, 1, "", "nonzero"], [553, 5, 1, "", "norm"], [554, 5, 1, "", "normal"], [555, 5, 1, "", "not_equal"], [556, 5, 1, "", "numel"], [557, 5, 1, "", "ones"], [558, 5, 1, "", "ones_like"], [559, 5, 1, "", "orgqr"], [560, 5, 1, "", "ormqr"], [561, 5, 1, "", "outer"], [562, 5, 1, "", "pca_lowrank"], [563, 5, 1, "", "permute"], [564, 5, 1, "", "pinverse"], [565, 5, 1, "", "poisson"], [566, 5, 1, "", "polar"], [567, 5, 1, "", "polygamma"], [568, 5, 1, "", "positive"], [569, 5, 1, "", "pow"], [570, 5, 1, "", "prod"], [571, 5, 1, "", "promote_types"], [572, 5, 1, "", "qr"], [573, 5, 1, "", "quantile"], [574, 5, 1, "", "quantize_per_channel"], [575, 5, 1, "", "quantize_per_tensor"], [576, 5, 1, "", "quantized_batch_norm"], [577, 5, 1, "", "quantized_max_pool1d"], [578, 5, 1, "", "quantized_max_pool2d"], [712, 0, 0, "-", "quasirandom"], [580, 5, 1, "", "rad2deg"], [581, 5, 1, "", "rand"], [582, 5, 1, "", "rand_like"], [583, 5, 1, "", "randint"], [584, 5, 1, "", "randint_like"], [585, 5, 1, "", "randn"], [586, 5, 1, "", "randn_like"], [587, 5, 1, "", "randperm"], [588, 5, 1, "", "range"], [589, 5, 1, "", "ravel"], [590, 5, 1, "", "real"], [591, 5, 1, "", "reciprocal"], [592, 5, 1, "", "remainder"], [593, 5, 1, "", "renorm"], [594, 5, 1, "", "repeat_interleave"], [595, 5, 1, "", "reshape"], [596, 5, 1, "", "resolve_conj"], [597, 5, 1, "", "resolve_neg"], [598, 5, 1, "", "result_type"], [712, 0, 0, "-", "return_types"], [599, 5, 1, "", "roll"], [600, 5, 1, "", "rot90"], [601, 5, 1, "", "round"], [602, 5, 1, "", "row_stack"], [603, 5, 1, "", "rsqrt"], [604, 5, 1, "", "save"], [605, 5, 1, "", "scatter"], [606, 5, 1, "", "scatter_add"], [607, 5, 1, "", "scatter_reduce"], [608, 5, 1, "", "searchsorted"], [609, 5, 1, "", "seed"], [610, 5, 1, "", "select"], [611, 5, 1, "", "select_scatter"], [712, 0, 0, "-", "serialization"], [612, 5, 1, "", "set_default_device"], [613, 5, 1, "", "set_default_dtype"], [614, 5, 1, "", "set_default_tensor_type"], [615, 5, 1, "", "set_deterministic_debug_mode"], [616, 5, 1, "", "set_float32_matmul_precision"], [617, 5, 1, "", "set_flush_denormal"], [618, 5, 1, "", "set_num_interop_threads"], [619, 5, 1, "", "set_num_threads"], [620, 5, 1, "", "set_printoptions"], [621, 5, 1, "", "set_rng_state"], [622, 5, 1, "", "set_warn_always"], [623, 5, 1, "", "sgn"], [624, 5, 1, "", "sigmoid"], [625, 5, 1, "", "sign"], [626, 5, 1, "", "signbit"], [627, 5, 1, "", "sin"], [628, 5, 1, "", "sinc"], [629, 5, 1, "", "sinh"], [630, 5, 1, "", "slice_scatter"], [631, 5, 1, "", "slogdet"], [632, 5, 1, "", "softmax"], [633, 5, 1, "", "sort"], [634, 5, 1, "", "sparse_bsc_tensor"], [635, 5, 1, "", "sparse_bsr_tensor"], [636, 5, 1, "", "sparse_coo_tensor"], [637, 5, 1, "", "sparse_csc_tensor"], [638, 5, 1, "", "sparse_csr_tensor"], [639, 5, 1, "", "split"], [640, 5, 1, "", "sqrt"], [641, 5, 1, "", "square"], [642, 5, 1, "", "squeeze"], [643, 5, 1, "", "stack"], [644, 5, 1, "", "std"], [645, 5, 1, "", "std_mean"], [646, 5, 1, "", "stft"], [712, 0, 0, "-", "storage"], [647, 5, 1, "", "sub"], [648, 5, 1, "", "subtract"], [649, 5, 1, "", "sum"], [650, 5, 1, "", "svd"], [651, 5, 1, "", "svd_lowrank"], [652, 5, 1, "", "swapaxes"], [653, 5, 1, "", "swapdims"], [654, 5, 1, "", "sym_float"], [655, 5, 1, "", "sym_int"], [656, 5, 1, "", "sym_ite"], [657, 5, 1, "", "sym_max"], [658, 5, 1, "", "sym_min"], [659, 5, 1, "", "sym_not"], [660, 5, 1, "", "t"], [661, 5, 1, "", "take"], [662, 5, 1, "", "take_along_dim"], [663, 5, 1, "", "tan"], [664, 5, 1, "", "tanh"], [665, 5, 1, "", "tensor"], [666, 5, 1, "", "tensor_split"], [667, 5, 1, "", "tensordot"], [668, 5, 1, "", "tile"], [669, 5, 1, "", "topk"], [712, 0, 0, "-", "torch_version"], [670, 5, 1, "", "trace"], [671, 5, 1, "", "transpose"], [672, 5, 1, "", "trapezoid"], [673, 5, 1, "", "trapz"], [674, 5, 1, "", "triangular_solve"], [675, 5, 1, "", "tril"], [676, 5, 1, "", "tril_indices"], [677, 5, 1, "", "triu"], [678, 5, 1, "", "triu_indices"], [679, 5, 1, "", "true_divide"], [680, 5, 1, "", "trunc"], [712, 0, 0, "-", "types"], [681, 5, 1, "", "unbind"], [682, 5, 1, "", "unflatten"], [683, 5, 1, "", "unique"], [684, 5, 1, "", "unique_consecutive"], [685, 5, 1, "", "unravel_index"], [686, 5, 1, "", "unsqueeze"], [687, 5, 1, "", "use_deterministic_algorithms"], [688, 5, 1, "", "vander"], [689, 5, 1, "", "var"], [690, 5, 1, "", "var_mean"], [691, 5, 1, "", "vdot"], [712, 0, 0, "-", "version"], [692, 5, 1, "", "view_as_complex"], [693, 5, 1, "", "view_as_real"], [694, 5, 1, "", "vmap"], [695, 5, 1, "", "vsplit"], [696, 5, 1, "", "vstack"], [697, 5, 1, "", "where"], [698, 5, 1, "", "xlogy"], [699, 5, 1, "", "zeros"], [700, 5, 1, "", "zeros_like"]], "torch.Event": [[1, 2, 1, "", "elapsed_time"], [1, 2, 1, "", "query"], [1, 2, 1, "", "record"], [1, 2, 1, "", "synchronize"], [1, 2, 1, "", "wait"]], "torch.Generator": [[2, 2, 1, "", "clone_state"], [2, 3, 1, "", "device"], [2, 2, 1, "", "get_state"], [2, 2, 1, "", "graphsafe_get_state"], [2, 2, 1, "", "graphsafe_set_state"], [2, 2, 1, "", "initial_seed"], [2, 2, 1, "", "manual_seed"], [2, 2, 1, "", "seed"], [2, 2, 1, "", "set_state"]], "torch.Stream": [[3, 2, 1, "", "query"], [3, 2, 1, "", "record_event"], [3, 2, 1, "", "synchronize"], [3, 2, 1, "", "wait_event"], [3, 2, 1, "", "wait_stream"]], "torch.SymFloat": [[712, 2, 1, "", "as_integer_ratio"], [712, 2, 1, "", "is_integer"]], "torch.SymInt": [[712, 2, 1, "", "as_integer_ratio"]], "torch.Tag": [[712, 4, 1, "", "name"]], "torch.autograd.grad_mode": [[103, 1, 1, "", "inference_mode"], [104, 1, 1, "", "set_grad_enabled"]], "torch.autograd.grad_mode.inference_mode": [[103, 2, 1, "", "clone"]], "torch.autograd.grad_mode.set_grad_enabled": [[104, 2, 1, "", "clone"]], "torch.nn": [[329, 5, 1, "", "AdaptiveAvgPool1d"], [330, 5, 1, "", "AdaptiveAvgPool2d"], [331, 5, 1, "", "AdaptiveAvgPool3d"], [332, 5, 1, "", "AdaptiveLogSoftmaxWithLoss"], [333, 5, 1, "", "AdaptiveMaxPool1d"], [334, 5, 1, "", "AdaptiveMaxPool2d"], [335, 5, 1, "", "AdaptiveMaxPool3d"], [336, 5, 1, "", "AlphaDropout"], [337, 5, 1, "", "AvgPool1d"], [338, 5, 1, "", "AvgPool2d"], [339, 5, 1, "", "AvgPool3d"], [340, 5, 1, "", "BCELoss"], [341, 5, 1, "", "BCEWithLogitsLoss"], [342, 5, 1, "", "BatchNorm1d"], [343, 5, 1, "", "BatchNorm2d"], [344, 5, 1, "", "BatchNorm3d"], [345, 5, 1, "", "Bilinear"], [346, 5, 1, "", "CELU"], [347, 5, 1, "", "CTCLoss"], [348, 5, 1, "", "ChannelShuffle"], [349, 5, 1, "", "CircularPad1d"], [350, 5, 1, "", "CircularPad2d"], [351, 5, 1, "", "CircularPad3d"], [352, 5, 1, "", "ConstantPad1d"], [353, 5, 1, "", "ConstantPad2d"], [354, 5, 1, "", "ConstantPad3d"], [355, 5, 1, "", "Conv1d"], [356, 5, 1, "", "Conv2d"], [357, 5, 1, "", "Conv3d"], [358, 5, 1, "", "ConvTranspose1d"], [359, 5, 1, "", "ConvTranspose2d"], [360, 5, 1, "", "ConvTranspose3d"], [361, 5, 1, "", "CosineEmbeddingLoss"], [362, 5, 1, "", "CosineSimilarity"], [363, 5, 1, "", "CrossEntropyLoss"], [364, 5, 1, "", "DataParallel"], [365, 5, 1, "", "Dropout"], [366, 5, 1, "", "Dropout1d"], [367, 5, 1, "", "Dropout2d"], [368, 5, 1, "", "Dropout3d"], [369, 5, 1, "", "ELU"], [370, 5, 1, "", "Embedding"], [371, 5, 1, "", "EmbeddingBag"], [372, 5, 1, "", "FeatureAlphaDropout"], [373, 5, 1, "", "Flatten"], [374, 5, 1, "", "Fold"], [375, 5, 1, "", "FractionalMaxPool2d"], [376, 5, 1, "", "FractionalMaxPool3d"], [377, 5, 1, "", "GELU"], [378, 5, 1, "", "GLU"], [379, 5, 1, "", "GRU"], [380, 5, 1, "", "GRUCell"], [381, 5, 1, "", "GaussianNLLLoss"], [382, 5, 1, "", "GroupNorm"], [383, 5, 1, "", "Hardshrink"], [384, 5, 1, "", "Hardsigmoid"], [385, 5, 1, "", "Hardswish"], [386, 5, 1, "", "Hardtanh"], [387, 5, 1, "", "HingeEmbeddingLoss"], [388, 5, 1, "", "HuberLoss"], [389, 5, 1, "", "Identity"], [390, 5, 1, "", "InstanceNorm1d"], [391, 5, 1, "", "InstanceNorm2d"], [392, 5, 1, "", "InstanceNorm3d"], [393, 5, 1, "", "KLDivLoss"], [394, 5, 1, "", "L1Loss"], [395, 5, 1, "", "LPPool1d"], [396, 5, 1, "", "LPPool2d"], [397, 5, 1, "", "LPPool3d"], [398, 5, 1, "", "LSTM"], [399, 5, 1, "", "LSTMCell"], [400, 5, 1, "", "LayerNorm"], [401, 5, 1, "", "LazyBatchNorm1d"], [402, 5, 1, "", "LazyBatchNorm2d"], [403, 5, 1, "", "LazyBatchNorm3d"], [404, 5, 1, "", "LazyConv1d"], [405, 5, 1, "", "LazyConv2d"], [406, 5, 1, "", "LazyConv3d"], [407, 5, 1, "", "LazyConvTranspose1d"], [408, 5, 1, "", "LazyConvTranspose2d"], [409, 5, 1, "", "LazyConvTranspose3d"], [410, 5, 1, "", "LazyInstanceNorm1d"], [411, 5, 1, "", "LazyInstanceNorm2d"], [412, 5, 1, "", "LazyInstanceNorm3d"], [413, 5, 1, "", "LazyLinear"], [414, 5, 1, "", "LeakyReLU"], [415, 5, 1, "", "Linear"], [416, 5, 1, "", "LocalResponseNorm"], [417, 5, 1, "", "LogSigmoid"], [418, 5, 1, "", "LogSoftmax"], [419, 5, 1, "", "MSELoss"], [420, 5, 1, "", "MarginRankingLoss"], [421, 5, 1, "", "MaxPool1d"], [422, 5, 1, "", "MaxPool2d"], [423, 5, 1, "", "MaxPool3d"], [424, 5, 1, "", "MaxUnpool1d"], [425, 5, 1, "", "MaxUnpool2d"], [426, 5, 1, "", "MaxUnpool3d"], [427, 5, 1, "", "Mish"], [428, 5, 1, "", "Module"], [429, 5, 1, "", "ModuleDict"], [430, 5, 1, "", "ModuleList"], [431, 5, 1, "", "MultiLabelMarginLoss"], [432, 5, 1, "", "MultiLabelSoftMarginLoss"], [433, 5, 1, "", "MultiMarginLoss"], [434, 5, 1, "", "MultiheadAttention"], [435, 5, 1, "", "NLLLoss"], [436, 5, 1, "", "PReLU"], [437, 5, 1, "", "PairwiseDistance"], [438, 5, 1, "", "ParameterDict"], [439, 5, 1, "", "ParameterList"], [440, 5, 1, "", "PixelShuffle"], [441, 5, 1, "", "PixelUnshuffle"], [442, 5, 1, "", "PoissonNLLLoss"], [443, 5, 1, "", "RMSNorm"], [444, 5, 1, "", "RNN"], [445, 5, 1, "", "RNNBase"], [446, 5, 1, "", "RNNCell"], [447, 5, 1, "", "RReLU"], [448, 5, 1, "", "ReLU"], [449, 5, 1, "", "ReLU6"], [450, 5, 1, "", "ReflectionPad1d"], [451, 5, 1, "", "ReflectionPad2d"], [452, 5, 1, "", "ReflectionPad3d"], [453, 5, 1, "", "ReplicationPad1d"], [454, 5, 1, "", "ReplicationPad2d"], [455, 5, 1, "", "ReplicationPad3d"], [456, 5, 1, "", "SELU"], [457, 5, 1, "", "Sequential"], [458, 5, 1, "", "SiLU"], [459, 5, 1, "", "Sigmoid"], [460, 5, 1, "", "SmoothL1Loss"], [461, 5, 1, "", "SoftMarginLoss"], [462, 5, 1, "", "Softmax"], [463, 5, 1, "", "Softmax2d"], [464, 5, 1, "", "Softmin"], [465, 5, 1, "", "Softplus"], [466, 5, 1, "", "Softshrink"], [467, 5, 1, "", "Softsign"], [468, 5, 1, "", "SyncBatchNorm"], [469, 5, 1, "", "Tanh"], [470, 5, 1, "", "Tanhshrink"], [471, 5, 1, "", "Threshold"], [472, 5, 1, "", "Transformer"], [473, 5, 1, "", "TransformerDecoder"], [474, 5, 1, "", "TransformerDecoderLayer"], [475, 5, 1, "", "TransformerEncoder"], [476, 5, 1, "", "TransformerEncoderLayer"], [477, 5, 1, "", "TripletMarginLoss"], [478, 5, 1, "", "TripletMarginWithDistanceLoss"], [479, 5, 1, "", "Unflatten"], [480, 5, 1, "", "Unfold"], [481, 5, 1, "", "Upsample"], [482, 5, 1, "", "UpsamplingBilinear2d"], [483, 5, 1, "", "UpsamplingNearest2d"], [484, 5, 1, "", "ZeroPad1d"], [485, 5, 1, "", "ZeroPad2d"], [486, 5, 1, "", "ZeroPad3d"], [707, 0, 0, "-", "backends"], [415, 3, 1, "", "bias"], [446, 3, 1, "", "bias_hh"], [444, 3, 1, "", "bias_hh_l"], [446, 3, 1, "", "bias_ih"], [444, 3, 1, "", "bias_ih_l"], [707, 0, 0, "-", "common_types"], [707, 0, 0, "-", "cpp"], [707, 0, 0, "-", "functional"], [707, 0, 0, "-", "grad"], [707, 0, 0, "-", "init"], [364, 3, 1, "", "module"], [707, 0, 0, "-", "modules"], [707, 0, 0, "-", "parallel"], [707, 0, 0, "-", "parameter"], [707, 0, 0, "-", "utils"], [436, 3, 1, "", "weight"], [446, 3, 1, "", "weight_hh"], [444, 3, 1, "", "weight_hh_l"], [398, 3, 1, "", "weight_hr_l"], [446, 3, 1, "", "weight_ih"], [444, 3, 1, "", "weight_ih_l"]], "torch.nn.backends": [[707, 0, 0, "-", "thnn"]], "torch.nn.modules": [[707, 0, 0, "-", "activation"], [707, 0, 0, "-", "adaptive"], [707, 0, 0, "-", "batchnorm"], [707, 0, 0, "-", "channelshuffle"], [707, 0, 0, "-", "container"], [707, 0, 0, "-", "conv"], [707, 0, 0, "-", "distance"], [707, 0, 0, "-", "dropout"], [707, 0, 0, "-", "flatten"], [707, 0, 0, "-", "fold"], [707, 0, 0, "-", "instancenorm"], [707, 0, 0, "-", "lazy"], [707, 0, 0, "-", "linear"], [707, 0, 0, "-", "loss"], [707, 0, 0, "-", "module"], [707, 0, 0, "-", "normalization"], [707, 0, 0, "-", "padding"], [707, 0, 0, "-", "pixelshuffle"], [707, 0, 0, "-", "pooling"], [707, 0, 0, "-", "rnn"], [707, 0, 0, "-", "sparse"], [707, 0, 0, "-", "transformer"], [707, 0, 0, "-", "upsampling"], [707, 0, 0, "-", "utils"]], "torch.nn.modules.lazy": [[487, 5, 1, "", "LazyModuleMixin"]], "torch.nn.modules.module": [[488, 5, 1, "", "register_module_backward_hook"], [489, 5, 1, "", "register_module_buffer_registration_hook"], [490, 5, 1, "", "register_module_forward_hook"], [491, 5, 1, "", "register_module_forward_pre_hook"], [492, 5, 1, "", "register_module_full_backward_hook"], [493, 5, 1, "", "register_module_full_backward_pre_hook"], [494, 5, 1, "", "register_module_module_registration_hook"], [495, 5, 1, "", "register_module_parameter_registration_hook"]], "torch.nn.modules.normalization": [[496, 5, 1, "", "RMSNorm"]], "torch.nn.parallel": [[497, 5, 1, "", "DistributedDataParallel"], [707, 0, 0, "-", "comm"], [707, 0, 0, "-", "distributed"], [497, 3, 1, "", "module"], [707, 0, 0, "-", "parallel_apply"], [707, 0, 0, "-", "replicate"], [707, 0, 0, "-", "scatter_gather"]], "torch.nn.parameter": [[498, 5, 1, "", "Buffer"], [499, 5, 1, "", "Parameter"], [500, 5, 1, "", "UninitializedBuffer"], [501, 5, 1, "", "UninitializedParameter"]], "torch.nn.utils": [[707, 0, 0, "-", "clip_grad"], [502, 5, 1, "", "clip_grad_norm"], [503, 5, 1, "", "clip_grad_norm_"], [504, 5, 1, "", "clip_grad_value_"], [505, 5, 1, "", "convert_conv2d_weight_memory_format"], [506, 5, 1, "", "convert_conv3d_weight_memory_format"], [707, 0, 0, "-", "convert_parameters"], [507, 5, 1, "", "fuse_conv_bn_eval"], [508, 5, 1, "", "fuse_conv_bn_weights"], [509, 5, 1, "", "fuse_linear_bn_eval"], [510, 5, 1, "", "fuse_linear_bn_weights"], [707, 0, 0, "-", "fusion"], [707, 0, 0, "-", "init"], [707, 0, 0, "-", "memory_format"], [511, 5, 1, "", "parameters_to_vector"], [707, 0, 0, "-", "parametrizations"], [707, 0, 0, "-", "parametrize"], [707, 0, 0, "-", "prune"], [537, 5, 1, "", "remove_spectral_norm"], [538, 5, 1, "", "remove_weight_norm"], [707, 0, 0, "-", "rnn"], [546, 5, 1, "", "skip_init"], [547, 5, 1, "", "spectral_norm"], [707, 0, 0, "-", "stateless"], [549, 5, 1, "", "vector_to_parameters"], [550, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrizations": [[512, 5, 1, "", "orthogonal"], [513, 5, 1, "", "spectral_norm"], [514, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrize": [[515, 5, 1, "", "ParametrizationList"], [516, 5, 1, "", "cached"], [517, 5, 1, "", "is_parametrized"], [518, 5, 1, "", "register_parametrization"], [519, 5, 1, "", "remove_parametrizations"]], "torch.nn.utils.prune": [[520, 1, 1, "", "BasePruningMethod"], [521, 1, 1, "", "CustomFromMask"], [522, 1, 1, "", "Identity"], [523, 1, 1, "", "L1Unstructured"], [524, 1, 1, "", "LnStructured"], [525, 1, 1, "", "PruningContainer"], [526, 1, 1, "", "RandomStructured"], [527, 1, 1, "", "RandomUnstructured"], [528, 5, 1, "", "custom_from_mask"], [529, 5, 1, "", "global_unstructured"], [530, 5, 1, "", "identity"], [531, 5, 1, "", "is_pruned"], [532, 5, 1, "", "l1_unstructured"], [533, 5, 1, "", "ln_structured"], [534, 5, 1, "", "random_structured"], [535, 5, 1, "", "random_unstructured"], [536, 5, 1, "", "remove"]], "torch.nn.utils.prune.BasePruningMethod": [[520, 2, 1, "", "apply"], [520, 2, 1, "", "apply_mask"], [520, 2, 1, "", "compute_mask"], [520, 2, 1, "", "prune"], [520, 2, 1, "", "remove"]], "torch.nn.utils.prune.CustomFromMask": [[521, 2, 1, "", "apply"], [521, 2, 1, "", "apply_mask"], [521, 2, 1, "", "prune"], [521, 2, 1, "", "remove"]], "torch.nn.utils.prune.Identity": [[522, 2, 1, "", "apply"], [522, 2, 1, "", "apply_mask"], [522, 2, 1, "", "prune"], [522, 2, 1, "", "remove"]], "torch.nn.utils.prune.L1Unstructured": [[523, 2, 1, "", "apply"], [523, 2, 1, "", "apply_mask"], [523, 2, 1, "", "prune"], [523, 2, 1, "", "remove"]], "torch.nn.utils.prune.LnStructured": [[524, 2, 1, "", "apply"], [524, 2, 1, "", "apply_mask"], [524, 2, 1, "", "compute_mask"], [524, 2, 1, "", "prune"], [524, 2, 1, "", "remove"]], "torch.nn.utils.prune.PruningContainer": [[525, 2, 1, "", "add_pruning_method"], [525, 2, 1, "", "apply"], [525, 2, 1, "", "apply_mask"], [525, 2, 1, "", "compute_mask"], [525, 2, 1, "", "prune"], [525, 2, 1, "", "remove"]], "torch.nn.utils.prune.RandomStructured": [[526, 2, 1, "", "apply"], [526, 2, 1, "", "apply_mask"], [526, 2, 1, "", "compute_mask"], [526, 2, 1, "", "prune"], [526, 2, 1, "", "remove"]], "torch.nn.utils.prune.RandomUnstructured": [[527, 2, 1, "", "apply"], [527, 2, 1, "", "apply_mask"], [527, 2, 1, "", "prune"], [527, 2, 1, "", "remove"]], "torch.nn.utils.rnn": [[539, 1, 1, "", "PackedSequence"], [540, 5, 1, "", "pack_padded_sequence"], [541, 5, 1, "", "pack_sequence"], [542, 5, 1, "", "pad_packed_sequence"], [543, 5, 1, "", "pad_sequence"], [544, 5, 1, "", "unpack_sequence"], [545, 5, 1, "", "unpad_sequence"]], "torch.nn.utils.rnn.PackedSequence": [[539, 3, 1, "id0", "batch_sizes"], [539, 2, 1, "", "count"], [539, 3, 1, "id1", "data"], [539, 2, 1, "", "index"], [539, 4, 1, "", "is_cuda"], [539, 2, 1, "", "is_pinned"], [539, 3, 1, "id2", "sorted_indices"], [539, 2, 1, "", "to"], [539, 3, 1, "id3", "unsorted_indices"]], "torch.nn.utils.stateless": [[548, 5, 1, "", "functional_call"]], "torch.quasirandom": [[579, 5, 1, "", "SobolEngine"]], "torch.signal.windows": [[712, 0, 0, "-", "windows"]], "torch.sparse": [[712, 0, 0, "-", "semi_structured"]], "torch.torch": [[712, 3, 1, "", "default_generator"]], "torch.utils": [[712, 0, 0, "-", "backcompat"], [712, 0, 0, "-", "hipify"], [712, 0, 0, "-", "model_dump"], [712, 0, 0, "-", "viz"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:property", "5": "py:function"}, "terms": {"": [1, 2, 4, 68, 72, 73, 74, 75, 78, 89, 91, 92, 93, 94, 121, 123, 136, 142, 143, 144, 145, 150, 165, 168, 170, 171, 173, 187, 188, 190, 191, 192, 193, 194, 197, 198, 199, 205, 206, 211, 221, 229, 230, 231, 253, 255, 263, 275, 276, 291, 298, 303, 305, 308, 310, 311, 318, 319, 322, 324, 330, 331, 332, 340, 341, 342, 343, 344, 347, 364, 370, 381, 429, 438, 457, 460, 462, 468, 474, 476, 482, 483, 487, 497, 498, 499, 505, 506, 518, 529, 542, 546, 553, 554, 560, 562, 566, 573, 588, 591, 592, 595, 596, 597, 599, 601, 608, 615, 616, 634, 635, 636, 637, 638, 642, 644, 645, 646, 649, 650, 651, 652, 653, 662, 666, 668, 674, 689, 690, 691, 694, 695, 704, 706, 710, 711, 712], "0": [3, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 121, 124, 125, 126, 127, 128, 129, 131, 132, 135, 140, 141, 142, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 173, 175, 176, 183, 186, 187, 188, 190, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 216, 221, 225, 227, 228, 229, 230, 231, 233, 237, 241, 243, 251, 262, 263, 264, 265, 266, 267, 268, 270, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 290, 293, 297, 301, 302, 303, 304, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 318, 319, 320, 321, 322, 323, 324, 326, 328, 330, 331, 332, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 379, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 416, 418, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 442, 443, 444, 445, 447, 448, 449, 450, 451, 452, 453, 454, 456, 460, 462, 463, 464, 465, 466, 468, 471, 472, 474, 476, 477, 478, 480, 481, 484, 485, 486, 487, 496, 497, 502, 503, 505, 506, 512, 513, 514, 518, 523, 524, 526, 527, 528, 529, 531, 532, 533, 534, 535, 536, 539, 540, 542, 543, 545, 546, 547, 548, 550, 552, 553, 554, 558, 563, 565, 566, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 579, 581, 582, 583, 584, 585, 586, 587, 588, 590, 591, 592, 593, 594, 595, 598, 599, 600, 601, 603, 604, 608, 610, 611, 612, 615, 617, 620, 623, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 649, 650, 651, 652, 653, 660, 661, 663, 664, 665, 666, 667, 671, 672, 674, 675, 676, 677, 678, 680, 681, 683, 684, 685, 686, 688, 689, 690, 692, 693, 694, 695, 697, 699, 700, 703, 704, 710, 711, 712], "00": [176, 194, 281, 290, 318, 546], "0000": [79, 108, 128, 132, 146, 154, 160, 161, 162, 187, 188, 199, 200, 201, 221, 227, 230, 233, 270, 273, 274, 290, 319, 370, 371, 481, 482, 484, 485, 553, 566, 572, 577, 578, 579, 588, 592, 593, 617, 623, 625, 674, 675, 677, 697], "00000e": 294, "00001": 576, "0000e": [176, 194, 281, 290, 318, 546], "0000j": [566, 623], "0001": [154, 416], "0006": 154, "0009": 241, "001": 703, "0014": 154, "0019": 487, "0026": 145, "0028": [645, 671], "0036": 301, "0042": 280, "0042e": 487, "0044": 371, "0049": 677, "0053": 74, "0056": 690, "0059": 145, "0061": 633, "0062": 154, "0065": 154, "0069": 641, "0081": 513, "0085": 313, "0090": [279, 326, 568], "01": [174, 194, 414, 487, 574], "0100": [89, 574], "0102": 89, "0111": 168, "0112": 640, "0128": 306, "0131": 303, "0133": 148, "0139": 297, "0157": 154, "0158": [154, 650], "0163": 303, "0164": 74, "0187": 667, "0196": [98, 125], "0199": 650, "0202": 64, "0210": 674, "0213": 89, "0225": 151, "0226": [640, 641], "0231": 241, "0233": [154, 580], "0238": 154, "0243": 674, "0249": [145, 279], "0250": 96, "0251": 370, "0255": [150, 160], "0257": 151, "0284": 312, "0287": 650, "0289": [107, 675], "0290": 278, "03": [128, 281], "0309": 370, "0311": 644, "0313": 168, "0315": 650, "0318": 74, "0343": 572, "0356": 173, "0360": [163, 313], "0362": 65, "0364": 370, "0367": 313, "0370": 603, "0382": 313, "0383": 697, "0384": 306, "0387": 243, "04": [194, 281], "0400": 481, "0401": 163, "0404": 316, "0425": 554, "0428": 66, "0430": 66, "0432": 677, "0436": 304, "0438": 304, "04462666": 283, "044715": 377, "0457": 641, "0466": 187, "0475": 187, "0478": [132, 697], "04805": 475, "0486": 187, "0490": 280, "0491": [352, 484], "05": [73, 187, 255, 290, 342, 343, 344, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 468, 472, 474, 476, 497], "0500": 163, "0503": 65, "0504": 650, "0505": 554, "0507": 74, "0507009873554804934193349852946": 456, "0511": 167, "05201": 448, "0521": 151, "0523": 371, "0527": 312, "05277811": 283, "0542": 187, "0551": 151, "0552": 188, "0563": 554, "0564": 173, "0566": 554, "0569": 649, "0584": 650, "059": 125, "0590": 125, "0592": 128, "0593": 291, "06": [381, 437, 477, 480, 650], "0608": [297, 633], "06084887": 283, "0614": 675, "0629": 570, "0631": 689, "0633": 237, "0633j": [237, 590], "0635": 370, "06376": 616, "0638": [237, 590], "0645": [645, 690], "0665": [645, 690], "0669": 90, "0679": [487, 677], "0680": 677, "0682": [326, 568], "06844475": 283, "0685": 152, "0687": 554, "0691": 88, "07": [73, 128, 176, 291, 294, 512, 650], "0700": 313, "0704": 667, "0705": 570, "0705e": 176, "0722": 90, "0732": [554, 667], "0736": 64, "0737": 649, "0742": 145, "0745": 90, "0748": 370, "0749": [352, 484], "0753": 674, "0755": [640, 641], "0760": 308, "0778": 304, "0779": [569, 697], "0780": 188, "0785": 90, "0786": 692, "07868": [514, 550], "0788": 90, "0794": 677, "0795": [92, 573], "08": [73, 115, 255, 362, 442], "0811": 98, "0813": 675, "0816": [74, 293], "0821": 570, "0831": [640, 641], "0842": 303, "0844": 151, "0845": [161, 629], "0854": 163, "0857": [306, 677], "0872": 160, "0874": 243, "0881": 312, "0887": 284, "0889": 129, "0899": 96, "09": [73, 706], "0900": 126, "0905": 163, "0907": 487, "0908": 146, "0909": [562, 651], "0921": 173, "0922": 132, "0923": 585, "0935": 675, "0936": 173, "0943": 65, "0950": 107, "0957": 645, "0959": 125, "0960": 633, "0967": 167, "0969": 124, "0975": 153, "0978": 675, "0985": 64, "0992": 74, "0994": 64, "0998": 581, "0d": [305, 420], "0j": [262, 691], "0th": 694, "0x": 275, "0x8000_0000_0000_0000": [2, 296], "0xffff_ffff_ffff_ffff": [2, 296], "1": [60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 176, 177, 178, 179, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 208, 209, 210, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 237, 238, 241, 243, 251, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 274, 275, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 297, 298, 301, 302, 303, 304, 305, 306, 307, 309, 310, 311, 312, 313, 314, 316, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 369, 370, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 384, 386, 387, 388, 389, 390, 391, 392, 393, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 428, 431, 432, 433, 434, 435, 436, 437, 440, 441, 442, 443, 444, 445, 446, 447, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 471, 472, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 497, 505, 506, 512, 513, 514, 518, 523, 524, 526, 527, 528, 529, 530, 532, 533, 534, 535, 539, 540, 541, 542, 544, 545, 546, 547, 548, 550, 551, 552, 553, 554, 556, 557, 558, 560, 561, 562, 563, 565, 566, 569, 570, 572, 573, 574, 575, 576, 577, 578, 580, 581, 582, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 603, 604, 608, 611, 612, 613, 614, 615, 617, 620, 623, 625, 626, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 703, 704, 710, 711, 712, 713], "10": [64, 65, 76, 105, 117, 127, 130, 131, 135, 142, 150, 152, 153, 154, 155, 156, 171, 173, 194, 202, 203, 209, 221, 231, 255, 267, 270, 274, 276, 278, 283, 285, 286, 287, 288, 290, 298, 314, 330, 331, 332, 334, 335, 341, 344, 347, 348, 354, 357, 360, 370, 371, 379, 380, 381, 382, 392, 398, 399, 400, 425, 429, 430, 435, 438, 439, 444, 446, 468, 472, 473, 474, 475, 476, 480, 486, 487, 505, 506, 529, 537, 551, 554, 574, 575, 583, 608, 616, 620, 633, 639, 650, 651, 662, 666, 667, 670, 672, 685, 687, 695, 703, 704, 711], "100": [228, 274, 281, 290, 305, 313, 332, 340, 341, 342, 343, 344, 356, 357, 359, 360, 362, 363, 390, 391, 392, 435, 437, 468, 477, 574, 685], "1000": [188, 197, 198, 332, 478, 574, 601, 620, 665], "10000": [73, 601], "1000e": 194, "1001": 332, "1002": 332, "1003": 649, "101": 332, "1015": 163, "1019": 313, "102": 332, "1029": 160, "102999": 550, "1030": 66, "1034": [124, 173], "1054": 145, "1062": 168, "1064": 160, "1065": 163, "1068": [168, 241], "1088": 487, "1089": 697, "1091": 487, "10x": [616, 651], "10x7": [330, 334], "11": [127, 131, 171, 231, 265, 274, 290, 332, 348, 376, 425, 553, 554, 633, 666, 695], "1106": 74, "1109": [65, 381], "1111": 665, "11111": 665, "1119": 127, "1127": 301, "1128": [145, 398], "1131": [173, 570], "1132": 649, "1133": 649, "1135": 290, "1137": 276, "1139": 89, "1151": 370, "1153": 306, "1156": 173, "1177": 554, "1182": [352, 484], "1183": 173, "1193": [125, 293], "12": [65, 127, 131, 171, 231, 264, 332, 348, 359, 374, 375, 376, 425, 440, 441, 463, 472, 480, 513, 547, 561, 572, 620, 633, 666, 682, 685, 695, 704], "120": 556, "1200": [481, 601], "1207": [89, 313], "1208": 273, "1210e": 546, "1216": 313, "1219": 591, "1222": 301, "1228": 241, "1229": 643, "1230": 601, "1234": [243, 685], "12345": 620, "1234567": 601, "1235": 620, "1239e": 176, "1241": 154, "1243": 675, "1244": 297, "125": [447, 688], "1250": 312, "1255": [352, 484], "1259": 312, "1264": [644, 645, 689, 690], "1265": 629, "1268": 629, "1269e": 281, "1271": 173, "128": [345, 362, 389, 415, 437, 477, 478, 703, 711], "1288": 643, "1289": 312, "1294": 128, "1297": 301, "13": [89, 131, 155, 171, 174, 196, 221, 231, 293, 348, 375, 376, 425, 463, 633, 666, 695], "1301": 278, "1306": 371, "1307": 297, "1312": 66, "1320": 487, "1321": 312, "1322": 168, "1334": 306, "1335": 649, "1336": 284, "1339": 151, "1341": 63, "1343": 627, "1347": 627, "135": 77, "1363": 313, "1374": 160, "1380": 675, "1381": [89, 649], "1392": 278, "1395": 147, "1398": [310, 311], "13x12": 375, "13x12x11": 376, "14": [130, 156, 171, 231, 318, 348, 425, 572, 579, 616, 633, 666, 667, 672, 695, 704], "1400e": 318, "1402": 398, "1408": 554, "1412": 129, "1414": 650, "14159": [77, 665], "141592": 206, "1416": [157, 206, 665], "142": 580, "1427": 241, "1428e": 174, "1431": 163, "1436": 585, "1438": 89, "1450": 64, "1455": 151, "1458": 306, "1466": [352, 484], "1479": 151, "1494": 313, "1497": 124, "15": [155, 171, 209, 221, 231, 267, 348, 425, 426, 543, 545, 564, 633, 670, 695], "1502": 675, "1506": 243, "1516": 162, "1516516984916": 2, "1527": 674, "1534": 96, "1535": [146, 370], "1551": 293, "1552": 554, "1560": 243, "1567": 313, "1584": 62, "1586": 92, "1598": 90, "1598e": 487, "1599": 96, "16": [171, 194, 221, 231, 268, 324, 336, 338, 339, 347, 348, 351, 354, 355, 356, 357, 359, 360, 365, 366, 367, 368, 372, 375, 376, 395, 396, 397, 416, 421, 422, 423, 425, 426, 435, 455, 472, 486, 556, 569, 616, 633, 687, 691, 695, 711], "160": 373, "1602": [514, 550], "1603": 448, "1606": 96, "1610": 64, "1614": 313, "1625": 130, "1626": [130, 151], "1632": 148, "1645": 313, "1646": 570, "1653": 65, "1655": 370, "1657": 697, "1669": 671, "167": 572, "1678": 485, "1684": 293, "1685": 370, "1695": 162, "17": [64, 263, 348, 425, 633], "1706": 152, "1707": 573, "1713": 173, "1714": 572, "1719": 585, "1724": 243, "1727": [310, 311], "1734": [132, 241], "1737": 107, "1745": 664, "1748": 243, "175": 572, "1751": 145, "1752": 163, "1762": 153, "1763": [125, 591], "1768": 677, "1774": 243, "1775": 74, "1782": 243, "1784": 243, "1788": 161, "1795": 487, "17m1129830": 276, "18": [64, 174, 221, 263, 276, 425], "180": [77, 157, 580], "1807": 303, "1810": 475, "1815": [168, 284], "1830": 168, "1831": 570, "1835": 148, "1836": 151, "1857": 570, "1863": 643, "1868": 64, "1871": 99, "1875": 569, "1893": 99, "1899": 306, "19": [64, 130, 425], "1904": 616, "1908": 168, "1909": 92, "1919": 154, "1936": 88, "1939": 92, "1940": 293, "1946": 650, "1949": 301, "1952": 277, "1967": 579, "1968": 154, "1975": 89, "1984": 263, "1990": 284, "1992": [644, 645, 689, 690], "1994": 381, "1995": 660, "1996": 585, "1998": 579, "1d": [136, 146, 150, 156, 170, 229, 230, 243, 263, 305, 321, 329, 333, 337, 347, 355, 358, 363, 366, 367, 395, 420, 421, 433, 435, 481, 573, 574, 577, 646, 662, 672, 691, 704, 710], "1e": [73, 128, 129, 130, 255, 342, 343, 344, 362, 381, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 414, 437, 442, 468, 472, 474, 476, 477, 513, 547, 564, 617], "1j": [77, 143, 144, 262, 596, 597, 691], "1st": 704, "1x": 704, "2": [60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 88, 89, 90, 91, 92, 93, 94, 98, 100, 101, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 135, 136, 139, 143, 144, 145, 146, 149, 150, 151, 152, 156, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 183, 186, 187, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 241, 243, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 273, 274, 275, 276, 280, 281, 282, 283, 290, 292, 293, 294, 295, 297, 298, 301, 302, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 318, 319, 320, 321, 322, 323, 324, 325, 328, 331, 336, 337, 338, 339, 340, 341, 346, 347, 348, 349, 350, 352, 353, 355, 356, 357, 358, 359, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 383, 384, 385, 386, 388, 395, 396, 397, 398, 399, 400, 414, 416, 417, 418, 419, 421, 422, 423, 424, 425, 426, 427, 430, 431, 433, 436, 437, 439, 440, 441, 442, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 456, 458, 459, 460, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 477, 479, 480, 481, 482, 483, 484, 485, 487, 496, 497, 502, 503, 505, 506, 512, 513, 518, 530, 531, 532, 533, 535, 536, 539, 541, 542, 544, 545, 546, 547, 548, 551, 552, 553, 554, 556, 557, 558, 561, 562, 563, 565, 566, 569, 570, 572, 573, 574, 575, 576, 577, 578, 581, 583, 585, 587, 588, 589, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 604, 608, 610, 611, 613, 614, 615, 616, 620, 625, 626, 627, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 649, 650, 651, 652, 653, 660, 661, 663, 665, 666, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 678, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 704, 710, 711, 712, 713], "20": [64, 155, 221, 267, 313, 336, 338, 339, 341, 342, 343, 344, 345, 347, 354, 355, 356, 357, 359, 360, 365, 366, 367, 368, 372, 375, 376, 379, 380, 382, 389, 390, 391, 392, 395, 396, 397, 398, 399, 400, 415, 421, 422, 423, 425, 426, 428, 444, 446, 457, 465, 468, 471, 472, 473, 474, 486, 512, 513, 514, 538, 547, 550, 575, 662], "200": [281, 574], "2000": [200, 281, 481, 576, 625, 665], "2001": 276, "2002": 276, "2004": 62, "2005": [62, 690], "2009": [562, 651], "2015": 313, "2016": [440, 441, 478], "2017": [472, 474, 476], "2018": [276, 570], "2020": 706, "2023": 173, "2027": 663, "2035": [297, 644, 645, 689, 690], "2046": 145, "2048": [472, 474, 476], "2069": 154, "2072": 677, "2086": 168, "2091": 195, "2094": 162, "2098": 693, "21": [64, 127, 156, 572, 672], "2104": 173, "2112": [173, 675], "2117": 573, "21201": 579, "2122": 129, "2129": 154, "2134": 554, "2145": 371, "2147483647": 2, "2156": 277, "2159": 151, "2162": 633, "2165": 276, "2168": [187, 667], "2182": 276, "2192": 304, "22": [276, 487, 543, 545], "2202": 304, "2204": 644, "2208": 90, "2219": 675, "2222": 665, "222222": 665, "2225": 279, "2235": [163, 649], "2239": 173, "224": 703, "2250": 553, "2251": [129, 151, 278], "2252": 297, "2254": 89, "2259": 152, "2260": 168, "2262": [326, 568], "2267": 243, "2270": 304, "2275": 312, "2278": 168, "2284": [127, 153], "2291": 243, "2294": [62, 303], "2299": 97, "23": [155, 276, 616], "2301": 487, "2303": [554, 643], "2308": 168, "2309": 677, "2310": 641, "2312": 66, "2318": 90, "2329": 151, "2335": 163, "2341": 97, "2343": 303, "2344": 168, "2345": [643, 675], "2350": 146, "2354": 173, "236": 263, "2360": 301, "2361": [553, 554], "2364": 650, "2369": 301, "2373": 145, "2379": 301, "2382": 313, "2387": [130, 146], "24": [110, 416, 546, 572, 616, 667], "2400": [481, 667], "2405": 173, "2411": 277, "2426": 553, "2429": 160, "243": [263, 650], "2432": 301, "2433": 173, "2445": 650, "2447": 677, "2450": 88, "2457": [127, 306], "2469": 243, "2475": [569, 649], "2476": 243, "2479": 487, "2481": 650, "2483": 280, "2487": 97, "2488": 304, "2491": 74, "2492": 279, "2498": 570, "24gb": 704, "24j": 623, "25": [125, 229, 276, 373, 431, 433, 436, 487, 497, 543, 545, 573, 688], "2500": [108, 274, 481, 579], "2500e": 194, "2503": 581, "2505": 304, "2521": 675, "2525": 187, "2526": 293, "2530": 195, "2536": 148, "2539": 97, "2544": 675, "255": [187, 188, 205], "2553": 664, "2557": 145, "256": [347, 569], "2561": 127, "2564": 90, "2573": 667, "2589": 290, "2594": 650, "260": 313, "2600": 145, "2604": 677, "2611": [284, 664], "2614": 127, "2618": 650, "2620": 645, "2631": [163, 312], "2634": 293, "2635": 306, "2639": 168, "2647": 241, "2663": 88, "2676": 107, "2678": [146, 370], "2680": 153, "2685": 173, "2686": 88, "27": [569, 688], "2700": 90, "2706": 147, "2711": 627, "2713": 75, "2716": 675, "2717": 650, "2741": 667, "2746": 627, "2751": 304, "2771": [352, 484], "2774": 168, "2778": 145, "2780": 146, "2791": 569, "2793": [487, 554], "28": [156, 672], "2800": [481, 623], "2803": 306, "2805": 148, "2807": 487, "2816": 127, "2820": 278, "2826": 674, "283": 580, "2830": [125, 677], "2832": 157, "2850": 667, "2851": 487, "2857": 572, "2866": [326, 568], "2883": 640, "2890": 650, "2897": 173, "2899": 99, "29": 546, "2907": 243, "2917": 168, "2919": 677, "2922": 667, "2925": 554, "2930": 168, "2934": 161, "2938": 487, "2942": 301, "2951": 303, "2956": 162, "2957": 147, "2958": 649, "2959": [644, 645, 689, 690], "2960": 89, "2962": 570, "2968": 99, "2970": 603, "2972": 168, "2979": 63, "2980": 75, "2987": 75, "2993": [88, 649], "2995": 75, "2998": 145, "2b": 704, "2d": [146, 150, 161, 173, 330, 334, 338, 341, 342, 343, 356, 359, 363, 367, 371, 375, 390, 391, 396, 422, 431, 433, 435, 481, 482, 483, 513, 547, 578, 636, 674], "2j": [77, 143, 144, 596, 597, 623, 691], "2n": 106, "2nd": [436, 463], "2x": 704, "2x3": 480, "3": [60, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 79, 89, 90, 92, 93, 94, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 135, 136, 139, 143, 144, 149, 150, 151, 155, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 186, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 208, 209, 210, 221, 224, 227, 228, 229, 230, 231, 232, 233, 241, 243, 251, 253, 255, 257, 265, 266, 267, 268, 269, 270, 274, 275, 281, 284, 286, 290, 291, 292, 293, 294, 295, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 318, 319, 320, 322, 323, 324, 325, 337, 338, 339, 340, 341, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 363, 370, 371, 374, 375, 376, 377, 379, 380, 382, 384, 385, 393, 394, 395, 396, 397, 398, 399, 400, 418, 419, 420, 421, 422, 423, 424, 425, 426, 429, 431, 433, 435, 440, 441, 443, 444, 446, 447, 450, 451, 452, 453, 454, 455, 462, 463, 464, 468, 476, 480, 481, 482, 483, 484, 485, 486, 496, 497, 505, 506, 513, 528, 530, 532, 533, 534, 535, 539, 541, 542, 543, 544, 547, 551, 552, 553, 554, 556, 557, 558, 561, 563, 565, 569, 570, 572, 573, 576, 577, 578, 579, 580, 581, 583, 585, 587, 588, 589, 592, 593, 594, 595, 596, 597, 599, 600, 601, 604, 608, 613, 614, 620, 623, 625, 626, 633, 634, 635, 636, 637, 638, 639, 642, 643, 649, 650, 652, 653, 660, 661, 665, 666, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 691, 694, 695, 696, 697, 699, 700, 703, 704, 710, 711, 712], "30": [221, 267, 345, 347, 354, 415, 480, 486, 487, 575, 662, 704], "300": [281, 341, 543, 545], "3000": [198, 625], "30000": 281, "3018": 162, "3031": 284, "3037": 151, "3060": 99, "3069": 281, "3077": [312, 641], "3081": 163, "31": [113, 339, 397, 423, 487], "3100": [237, 590], "3107": 173, "3108": [98, 125], "3120": [63, 145], "3126": 667, "3131": 304, "3132": 88, "3135": 649, "3136": 693, "3136j": 693, "3137": 313, "3139": 697, "3146": 677, "3161": 667, "3164": 675, "3180": 304, "3190": 145, "3192": 63, "3195": 88, "32": [2, 205, 263, 293, 338, 366, 367, 368, 372, 373, 375, 376, 396, 416, 422, 433, 472, 473, 474, 475, 476, 711], "320": [351, 455], "3204": 667, "3213": [127, 280], "3216": 64, "323": 617, "3234": 277, "324": 617, "3242": 284, "3261": 243, "3270": [644, 645, 689, 690], "3279": 243, "3284": 152, "3285": 293, "3287": [352, 484], "3288": 303, "3289": 650, "3298": [153, 160], "33": [155, 355, 356, 357, 359, 360, 426], "3311": 173, "3312": 75, "3314": 572, "3321": 304, "3330": [644, 645, 689, 690], "3332": 633, "3333": [132, 221, 230, 481, 482, 665], "3333333": 665, "3333333333333333": 447, "3337": 677, "3343": 633, "3348": 62, "3350": 303, "3362": [310, 311], "3366": 663, "3367": [303, 643], "3371": 650, "3375": 127, "3378": [127, 677], "3398": 88, "34": 685, "3402": 88, "3405": 187, "3409": 675, "3426": 585, "3429": 649, "3430": [173, 284], "3448": 370, "3449": 152, "3459": 293, "3460": 173, "3461": 675, "3470": 693, "3477": 297, "3480": 677, "3484": 168, "3491": 187, "3493e": 174, "3497": 64, "35": [343, 344, 391, 392, 468, 572], "3504": [280, 667], "3506": [64, 293], "3513": 674, "3518": 304, "3525": 581, "3544": 128, "3550": 650, "3552": 297, "3553": 237, "3553j": [237, 590], "3567": 243, "3582": 146, "359": 580, "3599": 151, "36": [194, 221], "360": 157, "3600": 481, "3607": 243, "3609": 107, "3615": 675, "3616": 370, "3623": 303, "3633": 308, "3637": 649, "3646": 690, "3651": 306, "3657": 243, "3666": 243, "3667": [64, 145], "3672": [64, 151], "3677": 370, "3679": 650, "3687": 89, "3690": 62, "3691": 65, "3701": 243, "3702": [125, 591], "3708": 649, "3711": 168, "3719": 168, "3726": 151, "3728": 173, "3735": 163, "3738": 74, "374138": 381, "3743": 64, "3744": 173, "3746": 68, "3755": 163, "3766": 146, "3768": 69, "3771": 130, "3791": 125, "38": 318, "3810": [168, 229], "3816": 581, "3825": 297, "3836": 163, "3837": [487, 570], "3839": [173, 693], "3839j": 693, "3841": 303, "3842e": 128, "3856": 663, "3885": 153, "3898": 697, "3904": 151, "3917": 243, "3918": 173, "39202815": 283, "3925": 64, "3930": 64, "3938": [168, 660], "3940": [326, 568], "3943": 572, "3944": 64, "3948": [88, 145], "3956": 151, "3973": 188, "3982": 304, "3986": 161, "3987": 554, "3d": [305, 331, 335, 339, 342, 344, 357, 360, 367, 368, 374, 376, 390, 392, 397, 423, 434, 481], "3j": [77, 143, 144, 596, 597, 613], "3x3": [156, 672], "3x4": 480, "4": [62, 63, 64, 65, 68, 70, 71, 72, 74, 75, 76, 78, 79, 88, 89, 90, 94, 95, 96, 97, 98, 99, 101, 102, 105, 108, 111, 115, 116, 117, 121, 123, 126, 127, 130, 131, 132, 135, 139, 142, 145, 146, 147, 148, 151, 153, 156, 163, 165, 167, 168, 171, 172, 173, 176, 178, 188, 190, 191, 192, 193, 194, 195, 196, 199, 201, 202, 205, 208, 209, 210, 221, 224, 228, 229, 230, 231, 232, 233, 237, 241, 243, 255, 257, 263, 265, 266, 267, 268, 269, 270, 274, 277, 279, 280, 285, 287, 288, 290, 292, 297, 298, 301, 302, 303, 304, 305, 306, 307, 309, 312, 313, 314, 322, 323, 324, 325, 332, 337, 348, 349, 350, 352, 353, 356, 357, 359, 360, 368, 370, 371, 372, 374, 378, 398, 399, 424, 425, 431, 433, 435, 440, 441, 450, 451, 452, 453, 454, 468, 480, 481, 482, 483, 484, 485, 487, 497, 505, 506, 512, 518, 529, 541, 542, 544, 546, 552, 553, 554, 556, 558, 561, 565, 566, 569, 570, 572, 573, 575, 579, 581, 583, 585, 587, 588, 589, 590, 591, 592, 594, 595, 599, 600, 601, 603, 604, 608, 620, 627, 629, 633, 634, 635, 636, 637, 638, 639, 640, 641, 646, 649, 652, 653, 661, 663, 664, 665, 666, 667, 668, 669, 670, 672, 675, 676, 677, 678, 680, 681, 682, 684, 685, 686, 687, 688, 691, 692, 693, 694, 695, 696, 700, 704, 710, 711], "40": [221, 276, 345, 390, 512, 513, 514, 537, 538, 547, 550, 662], "4000": [188, 481, 576], "4004": 370, "4013e": 546, "4022": [64, 650], "4024": 675, "4025": 284, "4027": 650, "4028e": 318, "4031": 233, "4032": 627, "4034": 243, "4038": 127, "4054": 650, "4061": [562, 651], "4064e": 174, "4065": 90, "4079": 667, "4090": 64, "4096": 687, "4099": 284, "41": [176, 487, 546, 572], "4112": 128, "4117": 667, "4126": 154, "4142": [553, 566], "4142j": 566, "4144": 150, "4151": 98, "4169": 150, "4173": 130, "42": [115, 313], "4206": 154, "4208": 126, "4219": 485, "4220": 153, "4226": 277, "42296738": 283, "4234": 650, "4254": 303, "4255": [65, 313], "4264": 160, "4267": 96, "4279": 303, "4282": 150, "4286": 572, "4290": 173, "4291": 173, "4292": 66, "4296": 650, "4309": 147, "4312": 313, "4314": 591, "4320": [353, 660], "4331": 569, "4333": 677, "4337": 243, "435": 649, "4350": 371, "4362": 370, "4370": 312, "4373": 650, "4375": 481, "4394": 313, "4396": 95, "44": [176, 339, 397, 423, 546], "4400": [481, 667], "4410": 677, "4412": 663, "4418": 485, "4419": 173, "4423": [98, 125], "4439": 129, "4472": 623, "4475": 145, "4477": 675, "4480": 173, "4485": [645, 690], "4490": 151, "4494": 173, "45": [77, 343, 344, 391, 392, 468, 546], "4509": 168, "4523": [352, 484], "4525": 95, "4526": 293, "4532": 667, "4537": [243, 487], "4539": 284, "4545": 173, "4551": 128, "4552": 95, "4558": 173, "4573": 677, "4581": 168, "4595": 591, "4598": 649, "4599": 303, "46": [155, 225], "4605": 168, "4606": 692, "4608": 660, "4614": 124, "4620": [168, 697], "4637": 168, "4640": 277, "4644": [306, 644, 645, 689, 690], "4649": 353, "466": 579, "4664": [241, 667], "4670": 569, "4671": 68, "4677e": 546, "4678": 168, "4682": 243, "4684": 127, "4696": 152, "4709": 585, "4713": [125, 591], "4722": 663, "4725": 151, "4730": [65, 667], "4732": 89, "4733": 650, "4737": [667, 693], "4740": 145, "4742": [304, 680], "4752": 649, "4757": 168, "4784": 308, "4785": 675, "4796": 667, "4798": 677, "480": [351, 455], "4806": [640, 641], "4809": 650, "4817": 74, "4821": [125, 128], "4842e": 176, "4851": 308, "4853": 75, "4864": 243, "4866": 75, "4867": 667, "4874": 667, "4875": 660, "4878": 74, "4884": 573, "489": 579, "4893": 689, "49": [155, 194], "4900": 92, "4907": [88, 291], "4928": 667, "4942": 671, "4945": 163, "4963": 173, "4970": 370, "4982": 127, "4985": 95, "4d": [343, 374, 391, 481, 505, 506, 576], "4gb": 704, "4j": 623, "5": [64, 65, 69, 76, 79, 94, 100, 101, 102, 105, 108, 115, 116, 117, 121, 123, 127, 129, 130, 131, 132, 135, 145, 149, 152, 154, 156, 163, 165, 167, 168, 171, 172, 173, 176, 190, 191, 194, 197, 199, 200, 201, 203, 209, 221, 227, 229, 231, 232, 233, 243, 251, 255, 265, 266, 267, 270, 273, 274, 276, 277, 278, 279, 280, 286, 290, 297, 298, 304, 305, 314, 321, 323, 324, 326, 329, 330, 331, 333, 334, 335, 336, 337, 341, 342, 343, 344, 348, 349, 350, 352, 353, 354, 356, 357, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 379, 381, 382, 383, 388, 390, 391, 392, 393, 394, 398, 400, 401, 402, 403, 410, 411, 412, 416, 419, 424, 425, 428, 435, 438, 442, 443, 444, 450, 451, 452, 453, 454, 457, 460, 466, 468, 472, 474, 476, 478, 479, 480, 481, 482, 483, 496, 497, 518, 528, 531, 533, 534, 536, 541, 542, 544, 546, 552, 553, 554, 556, 557, 561, 563, 565, 566, 568, 569, 572, 573, 576, 577, 578, 579, 583, 588, 589, 592, 593, 599, 600, 601, 608, 620, 633, 634, 635, 636, 639, 646, 649, 650, 651, 652, 653, 661, 663, 665, 666, 667, 669, 670, 672, 681, 682, 685, 687, 688, 694, 695, 696, 699, 703, 710, 711], "50": [338, 339, 347, 355, 356, 357, 359, 360, 375, 376, 395, 396, 397, 421, 422, 423, 479, 662], "5000": [79, 94, 100, 101, 102, 108, 132, 197, 199, 200, 201, 221, 227, 230, 270, 274, 319, 321, 352, 353, 481, 573, 577, 578, 579, 588, 592], "5002": 297, "5018": 667, "5027": [644, 645, 689, 690], "50276": 305, "5037": 308, "5071": 633, "5080": [644, 645, 650, 689, 690], "5083": 313, "5085": 303, "5087": 173, "5095": 127, "51": [426, 572], "5104": 152, "5113": 667, "5115": 243, "512": [472, 473, 474, 475, 476], "5146": 313, "5162": 667, "517": 276, "5173": [310, 311], "5174": 693, "5194": 627, "5197": 649, "52": 173, "5200": 481, "5201": 173, "5204": [277, 581], "5207": 677, "5211": 677, "5212": 304, "5219": 304, "5223": 487, "5224": 278, "5235": 677, "5241": 485, "5244": 313, "5250e": 546, "5261": [570, 650], "5267": 90, "5280": 573, "5281": 151, "5287": 280, "5296": 650, "5306": 667, "5308": 195, "5369": 66, "5372": 279, "5380": 629, "5387": 145, "5393": 167, "54": [225, 389], "5405": 674, "541": 276, "5410": 161, "5413": 675, "5414": 241, "5419": 88, "5420": 603, "5428": 570, "5429": 674, "5434": 650, "5436": [485, 667], "5445": [237, 590], "5447": 152, "5452": 243, "5461": 627, "5466": 680, "5475": 649, "5481": [290, 303], "5487": 128, "5491": 313, "5492": 674, "5495": 312, "5497": 293, "55": 381, "5509": 243, "5513": 667, "5528": 128, "5548": 168, "5558": 293, "5561": 569, "5565": 69, "5569": 650, "5574": 147, "5590": 689, "5591": 97, "5596": [644, 645, 689, 690], "56": 685, "5600": [303, 481], "5609": 127, "5636e": 487, "5637": 277, "5637e": 487, "5644": 629, "5650": 151, "5653": 675, "5661": 573, "5671": 243, "5672": [243, 554], "5673": 581, "5676": 168, "5678": 685, "5684": 161, "5687": 151, "5688": 649, "5696": 291, "570": 580, "5704": 173, "5708": 157, "5717": 301, "5719": 145, "5724": 273, "5727": 97, "5739": 277, "5743": 65, "5744": 75, "5745": [644, 645, 689, 690], "5749": 243, "5751e": 174, "5756": 173, "5757": 145, "5766": 487, "5767": 313, "5772": 692, "5772j": 692, "5781": 581, "5787": [243, 284], "5788": 306, "5790": 124, "5793": 633, "5795": 573, "5798": 371, "5802": 173, "5803": 370, "5809": 671, "5811": 64, "5812": 146, "5826": 126, "5846e": 546, "5849": 151, "5850": 243, "5854": 570, "5872": 660, "5876": 677, "5877": 313, "5879": 67, "5889": 62, "59": [676, 678], "5904": 173, "5905": [644, 645, 689, 690], "5906": 187, "5915e": 546, "5916": 167, "5923": 168, "5926": 690, "5930": 663, "5944": 168, "5950": 160, "5954": 585, "5955e": 174, "5962": 95, "5977": 163, "5997": 667, "5d": [344, 392, 481], "5x7": [330, 334], "5x7x9": [331, 335], "6": [64, 65, 70, 76, 108, 116, 121, 127, 131, 135, 150, 152, 156, 157, 168, 171, 172, 190, 191, 194, 201, 221, 231, 232, 233, 255, 266, 270, 274, 276, 305, 322, 323, 324, 337, 348, 349, 350, 351, 354, 359, 362, 380, 381, 382, 384, 385, 424, 425, 429, 437, 446, 449, 450, 451, 452, 453, 454, 455, 472, 473, 475, 477, 480, 486, 487, 541, 542, 544, 546, 552, 553, 554, 561, 562, 565, 572, 573, 579, 580, 583, 589, 599, 600, 604, 608, 620, 630, 633, 634, 635, 639, 649, 651, 652, 653, 661, 666, 667, 668, 669, 670, 672, 675, 677, 681, 685, 687, 695, 696, 704, 711], "60": [381, 662, 667], "6000": [472, 474, 476, 481, 576, 623], "6001": 154, "6004": 241, "6010": [472, 474, 476], "6038": 645, "6048": 554, "6049": 675, "6051": 168, "6056": 64, "6058": 633, "6060": 301, "6070": 173, "6087": 313, "6092": 88, "6097": 130, "6116": 692, "6120": 151, "6134": [187, 306], "6147": 64, "6148": 554, "6165": 75, "6166": 163, "6172": 301, "6174": 67, "6189": 293, "6213": 284, "6217": 649, "6218": 664, "6245": 64, "6248": [297, 306], "6249": 67, "6250": [201, 481], "6251": 371, "6256": 97, "6258": 187, "6291": 92, "6295": 167, "6300": 160, "6311": 65, "6320": 303, "6321": 167, "6323": 187, "6341": 126, "6347": 243, "6358e": 129, "6361": 316, "6366": 585, "6368": 675, "6372": [352, 484, 650], "6387": 95, "6391": 67, "64": [155, 329, 330, 331, 333, 334, 335, 341, 457, 609, 711], "6400": 481, "6420": [644, 645, 689, 690], "6431": 370, "6444": 187, "6446": 485, "6448": 97, "6451": 75, "6476": 278, "6482": 160, "6492": [237, 590], "6496": 66, "6503e": 650, "6511": 67, "6531e": 650, "6535": 554, "6537": 167, "6538": [644, 645, 689, 690], "6548": [644, 645, 689, 690], "6549": 303, "6553": 147, "6556": 677, "6558": 243, "6561": 692, "6569": 233, "6571": 241, "6576": 677, "6577": 127, "6580": 124, "6585": 353, "6602": 677, "6604": 650, "6616": [352, 484], "6623": 692, "6623j": 692, "6628": 153, "6654": 677, "6667": [150, 230, 481, 482, 593], "6684": [153, 243], "6699": 693, "6699j": 693, "6702": 301, "6705": 308, "6706": [173, 573], "6708": 487, "6719": 633, "6724": 128, "6727": [154, 167], "6732632423543772848170429916717": 456, "6750": 306, "6760": 65, "6763": 301, "6778": 370, "6785": 243, "68": 572, "6813": 487, "6834": 569, "6843": 284, "6859e": 291, "6864": [649, 675], "6867": 281, "6879": 581, "6881e": 130, "6895": 151, "6902": [370, 570], "6912": 243, "6927": 163, "6929": 660, "6932": 660, "6933": 640, "6969": 370, "6971": 64, "6973": 167, "6979": 148, "6986": [125, 591], "6993": 304, "6b": 704, "6gb": 704, "7": [64, 76, 113, 116, 121, 127, 129, 131, 135, 155, 156, 168, 170, 171, 174, 190, 191, 194, 197, 201, 221, 231, 243, 266, 270, 322, 323, 324, 330, 331, 334, 335, 337, 348, 349, 350, 370, 416, 424, 425, 450, 451, 452, 453, 454, 477, 480, 505, 506, 531, 536, 546, 553, 579, 583, 589, 599, 600, 601, 608, 616, 620, 623, 625, 626, 633, 634, 635, 639, 650, 652, 653, 661, 666, 667, 670, 672, 681, 685, 691, 695, 711], "70": 572, "7000": [197, 625], "7005": 151, "7015": 306, "7021": 313, "7023": 128, "7048": 304, "7055": 279, "7064": 90, "7079": 145, "7082": 371, "7089": [284, 370], "7105": 675, "7120": 132, "7125": 304, "7138": 125, "7145": 675, "7148": 107, "7151": 63, "7152": [352, 484], "7153": 151, "7156": 664, "7158": 74, "7159": 243, "7163": 127, "7172": 370, "7175": 293, "7180": 151, "7193": 667, "7197": [306, 697], "72": 221, "7200": 481, "7201": 650, "7202": 107, "7208": 173, "7229": 554, "7230": 241, "7242": 243, "7249": 581, "7253": 99, "7257": 278, "7265": 370, "7266": 627, "7268": 75, "7279": 664, "7298": [62, 591], "7299": 671, "7303": 304, "7325": [148, 163], "7336": 163, "7344": 675, "7350": 173, "7366": 243, "7384": 303, "7386": 284, "7388": 67, "7394": 650, "74": 155, "7401": 88, "7403": 674, "7417": 553, "7438": 168, "7445": 301, "7460": 553, "7477": 644, "7486": 128, "7493": 243, "7497": 692, "7497j": 692, "75": [229, 416, 573], "7500": [108, 201, 221, 274, 481, 579], "7503": 92, "7506": 89, "7556": 667, "7573": 68, "7600": 650, "7617": 67, "7620": 168, "7648": 675, "7656e": 194, "7687": 663, "7694": 303, "7695": 64, "7702": 660, "7705": 279, "7724": 64, "7752": 650, "7759": 168, "7767": 277, "7780": 667, "7791": 63, "78": 685, "7806": 650, "7809": 89, "784": 579, "7841": 674, "7845": 64, "7860": 148, "7892": 649, "7894": 243, "7895": 370, "7896": 237, "7896j": [237, 590], "7909": 554, "7920": 243, "7938": 163, "7952": 173, "7969": 554, "7986": 674, "7988": 293, "7x7": [330, 334], "7x7x7": [331, 335], "7x9x8": [331, 335], "8": [64, 65, 76, 77, 108, 116, 127, 130, 131, 135, 137, 152, 156, 171, 176, 190, 191, 194, 201, 221, 230, 231, 268, 274, 275, 323, 324, 329, 330, 331, 333, 334, 335, 348, 349, 350, 351, 362, 424, 425, 431, 433, 435, 442, 447, 450, 451, 452, 453, 454, 455, 468, 472, 473, 474, 475, 476, 480, 505, 506, 553, 554, 561, 565, 569, 589, 599, 600, 601, 608, 616, 620, 630, 633, 634, 635, 639, 646, 650, 661, 666, 667, 668, 670, 672, 681, 685, 687, 688, 695, 704, 711], "80": [221, 620], "8000": [319, 481, 573], "8000e": 174, "8000j": 623, "8003": 280, "8008": 680, "8017": 64, "802": 579, "8020": 570, "8025": 173, "8032": 168, "8053": 603, "8058": 173, "80827": [424, 425, 426], "8097": 173, "8101": [644, 645, 689, 690], "8113": 168, "8119": 237, "8119j": [237, 590], "8125": 481, "8153": 173, "8166": 195, "8172": 163, "8173": 243, "8177": 74, "8185": 65, "8202": 65, "8209": 152, "8223": 667, "8229": 90, "8237": 581, "8257": 664, "8258": 689, "8297": 297, "83": 155, "8304": 151, "8305": 173, "8307e": 546, "8312": 294, "8318": 554, "8322": 125, "8351": 603, "83525007": 283, "8353": 67, "8360": 167, "8373": 677, "8378": 313, "8397": 75, "8398": 130, "8419": 280, "8437": [310, 311], "84492621": 283, "8475": 301, "85": 431, "8521": 90, "8530": [173, 352, 484], "8536": 163, "8562": 147, "8571": 572, "8591": 99, "8611": 650, "8615": 127, "8619": 675, "86278635": 283, "8632": 629, "8635": 67, "8652": [352, 484], "8653": 279, "8663": 313, "8675": 167, "8678": 487, "8681": 68, "8701": 353, "8707": [645, 690], "8716": 68, "8731": 281, "8744": 667, "8750": [201, 481], "8753": 313, "8766": 650, "8768": 301, "8775": 675, "8785": 697, "8787": 173, "8788e": 487, "8795": 160, "8800": 481, "8805": 88, "88131e": 617, "8832e": 487, "8833": 650, "8857": 278, "8861": 371, "89": 580, "8917": [127, 284], "8929": 585, "8937": 107, "8944j": 623, "8966": [352, 484], "8986": 664, "8990": [96, 168], "8gb": 704, "9": [76, 121, 127, 131, 135, 150, 155, 156, 171, 174, 194, 197, 198, 201, 202, 221, 231, 323, 324, 330, 331, 334, 335, 348, 350, 370, 371, 424, 425, 440, 441, 451, 454, 553, 554, 561, 565, 601, 608, 617, 620, 633, 639, 665, 666, 670, 672, 681, 688, 695, 703, 711], "90": [157, 600], "9000": 665, "9023": 75, "9028": 487, "9029": 572, "9032": 284, "9039": 92, "9041": [98, 125], "9046": 674, "9068": 162, "9073e": 480, "9075": 75, "9079": 680, "9087": 644, "9105": 603, "9120": 692, "9120j": 692, "9124": 370, "9128": 75, "9130": 74, "9138": 649, "9158": 660, "9162": 485, "9165": 153, "9196": 280, "9206": 573, "9207": 301, "9214": 75, "9223372036854775807": 539, "9240": 89, "9244": 145, "9254": 284, "9255": 293, "9270": 674, "92701": [612, 711], "9274": 168, "9280": 90, "93": 155, "9314": 129, "9315": 370, "9320": 674, "9323": 173, "9332e": 512, "9337": 649, "9342": 162, "9348": 677, "9353": 168, "9354": 278, "9355": 92, "9371": 128, "9375": 481, "9381": 173, "9384": 89, "9385": 99, "9399": 629, "94": 381, "9400": 370, "9429": 572, "9435": 96, "9445": 667, "9451": 693, "9451j": 693, "9453": 65, "9456": 107, "94622083": 283, "9466": 485, "9482": 243, "9497": 633, "9510": 304, "9524": 229, "9544": [554, 580], "9553": 633, "9555": 68, "9556": 677, "9564": 168, "9566": 290, "9567": [145, 649], "9580": 303, "9600j": 623, "9604": 485, "9627": [310, 311], "9644": 303, "9647": 127, "9665": 284, "9674": 63, "9683e": 176, "9685": 370, "9688": 151, "9700": 74, "9701": 293, "9730": 188, "9732": 64, "9743": 98, "9744": 629, "9757": 151, "9764": 168, "9765": 573, "9768": 65, "9790": 127, "9792": [151, 154], "9796": 147, "9805": 168, "9828": 675, "9829": 66, "9833": 98, "9837": 243, "9843": 243, "9849": 306, "9859": 663, "9883": 151, "9888": 677, "9892": 243, "9893": 671, "9894": 580, "9897": 370, "9902": [64, 151], "9906": 649, "9915": 63, "9923": 279, "9946": 152, "9948": 304, "9966": 585, "9971": 280, "A": [1, 2, 3, 4, 71, 76, 106, 115, 116, 118, 123, 128, 129, 130, 136, 137, 142, 146, 150, 158, 173, 178, 186, 187, 188, 210, 221, 224, 225, 226, 230, 256, 257, 258, 259, 262, 265, 269, 276, 284, 292, 293, 294, 295, 299, 325, 341, 345, 347, 363, 366, 367, 368, 370, 372, 380, 381, 389, 399, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 418, 427, 457, 462, 464, 472, 477, 478, 487, 498, 499, 500, 501, 507, 509, 512, 515, 518, 540, 541, 544, 562, 572, 574, 575, 576, 577, 578, 589, 595, 601, 604, 633, 642, 645, 646, 650, 651, 669, 674, 675, 676, 677, 678, 682, 683, 684, 686, 687, 690, 694, 697, 704, 711], "AND": [109, 285], "And": [152, 153, 266, 301, 306, 347, 704], "As": [119, 173, 332, 366, 367, 368, 372, 393, 428, 460, 552, 558, 700, 703, 704, 712], "At": [342, 343, 344, 355, 356, 357, 358, 359, 360, 395, 396, 397], "But": 497, "By": [3, 94, 137, 150, 156, 168, 221, 229, 230, 275, 304, 309, 318, 340, 341, 342, 343, 344, 361, 363, 381, 387, 390, 391, 392, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 468, 477, 514, 550, 562, 573, 594, 672, 694, 704], "For": [65, 66, 67, 68, 69, 72, 78, 105, 109, 111, 112, 114, 117, 126, 137, 154, 155, 156, 173, 195, 203, 208, 221, 230, 243, 276, 283, 291, 298, 304, 308, 332, 336, 340, 341, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 364, 370, 371, 373, 374, 379, 381, 388, 393, 398, 400, 431, 432, 433, 442, 443, 444, 450, 451, 452, 453, 454, 455, 460, 465, 479, 480, 484, 485, 486, 487, 496, 497, 498, 516, 539, 540, 541, 553, 585, 601, 610, 613, 621, 636, 642, 650, 651, 666, 668, 672, 680, 683, 692, 693, 694, 703, 704, 706, 707, 711], "If": [1, 3, 65, 68, 69, 70, 72, 74, 75, 76, 78, 79, 88, 89, 90, 91, 92, 93, 94, 105, 106, 108, 115, 117, 118, 119, 121, 125, 127, 128, 131, 132, 137, 139, 143, 144, 145, 149, 150, 151, 154, 155, 156, 160, 161, 162, 163, 164, 173, 174, 175, 176, 186, 190, 194, 202, 203, 205, 206, 207, 208, 216, 221, 225, 226, 228, 229, 230, 231, 241, 243, 257, 263, 264, 265, 266, 270, 274, 275, 276, 286, 290, 291, 293, 295, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 314, 316, 318, 319, 320, 321, 322, 323, 332, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 372, 374, 375, 376, 379, 380, 381, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 404, 405, 406, 407, 408, 409, 413, 415, 419, 420, 421, 422, 423, 431, 432, 433, 434, 435, 436, 437, 442, 443, 444, 446, 450, 451, 452, 453, 454, 455, 460, 461, 468, 472, 474, 476, 477, 478, 480, 481, 484, 485, 486, 490, 496, 497, 499, 503, 504, 507, 508, 512, 513, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 534, 535, 539, 540, 541, 543, 546, 547, 548, 550, 551, 552, 553, 557, 558, 560, 561, 566, 570, 572, 573, 577, 578, 581, 582, 583, 584, 585, 586, 587, 588, 593, 594, 599, 601, 604, 608, 610, 612, 615, 616, 620, 622, 633, 634, 635, 636, 637, 638, 639, 642, 644, 645, 646, 649, 650, 651, 662, 665, 666, 668, 669, 671, 672, 674, 675, 676, 677, 678, 683, 684, 687, 688, 689, 690, 694, 699, 700, 703, 704, 711], "In": [2, 113, 121, 143, 144, 151, 173, 199, 263, 276, 281, 284, 293, 298, 304, 305, 319, 337, 338, 339, 341, 347, 355, 356, 357, 358, 359, 360, 364, 366, 367, 368, 372, 374, 379, 388, 398, 413, 421, 422, 423, 434, 472, 474, 476, 480, 497, 505, 506, 512, 518, 519, 551, 592, 608, 610, 646, 650, 651, 674, 687, 691, 692, 704], "It": [3, 104, 137, 142, 143, 144, 204, 208, 229, 263, 275, 276, 284, 332, 341, 347, 355, 356, 357, 358, 359, 360, 363, 364, 374, 422, 423, 424, 425, 426, 435, 457, 460, 480, 482, 489, 490, 491, 494, 495, 513, 515, 518, 539, 542, 551, 560, 579, 592, 608, 623, 682, 694, 704, 706, 710, 712], "Its": [150, 295, 553, 691], "NOT": [111, 286, 367, 497, 499, 520, 521, 522, 523, 524, 525, 526, 527, 536, 551], "No": [497, 505, 506, 551], "Not": [322, 476, 646], "OR": [112, 287], "Of": 552, "On": [65, 68, 105, 117, 298, 308, 355, 356, 357, 358, 359, 360, 380, 395, 396, 397, 399, 415, 438, 457], "One": [116, 257, 481, 498, 505, 506, 512, 516, 583, 584, 682, 694], "Or": [94, 132], "Such": 688, "That": [142, 263, 274, 290, 687, 704], "The": [1, 2, 63, 66, 67, 68, 69, 73, 74, 75, 76, 91, 92, 94, 98, 99, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 122, 123, 136, 139, 142, 146, 150, 156, 160, 161, 162, 163, 164, 165, 167, 173, 174, 178, 190, 199, 201, 202, 204, 205, 206, 210, 211, 220, 221, 224, 225, 226, 227, 228, 229, 230, 233, 237, 241, 242, 243, 263, 264, 265, 269, 270, 275, 276, 291, 292, 293, 294, 296, 297, 298, 304, 314, 320, 323, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 370, 371, 372, 374, 375, 376, 379, 380, 381, 382, 387, 388, 390, 391, 392, 393, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 418, 419, 420, 421, 422, 423, 431, 433, 435, 442, 443, 444, 445, 446, 447, 457, 458, 460, 468, 471, 472, 477, 478, 480, 481, 487, 489, 490, 491, 494, 495, 496, 497, 500, 501, 503, 504, 505, 506, 507, 509, 511, 512, 513, 514, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 532, 533, 536, 542, 546, 547, 550, 552, 553, 554, 562, 563, 566, 569, 572, 577, 578, 579, 581, 583, 585, 590, 592, 594, 596, 597, 599, 601, 604, 611, 612, 613, 614, 616, 620, 621, 630, 634, 635, 636, 637, 638, 642, 644, 645, 646, 650, 651, 661, 667, 668, 669, 671, 672, 675, 676, 677, 678, 685, 686, 687, 688, 689, 690, 692, 694, 697, 703, 704, 706, 707, 710, 711, 712], "Their": 165, "Then": [374, 480, 703], "There": [137, 364, 497, 505, 506, 546, 551, 712], "These": [94, 150, 173, 263, 311, 332, 487, 513, 707, 711, 712], "To": [134, 137, 161, 163, 173, 196, 276, 304, 332, 341, 367, 393, 424, 425, 426, 482, 483, 497, 514, 520, 521, 522, 523, 524, 525, 526, 527, 550, 562, 573, 612, 616, 619, 636, 651, 703, 704, 707, 711], "Will": 636, "With": [342, 343, 344, 356, 357, 359, 360, 373, 390, 391, 392, 468, 479, 481, 583], "_": [60, 62, 63, 77, 79, 95, 96, 97, 98, 99, 104, 107, 126, 144, 145, 147, 148, 150, 195, 200, 233, 265, 273, 283, 291, 342, 343, 344, 390, 391, 392, 444, 468, 513, 547, 562, 585, 588, 591, 603, 623, 625, 627, 629, 640, 650, 663, 664, 706], "_2": [362, 513, 547], "__array_interface__": 94, "__dlpack__": 202, "__getitem__": 687, "__init__": [379, 398, 428, 429, 430, 438, 439, 444, 487], "_another_": 704, "_back": [351, 354, 452, 455, 486], "_batchnorm": [507, 509], "_bottom": [350, 351, 353, 354, 451, 452, 454, 455, 485, 486], "_channel": [355, 356, 357, 358, 359, 360, 382], "_class": 332, "_convnd": 507, "_could_": 704, "_dim": 370, "_dynamo": 137, "_factor": [440, 441, 481, 482, 483], "_featur": [332, 345, 413, 415], "_fft": 646, "_formatt": 620, "_freez": 370, "_front": [351, 354, 452, 455, 486], "_get_ddp_logging_data": 497, "_glibcxx_use_cxx11_abi": [138, 703], "_h": 375, "_i": [64, 65, 66, 67, 68, 105, 107, 110, 113, 117, 132, 168, 196, 268, 270, 313, 477, 565, 569, 585, 588, 623, 647, 697], "_index": [363, 435], "_indic": 636, "_inductor": 137, "_inputt": 137, "_int": [187, 188], "_j": [355, 356], "_layer": [379, 398, 444], "_left": [349, 350, 351, 352, 353, 354, 450, 451, 452, 453, 454, 455, 484, 485, 486], "_length": [106, 115, 225, 226, 263, 347, 646], "_m": 512, "_mask": [520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536], "_max": [187, 188], "_min": [187, 188], "_n": 512, "_orig": [520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536], "_orthogon": 512, "_p": 437, "_pad": [358, 359, 360], "_point": [187, 188], "_random_sampl": [375, 376], "_ratio": [375, 376], "_rett": 137, "_revers": 398, "_right": [349, 350, 351, 352, 353, 354, 450, 451, 452, 453, 454, 455, 484, 485, 486], "_sampl": 314, "_shape": [400, 443, 496], "_size": [329, 330, 331, 333, 334, 335, 337, 338, 339, 355, 356, 357, 358, 359, 360, 374, 375, 376, 379, 380, 395, 396, 397, 398, 399, 421, 422, 423, 424, 425, 426, 444, 446, 480], "_slope": 414, "_spectralnorm": 513, "_t": [379, 398], "_tensor_str": 620, "_the_": 173, "_top": [350, 351, 353, 354, 451, 452, 454, 455, 485, 486], "_use_new_zipfile_seri": 604, "_val": 386, "_valu": [132, 332, 504, 636], "_version": 103, "_w": [150, 375], "_weight": [370, 371], "_weightnorm": 514, "a_": [265, 295, 416, 667], "a_0": 265, "a_1": 265, "a_big": 650, "a_i": [477, 478], "a_lu": 293, "a_n": 265, "a_unique_dim0": 683, "aarch64": 617, "ab": [5, 6, 61, 125, 173, 276, 398, 448, 475, 478, 480, 514, 550, 553, 562, 566, 616], "abc": 539, "abi": 703, "abil": 604, "abl": [472, 704], "about": [142, 539, 615, 704, 706], "abov": [94, 106, 115, 156, 160, 161, 162, 163, 164, 173, 211, 225, 226, 265, 276, 337, 338, 339, 340, 341, 374, 428, 457, 465, 480, 487, 554, 572, 583, 584, 616, 620, 672, 675, 676, 677, 678, 706], "absolut": [60, 73, 199, 255, 273, 284, 388, 394, 460, 523, 524, 526, 527, 529, 532, 533, 534, 535, 553, 566, 592, 623], "abstract": 520, "acceler": [1, 3, 216, 342, 343, 344, 468], "accept": [127, 204, 230, 363, 435, 457, 476, 525, 539, 540, 546, 642, 694, 711], "access": [332, 487, 500, 501, 513, 518, 540, 550, 711], "accommod": [424, 425, 426], "accord": [94, 107, 119, 171, 231, 297, 314, 332, 371, 440, 520, 521, 522, 523, 524, 525, 526, 527, 573, 639, 651, 666, 695], "accordingli": [398, 518], "account": [341, 497, 704], "accumul": [65, 497, 687], "accur": [221, 279, 341, 369, 579, 672], "accuraci": [137, 616], "achiev": [173, 341, 347, 435], "acitv": 703, "aco": [7, 8, 80], "acosh": 81, "across": [1, 88, 173, 187, 305, 341, 364, 374, 416, 434, 436, 468, 480, 497, 525, 529, 553, 604, 694], "act": [341, 429, 430, 439, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 536, 687], "activ": [276, 336, 366, 367, 368, 372, 382, 400, 427, 429, 447, 458, 472, 474, 476, 497, 516, 518, 548, 553, 694, 704], "actual": [143, 358, 359, 360, 497, 530, 704], "ad": [65, 66, 67, 68, 69, 70, 103, 104, 105, 173, 177, 275, 281, 337, 338, 339, 341, 342, 343, 344, 355, 356, 357, 358, 359, 360, 374, 382, 390, 391, 392, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 421, 422, 423, 424, 425, 426, 435, 437, 442, 443, 457, 468, 477, 480, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 518, 525, 528, 529, 530, 532, 533, 534, 535, 551, 576, 577, 578, 704, 712], "adagrad": 370, "adapt": [329, 330, 331, 332, 333, 334, 335, 365], "adaptiveavgpool2d": 687, "adaptiveavgpool3d": 687, "adaptivemaxpool2d": 687, "add": [65, 66, 67, 70, 173, 332, 347, 355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409, 430, 434, 435, 439, 442, 489, 490, 491, 492, 493, 494, 495, 497, 518, 520, 521, 522, 523, 524, 525, 526, 527, 616, 701, 711], "add_": 142, "add_bias_kv": 434, "add_param_group": 518, "add_pruning_method": 525, "add_safe_glob": 275, "add_zero_attn": 434, "addbackward0": 94, "addbmm": 105, "addit": [263, 332, 343, 344, 345, 358, 359, 360, 371, 378, 379, 381, 388, 391, 392, 400, 407, 408, 409, 413, 414, 415, 416, 418, 424, 425, 426, 434, 436, 462, 464, 468, 472, 474, 476, 478, 497, 616, 683, 684, 687, 692, 704], "addition": [332, 390, 391, 392, 710, 712], "adequ": 651, "adjac": [79, 116, 366, 367, 368, 372, 588], "adjust": 341, "admonit": 710, "adopt": [505, 506], "advanc": [472, 474, 476, 552, 651], "advantag": [341, 388], "adversari": [513, 547], "advis": 79, "affect": [103, 104, 177, 202, 203, 481, 499, 505, 506, 551, 612, 615, 616, 704], "affin": [342, 343, 344, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 415, 443, 468, 496], "after": [137, 172, 251, 275, 298, 328, 364, 379, 413, 431, 472, 474, 476, 487, 490, 497, 518, 520, 524, 526, 612, 646, 672, 696, 703, 704, 711], "afterward": [487, 497, 704], "again": 314, "against": [79, 208, 257], "aggreg": 529, "aggress": [263, 505, 506], "agnost": [505, 506], "aidan": [472, 474, 476], "aka": [142, 388, 711], "al": [347, 440, 441, 477, 478, 651], "alexandr": 688, "algebra": 173, "algorithm": [2, 127, 263, 276, 293, 347, 355, 356, 357, 358, 359, 360, 374, 377, 480, 481, 562, 601, 616, 650, 651, 687], "alia": [61, 80, 81, 82, 83, 84, 85, 86, 133, 140, 141, 159, 166, 169, 180, 181, 182, 184, 185, 189, 212, 222, 223, 234, 235, 236, 244, 271, 272, 289, 299, 300, 310, 315, 317, 327, 539, 555, 559, 564, 567, 602, 624, 628, 631, 632, 648, 652, 653, 673, 679, 698], "alias": 694, "align": [137, 173, 221, 339, 347, 363, 379, 393, 398, 422, 423, 444, 481, 512, 553, 672], "align_corn": [481, 482], "all": [1, 2, 3, 65, 66, 71, 73, 77, 78, 88, 91, 107, 116, 118, 123, 124, 128, 131, 132, 136, 137, 142, 149, 203, 205, 208, 230, 232, 262, 263, 275, 291, 293, 296, 301, 303, 306, 319, 320, 321, 322, 332, 339, 341, 345, 347, 349, 350, 351, 353, 354, 355, 356, 357, 358, 359, 360, 364, 370, 371, 374, 379, 380, 381, 382, 387, 393, 394, 398, 399, 415, 419, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 444, 446, 450, 451, 452, 453, 454, 455, 468, 472, 474, 476, 477, 480, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 497, 503, 512, 518, 525, 529, 539, 543, 551, 552, 553, 554, 570, 609, 616, 634, 635, 636, 637, 638, 642, 643, 644, 645, 646, 649, 666, 668, 675, 676, 677, 678, 681, 683, 684, 685, 689, 690, 692, 696, 703, 704, 711, 712], "allclos": [295, 518, 545, 572, 694], "alloc": [3, 174, 176, 203, 213, 581, 585, 587, 612, 634, 635, 636, 637, 638, 665, 704, 711], "allow": [3, 122, 136, 142, 173, 281, 323, 337, 338, 339, 363, 364, 381, 421, 422, 423, 428, 431, 434, 457, 497, 504, 552, 687, 704, 711, 712], "allow_tf32": 616, "allreduc": 497, "alon": 687, "along": [65, 76, 89, 90, 124, 131, 149, 151, 156, 164, 165, 172, 173, 191, 208, 232, 241, 243, 266, 312, 319, 323, 324, 333, 334, 335, 341, 362, 375, 376, 418, 421, 422, 423, 462, 464, 524, 526, 533, 534, 543, 552, 573, 593, 594, 599, 610, 633, 639, 643, 662, 666, 669, 672, 681, 691, 694, 696], "alongsid": [703, 712], "alpha": [64, 65, 68, 69, 70, 105, 225, 238, 336, 346, 369, 416, 456, 647, 648], "alphabet": 173, "alphadropout": 372, "alreadi": [1, 3, 93, 275, 491, 497, 539, 681, 683, 704], "also": [94, 103, 106, 115, 129, 130, 137, 151, 154, 155, 173, 177, 202, 208, 211, 220, 225, 226, 230, 305, 311, 312, 320, 332, 340, 342, 343, 344, 355, 356, 357, 358, 359, 360, 363, 371, 374, 379, 393, 398, 428, 435, 444, 458, 460, 468, 477, 478, 480, 487, 497, 516, 518, 528, 530, 532, 533, 534, 535, 551, 560, 585, 592, 604, 614, 642, 650, 660, 662, 665, 671, 672, 683, 684, 694, 697, 704, 711, 712], "altern": [230, 275, 457, 474, 476, 497, 558, 614, 615, 687, 700], "although": [358, 359, 360, 436], "alwai": [1, 94, 106, 115, 125, 131, 137, 160, 168, 190, 194, 225, 226, 320, 340, 342, 343, 344, 364, 390, 391, 392, 401, 402, 403, 410, 411, 412, 465, 468, 487, 497, 539, 596, 597, 622, 646, 650, 657, 683, 687, 704, 711], "always_cal": 490, "amax": [75, 76], "amaxbackward0": 513, "ambigu": [251, 358, 359, 360, 374, 424, 425, 426, 481], "amin": [74, 76], "among": [230, 364, 554], "amount": [263, 355, 356, 357, 358, 359, 360, 363, 374, 416, 431, 480, 523, 524, 526, 527, 529, 531, 532, 533, 534, 535, 536], "an": [0, 1, 2, 3, 66, 67, 92, 93, 94, 108, 124, 134, 137, 143, 144, 146, 158, 171, 173, 174, 175, 176, 191, 194, 202, 205, 208, 211, 221, 229, 230, 231, 263, 275, 276, 293, 295, 298, 304, 314, 323, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 355, 356, 357, 358, 359, 360, 363, 365, 366, 367, 368, 370, 371, 372, 374, 375, 376, 379, 387, 391, 392, 395, 396, 397, 398, 400, 410, 411, 412, 413, 415, 416, 418, 421, 422, 423, 424, 425, 426, 428, 429, 430, 434, 435, 436, 438, 439, 440, 441, 443, 444, 446, 448, 457, 460, 462, 463, 464, 468, 472, 473, 474, 475, 476, 477, 480, 482, 483, 487, 490, 496, 497, 502, 503, 504, 505, 506, 511, 512, 516, 518, 525, 542, 549, 551, 553, 558, 572, 577, 578, 579, 598, 600, 604, 612, 613, 615, 623, 636, 639, 643, 646, 650, 651, 665, 666, 682, 683, 684, 685, 687, 692, 693, 694, 695, 700, 704, 707, 710, 711, 712], "analog": [73, 103, 156, 398, 650, 668], "analysi": [264, 562], "analyz": 704, "anchor": [477, 478], "anchor_id": 478, "andrea": 276, "andrew": 276, "angl": [98, 157, 284, 414, 566, 580, 623], "ani": [2, 76, 79, 113, 119, 123, 124, 143, 174, 175, 176, 199, 230, 266, 275, 329, 330, 331, 333, 334, 335, 336, 340, 341, 345, 346, 355, 356, 357, 364, 365, 369, 373, 374, 377, 378, 381, 383, 384, 385, 386, 387, 388, 389, 393, 394, 414, 415, 417, 418, 419, 427, 436, 438, 439, 442, 447, 448, 449, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 478, 479, 480, 487, 497, 505, 506, 517, 520, 521, 522, 523, 524, 525, 526, 527, 530, 540, 541, 543, 546, 548, 553, 588, 604, 618, 620, 650, 657, 694, 704], "anm": 173, "anoth": [3, 202, 370, 371, 429, 438, 487, 505, 506, 513, 612, 704, 712], "answer": [341, 531], "anyth": 704, "anywai": 704, "api": [104, 126, 177, 195, 548, 550, 551, 601, 612, 680, 694, 703, 706, 711, 712], "appear": [173, 192, 193, 275, 309, 311, 498, 499, 594, 622, 694], "append": [163, 165, 298, 380, 399, 439, 444, 446, 497], "appli": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 104, 110, 113, 142, 145, 161, 163, 168, 177, 199, 276, 293, 329, 330, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 355, 356, 357, 358, 359, 360, 361, 363, 369, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 427, 431, 432, 433, 435, 436, 442, 443, 444, 447, 448, 449, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 477, 478, 482, 483, 487, 496, 497, 505, 506, 512, 513, 514, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 539, 540, 547, 548, 550, 551, 553, 569, 574, 575, 576, 577, 578, 646, 683, 684, 686, 694, 704, 707], "applic": [137, 363, 364, 474, 476, 687], "apply_mask": [520, 521, 522, 523, 524, 525, 526, 527], "approach": [125, 341, 616, 694], "appropri": [150, 616], "approx": [221, 562, 651], "approxim": [221, 276, 332, 377, 442, 458, 465, 513, 562, 616, 651, 672], "apr": 263, "ar": [1, 2, 3, 68, 69, 70, 76, 79, 88, 89, 100, 101, 102, 103, 106, 115, 116, 118, 119, 121, 124, 137, 139, 142, 145, 146, 149, 150, 156, 161, 165, 168, 173, 174, 175, 176, 190, 192, 193, 197, 198, 199, 203, 211, 221, 225, 226, 228, 230, 243, 255, 256, 258, 259, 262, 263, 266, 274, 275, 276, 285, 286, 287, 288, 290, 291, 293, 295, 296, 298, 301, 304, 305, 306, 309, 311, 314, 318, 319, 320, 321, 322, 332, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 349, 350, 351, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 372, 374, 379, 380, 381, 382, 387, 390, 391, 392, 393, 394, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 419, 420, 421, 422, 423, 424, 425, 426, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 442, 444, 446, 457, 460, 461, 462, 468, 472, 474, 476, 477, 478, 480, 481, 487, 497, 498, 499, 500, 501, 503, 504, 505, 506, 511, 512, 513, 516, 518, 525, 539, 543, 546, 547, 548, 549, 550, 551, 553, 554, 566, 572, 573, 579, 588, 591, 592, 599, 601, 612, 613, 616, 633, 634, 635, 636, 637, 638, 645, 646, 649, 650, 660, 662, 666, 668, 669, 671, 672, 674, 675, 676, 677, 678, 683, 687, 688, 689, 690, 694, 703, 704, 706, 707, 711, 712], "arang": [70, 71, 72, 76, 78, 100, 101, 102, 119, 131, 135, 156, 171, 191, 192, 193, 194, 201, 202, 231, 265, 266, 270, 273, 324, 348, 349, 350, 450, 451, 452, 453, 454, 481, 482, 483, 553, 554, 561, 569, 573, 588, 595, 600, 620, 639, 649, 666, 667, 669, 670, 672, 695], "arbitrari": [156, 275, 364, 370, 394, 419, 480, 539, 650, 672, 685, 710, 712], "architectur": [363, 472, 617], "arcsin": 95, "arctang": [97, 98], "aren": 704, "arg": [293, 340, 341, 361, 363, 379, 387, 389, 394, 398, 417, 419, 420, 428, 431, 432, 433, 435, 442, 444, 457, 459, 460, 461, 463, 467, 468, 469, 470, 477, 487, 497, 520, 525, 539, 546, 548, 651, 684, 691, 694], "argmax": [301, 421, 662], "argmin": 306, "argsort": 662, "argument": [2, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 94, 95, 96, 97, 98, 99, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 117, 121, 124, 126, 127, 128, 129, 130, 132, 134, 135, 139, 142, 144, 145, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 170, 171, 172, 174, 175, 176, 178, 183, 186, 194, 195, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 209, 210, 211, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 241, 243, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 292, 294, 295, 297, 298, 301, 302, 303, 304, 306, 307, 308, 309, 312, 313, 314, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 342, 343, 344, 347, 355, 356, 357, 358, 359, 360, 363, 371, 374, 377, 379, 386, 389, 390, 391, 392, 393, 398, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 424, 425, 426, 429, 434, 435, 436, 444, 468, 476, 480, 482, 483, 487, 490, 491, 497, 518, 520, 524, 525, 529, 533, 539, 548, 552, 554, 557, 558, 560, 561, 565, 566, 569, 570, 572, 573, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 593, 594, 601, 603, 608, 612, 623, 625, 626, 627, 629, 633, 634, 635, 636, 637, 638, 640, 641, 643, 644, 645, 646, 647, 649, 650, 657, 662, 663, 664, 665, 667, 668, 669, 671, 672, 674, 675, 676, 677, 678, 680, 683, 687, 689, 690, 694, 695, 696, 697, 699, 700, 704, 711], "arithmet": [110, 113, 127, 598, 711], "armand": 332, "around": [4, 197, 198, 601], "arrai": [93, 94, 108, 126, 146, 150, 173, 195, 204, 205, 275, 305, 374, 379, 380, 398, 399, 594, 601, 620, 634, 635, 637, 638, 662, 665, 672, 680, 688], "arrang": 116, "array_lik": [93, 634, 635, 636, 637, 638, 665], "array_list": [634, 635, 637, 638], "array_split": 666, "arrow": 173, "art": 579, "artifact": 646, "arxiv": [398, 448, 475, 514, 550, 562, 616, 651], "as_integer_ratio": 712, "as_tensor": [545, 665], "as_tupl": [552, 697], "ascend": [90, 312, 608, 633, 683], "ascii": 275, "ashish": [472, 474, 476], "asin": [9, 10, 82], "asinh": 83, "aspect": 445, "assert": [4, 694], "assign": [332, 363, 428, 435, 438, 439, 498, 499, 518, 704], "associ": [137, 216, 229, 230, 275, 347, 513, 711], "assp": 263, "assum": [142, 156, 257, 263, 276, 347, 420, 481, 497, 515, 518, 543, 562, 672, 674, 712], "assume_uniqu": 257, "assumpt": [347, 381], "ast_1": [362, 378], "ast_2": [362, 378], "asymmetr": 707, "asynchron": [3, 712], "atan": [11, 12, 84], "atan2": 85, "atanh": 86, "aten": 706, "atleast_2d": 696, "atleast_3d": 172, "atol": [73, 255], "attach": 487, "attempt": [131, 137, 146, 293, 500, 501, 687], "attend": 434, "attent": [0, 341, 434, 472, 474, 476], "attn": [474, 476], "attn_mask": 434, "attn_output": 434, "attn_output_weight": 434, "attr": [275, 305, 601], "attribut": [202, 263, 276, 364, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 428, 472, 497, 498, 499, 518, 519, 540, 646, 687], "au": 579, "audio": 703, "author": [579, 694], "auto": [173, 340, 341, 711], "autobatch": 694, "autocast": [434, 703], "autograd": [68, 79, 93, 94, 103, 104, 106, 115, 134, 174, 175, 176, 186, 205, 206, 207, 225, 226, 264, 274, 290, 298, 308, 381, 434, 476, 497, 557, 558, 581, 582, 583, 584, 585, 586, 587, 588, 619, 634, 635, 636, 637, 638, 665, 694, 699, 700, 704], "automat": [137, 230, 305, 475, 498, 499, 591, 620, 703, 711], "autotun": 137, "avail": [173, 293, 472, 481, 562, 616, 646, 651, 687, 712], "averag": [150, 329, 330, 331, 337, 338, 339, 340, 341, 342, 343, 344, 361, 363, 371, 381, 387, 393, 394, 395, 396, 397, 401, 402, 403, 419, 420, 431, 432, 433, 435, 442, 460, 461, 468, 477, 497, 672], "avg_pool3d_backward_cuda": 687, "avgpool3d": 687, "avoid": [79, 118, 137, 275, 362, 393, 394, 419, 437, 442, 480, 497, 513, 594, 622, 646, 657, 665, 683], "aw": 150, "awar": [476, 654, 655, 657, 658, 659], "aweight": 150, "ax": [130, 294, 305, 436, 447, 674], "axbc": 539, "axi": [141, 172, 187, 191, 208, 232, 574, 594, 599, 600, 696], "axis0": 652, "axis1": 652, "b": [64, 65, 94, 105, 116, 117, 119, 123, 125, 127, 130, 135, 142, 145, 151, 165, 168, 172, 173, 196, 197, 198, 199, 205, 209, 232, 243, 263, 264, 265, 267, 276, 285, 287, 288, 294, 302, 307, 309, 313, 341, 345, 370, 378, 415, 512, 540, 541, 542, 543, 544, 545, 553, 573, 579, 592, 595, 611, 622, 630, 634, 635, 637, 638, 642, 646, 647, 649, 656, 657, 658, 667, 674, 675, 677, 691, 696], "b_": [379, 380, 398, 399, 416, 444, 446, 667], "b_0": 265, "b_1": 265, "b_hf": 398, "b_hg": 398, "b_hh": [379, 380, 398, 399, 444, 446], "b_hi": 398, "b_hn": 379, "b_ho": 398, "b_hr": 379, "b_hz": 379, "b_if": 398, "b_ig": 398, "b_ih": [379, 380, 398, 399, 444, 446], "b_ii": 398, "b_in": 379, "b_io": 398, "b_ir": 379, "b_iz": 379, "b_n": 265, "b_t": 265, "ba": 173, "back": [134, 137, 203, 275, 475, 503, 504, 505, 506, 704], "backend": [137, 173, 347, 355, 356, 357, 358, 359, 360, 497, 616], "background": [347, 358], "backpropag": 572, "backward": [65, 68, 105, 117, 177, 276, 284, 298, 308, 340, 341, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 370, 379, 380, 381, 394, 398, 399, 415, 419, 420, 435, 442, 444, 477, 478, 488, 492, 493, 497, 518, 551, 560, 572, 650, 687, 703, 704], "badli": 674, "bag": 371, "balanc": 137, "balnta": [477, 478], "bar": [150, 644, 645, 689, 690], "bartlett": 106, "base": [104, 137, 150, 171, 173, 194, 221, 231, 270, 278, 280, 282, 290, 341, 364, 401, 428, 431, 432, 433, 437, 445, 472, 474, 476, 497, 503, 504, 512, 520, 524, 526, 569, 604, 616, 650, 651, 666, 676, 678, 695, 704], "basepruningmethod": [525, 531], "basi": 276, "basic": [276, 497, 707], "batch": [65, 105, 117, 118, 125, 128, 129, 130, 137, 151, 161, 163, 173, 263, 276, 284, 293, 294, 298, 340, 341, 342, 343, 344, 347, 355, 356, 361, 363, 364, 366, 367, 368, 370, 371, 372, 374, 379, 380, 381, 382, 387, 388, 390, 391, 392, 393, 394, 398, 399, 400, 401, 402, 403, 410, 411, 412, 419, 420, 431, 432, 433, 434, 435, 437, 440, 441, 442, 443, 444, 446, 460, 461, 468, 472, 474, 476, 477, 478, 480, 496, 497, 512, 539, 540, 542, 543, 545, 560, 562, 572, 576, 634, 635, 637, 638, 642, 646, 650, 651, 671, 674, 675, 677, 691, 694], "batch1": [65, 105], "batch2": [65, 105], "batch_first": [379, 398, 434, 444, 445, 472, 474, 476, 540, 542, 543, 545], "batch_idx": 703, "batch_siz": [444, 539, 541, 542, 544, 694, 703], "batched_dot": 694, "batched_pow": 694, "batchmean": 393, "batchnorm": [468, 497, 498, 507, 508, 509, 510, 707], "batchnorm1d": 401, "batchnorm2d": [364, 402], "batchnorm3d": [403, 468], "batchsiz": [634, 635, 637, 638], "bceloss": 341, "becaus": [263, 275, 293, 342, 343, 344, 364, 468, 487, 497, 499, 588, 613, 616, 646, 694, 704], "becom": [90, 221, 355, 356, 357, 358, 359, 360, 363, 379, 398, 413, 433, 444, 457, 487, 633, 672], "been": [1, 3, 172, 177, 275, 379, 386, 398, 444, 497, 505, 506, 515, 520, 524, 526, 546, 547, 572, 646, 662, 696, 704], "befor": [135, 154, 155, 156, 165, 173, 192, 193, 196, 205, 303, 319, 322, 364, 370, 371, 374, 379, 428, 429, 468, 472, 480, 487, 490, 491, 492, 493, 497, 505, 506, 513, 547, 550, 570, 573, 599, 608, 618, 619, 634, 635, 637, 638, 646, 649, 672, 683, 703, 704], "begin": [79, 106, 145, 221, 227, 265, 339, 340, 341, 349, 350, 351, 361, 363, 369, 379, 380, 383, 384, 385, 386, 387, 388, 394, 398, 399, 414, 419, 422, 423, 435, 436, 444, 447, 460, 466, 471, 478, 497, 512, 620, 623, 646, 672, 683, 697, 703, 704], "behav": [424, 425, 426, 492, 493], "behavior": [3, 66, 92, 113, 119, 121, 123, 136, 151, 168, 173, 174, 175, 176, 196, 204, 205, 274, 275, 290, 298, 305, 364, 367, 388, 468, 481, 487, 488, 499, 550, 552, 553, 566, 572, 588, 595, 650, 672, 687], "behaviour": [72, 73, 78, 622], "being": [135, 142, 186, 197, 198, 255, 293, 302, 307, 337, 338, 339, 340, 341, 361, 363, 375, 376, 381, 387, 394, 419, 420, 431, 432, 433, 434, 435, 442, 460, 461, 477, 497, 520, 521, 522, 523, 524, 525, 526, 527, 532, 533, 572, 573, 644, 645, 646, 689, 690, 704, 712], "belong": 121, "below": [160, 161, 162, 163, 164, 173, 211, 221, 305, 358, 359, 360, 379, 381, 388, 398, 400, 424, 425, 426, 444, 460, 481, 518, 552, 613, 616, 662, 672, 675, 676, 677, 678], "ben": [375, 376], "benefici": [2, 505, 506], "benefit": [505, 506, 704], "bernoulli": [336, 365, 366, 367, 368, 372, 379, 398, 712], "bernoulli_": 712, "bert": 475, "bessel": [150, 264, 644, 645, 689, 690], "best": [124, 137], "beta": [65, 68, 69, 70, 105, 225, 264, 298, 308, 342, 343, 344, 382, 388, 390, 391, 392, 400, 416, 460, 465, 468, 576, 711, 712], "better": [103, 137, 253, 363, 462, 505, 506, 579, 704], "between": [1, 68, 69, 70, 74, 75, 79, 98, 125, 137, 150, 156, 173, 202, 203, 221, 228, 263, 321, 340, 341, 347, 355, 356, 357, 358, 359, 360, 362, 363, 366, 367, 368, 372, 374, 379, 388, 394, 404, 405, 406, 407, 408, 409, 419, 421, 422, 423, 431, 432, 433, 437, 457, 460, 461, 462, 477, 478, 480, 497, 505, 506, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 534, 535, 565, 573, 577, 578, 583, 584, 588, 613, 643, 644, 645, 646, 650, 671, 672, 689, 690, 711], "beyond": [363, 599], "bf": 477, "bf16": 703, "bfloat16": [248, 613, 616, 703, 711], "bfloat16tensor": 711, "bia": [332, 345, 355, 356, 357, 358, 359, 360, 379, 380, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 434, 444, 445, 446, 472, 474, 476, 487, 508, 510, 512, 513, 514, 528, 530, 532, 547, 550, 576], "bias": [342, 343, 344, 379, 380, 382, 390, 391, 392, 398, 399, 400, 443, 444, 446, 468, 496], "bias_hh": [380, 399, 444, 446], "bias_hh_l": [379, 398, 444], "bias_ih": [380, 399, 444, 446], "bias_ih_l": [379, 398, 444], "bias_mask": [528, 530], "bicub": [481, 687], "bidirect": [379, 398, 444, 445], "big": [634, 635, 636, 637, 638], "bij": 173, "bik": 173, "bilinear": [173, 481, 482, 687], "bin": [108, 228, 229, 230], "bin_edg": [229, 230], "binari": [107, 297, 340, 341, 528, 529, 530, 531, 532, 533, 534, 535], "binary16": 711, "binaryio": [275, 604], "bincount": 687, "bit": [2, 110, 113, 143, 144, 205, 246, 596, 597, 609, 616, 626, 704, 711], "bitwidth": 707, "bitwis": [109, 111, 112, 114, 712], "bjk": 173, "blackman": 115, "blank": 347, "blend": 363, "block": [3, 116, 265, 276, 355, 356, 357, 358, 359, 360, 374, 404, 405, 406, 407, 408, 409, 431, 480, 634, 635, 704, 707], "blocksiz": [634, 635], "blog": [142, 706], "bm": 173, "bmatrix": 265, "bmm": 687, "bmva": 478, "bmvc": 478, "bn": [173, 507, 509], "bn_b": [508, 510], "bn_ep": [508, 510], "bn_rm": [508, 510], "bn_rv": [508, 510], "bn_w": [508, 510], "bool": [1, 3, 72, 73, 74, 75, 76, 78, 79, 87, 88, 89, 90, 94, 103, 104, 106, 109, 111, 112, 114, 115, 121, 122, 128, 129, 130, 136, 137, 138, 142, 174, 175, 176, 179, 186, 203, 204, 205, 206, 207, 208, 225, 226, 229, 230, 247, 251, 254, 255, 257, 263, 264, 266, 274, 275, 276, 285, 286, 287, 288, 290, 291, 293, 295, 301, 303, 304, 306, 309, 314, 319, 320, 321, 322, 323, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 380, 381, 382, 384, 385, 386, 387, 390, 391, 392, 393, 394, 395, 396, 397, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 415, 419, 420, 421, 422, 423, 428, 431, 432, 433, 435, 437, 442, 443, 446, 447, 448, 449, 456, 460, 461, 468, 471, 472, 474, 475, 476, 477, 478, 481, 490, 496, 497, 498, 499, 503, 504, 507, 508, 512, 515, 517, 518, 519, 539, 540, 541, 542, 543, 545, 548, 553, 557, 558, 560, 562, 568, 570, 572, 573, 577, 578, 579, 581, 582, 583, 584, 585, 586, 587, 588, 608, 613, 617, 622, 633, 634, 635, 636, 637, 638, 644, 645, 646, 649, 650, 659, 665, 669, 674, 683, 684, 687, 688, 689, 690, 699, 700, 711, 712], "bool_tensor": 711, "boolean": [1, 3, 103, 109, 111, 112, 114, 142, 178, 210, 224, 255, 256, 257, 258, 259, 262, 269, 276, 292, 297, 325, 342, 343, 344, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 428, 443, 468, 496, 515, 518, 572, 644, 645, 669, 689, 690, 711, 712], "booltensor": [297, 697, 711], "both": [105, 150, 168, 174, 175, 176, 197, 198, 199, 209, 211, 221, 228, 243, 256, 257, 263, 266, 267, 274, 290, 298, 304, 337, 338, 342, 343, 344, 352, 355, 356, 357, 358, 359, 360, 374, 382, 388, 390, 391, 392, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 421, 422, 423, 468, 476, 480, 481, 484, 497, 507, 509, 518, 548, 577, 578, 616, 621, 646, 650, 671, 672, 703, 704, 707], "bother": 550, "bottom": 338, "bound": [121, 132, 187, 188, 337, 338, 339, 421, 422, 423, 447, 587, 608, 704], "boundari": [121, 221, 349, 350, 351, 352, 353, 354, 450, 451, 452, 453, 454, 455, 481, 484, 485, 486], "box": 694, "bparam": 276, "brain": 711, "branch": [142, 657], "break": [137, 601, 620, 712], "breviti": 150, "brief": 497, "briefli": [616, 704], "broadcast": [64, 65, 66, 67, 68, 69, 70, 76, 98, 105, 110, 113, 117, 118, 119, 120, 145, 167, 168, 173, 178, 196, 197, 198, 199, 208, 210, 224, 233, 269, 270, 292, 297, 298, 308, 313, 316, 325, 328, 341, 362, 381, 497, 561, 569, 592, 594, 647, 651, 667, 672, 697], "broadcast_buff": 497, "broadcast_tensor": 118, "broader": 712, "bsc": 634, "bsr": 635, "bucket": [332, 497], "bucket_cap_mb": 497, "buffer": [94, 205, 266, 275, 342, 343, 344, 364, 401, 402, 403, 468, 489, 497, 500, 507, 509, 515, 518, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536, 546, 548, 604, 633, 669, 707], "bug": 293, "build": [475, 707], "built": [138, 478], "builtin": [275, 588, 657], "bump": 103, "bvar": 276, "bypass": 173, "byte": [94, 203, 205, 275, 604, 704], "byte_arrai": 275, "bytesio": [275, 604], "bytetensor": [2, 220, 621, 711], "c": [64, 91, 94, 116, 127, 146, 165, 168, 173, 197, 198, 199, 209, 221, 267, 313, 329, 330, 331, 333, 334, 335, 337, 338, 339, 341, 342, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 363, 366, 367, 368, 372, 374, 375, 376, 382, 390, 391, 392, 395, 396, 397, 399, 400, 410, 411, 412, 416, 421, 422, 423, 424, 425, 426, 431, 432, 433, 435, 440, 441, 450, 451, 452, 453, 454, 455, 463, 468, 479, 480, 481, 482, 483, 484, 485, 486, 512, 541, 543, 544, 545, 552, 553, 560, 576, 592, 642, 646, 667, 684, 703, 706], "c0": 398, "c655": 276, "c676": 276, "c_": [146, 355, 356, 357, 358, 359, 360, 398, 440, 441], "c_0": [398, 399], "c_1": 399, "c_j": [337, 338, 339, 421, 422, 423], "c_n": 398, "c_t": 398, "cach": [137, 499, 518, 550], "cache_size_limit": 137, "calcul": [104, 125, 150, 161, 165, 173, 177, 257, 263, 281, 282, 284, 337, 338, 339, 341, 342, 343, 344, 347, 358, 359, 360, 374, 379, 381, 382, 390, 391, 392, 400, 468, 477, 480, 481, 513, 525, 547, 551, 553, 594, 644, 645, 676, 678, 689, 690, 704], "calculate_gain": 456, "call": [76, 103, 120, 137, 171, 203, 211, 231, 251, 263, 264, 275, 276, 305, 336, 342, 343, 344, 364, 365, 366, 367, 368, 370, 372, 374, 413, 424, 425, 426, 428, 435, 436, 457, 468, 478, 480, 488, 489, 490, 491, 492, 493, 494, 495, 497, 505, 506, 518, 525, 528, 529, 530, 532, 533, 534, 535, 541, 547, 548, 550, 551, 585, 612, 618, 619, 644, 645, 646, 667, 683, 687, 689, 690, 694, 695, 704, 707, 711], "callabl": [137, 142, 275, 276, 472, 474, 476, 478, 490, 694], "caller": [476, 636], "can": [2, 3, 66, 93, 94, 103, 104, 107, 124, 137, 143, 150, 156, 173, 174, 177, 178, 190, 203, 210, 211, 221, 224, 229, 230, 257, 263, 266, 269, 275, 292, 293, 295, 305, 321, 323, 324, 325, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 355, 356, 357, 358, 359, 360, 363, 364, 365, 369, 370, 371, 372, 375, 376, 379, 384, 385, 386, 388, 394, 396, 397, 398, 401, 402, 403, 414, 418, 419, 421, 422, 423, 424, 425, 426, 428, 429, 430, 433, 434, 435, 437, 438, 439, 442, 444, 446, 447, 448, 449, 456, 457, 460, 465, 468, 471, 472, 474, 475, 476, 478, 479, 481, 487, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 503, 518, 539, 540, 543, 546, 551, 553, 557, 560, 569, 573, 581, 585, 595, 601, 604, 613, 614, 616, 618, 620, 633, 634, 635, 636, 637, 638, 642, 644, 645, 646, 650, 651, 665, 669, 672, 674, 682, 683, 686, 689, 690, 694, 699, 703, 704, 707, 711, 712], "can_set_static_graph": 497, "cancel": 263, "cannot": [94, 142, 190, 203, 263, 314, 347, 370, 481, 497, 651, 711], "capabl": [505, 506, 579, 710, 712], "capsul": [94, 202], "captur": [1, 2, 137, 142], "cardin": 305, "cartesian": [123, 305, 566], "cartesian_prod": 305, "cascad": 457, "case": [79, 106, 108, 113, 145, 151, 173, 199, 227, 251, 275, 276, 281, 284, 293, 304, 314, 337, 338, 339, 340, 341, 355, 356, 357, 359, 360, 361, 363, 366, 367, 368, 369, 372, 374, 383, 384, 385, 386, 387, 388, 394, 395, 396, 397, 414, 419, 421, 422, 423, 434, 435, 436, 447, 460, 466, 471, 476, 478, 480, 497, 500, 501, 505, 506, 512, 515, 518, 519, 552, 553, 592, 595, 608, 610, 623, 636, 650, 651, 682, 683, 687, 697, 704], "cast": [122, 154, 155, 303, 319, 322, 553, 570, 636, 649, 654, 655, 711], "cat": [140, 141, 305, 448, 643], "categori": 711, "cauchi": 712, "cauchy_": 712, "caus": [91, 94, 205, 487, 552, 612, 613, 622, 646, 687, 711], "caution": 0, "caveat": [487, 546], "caylei": 512, "ccol_indic": [634, 637], "cd": 703, "cdot": [265, 340, 341, 362, 363, 385, 393, 431, 432, 433, 435, 566, 646], "cdoubl": [129, 130, 151, 294, 560, 650, 674, 711], "ceil": [13, 14, 337, 338, 339, 395, 396, 397, 421, 422, 423, 577, 578, 601], "ceil_mod": [337, 338, 339, 395, 396, 397, 421, 422, 423, 577, 578], "cell": [379, 380, 398, 399, 444, 446], "center": [263, 562, 646, 703], "central": 221, "certain": [65, 68, 103, 105, 117, 161, 263, 275, 298, 308, 355, 356, 357, 358, 359, 360, 380, 399, 415, 480, 552], "cfloat": [129, 130, 151, 237, 294, 560, 590, 650, 674, 693, 711], "chain": [127, 371, 457], "chang": [91, 137, 142, 143, 144, 151, 161, 203, 214, 221, 241, 263, 305, 367, 370, 388, 398, 460, 481, 487, 488, 497, 500, 501, 505, 506, 515, 518, 519, 548, 552, 572, 612, 613, 614, 616, 642, 644, 645, 646, 671, 689, 690, 704, 711, 712], "channel": [187, 342, 343, 344, 348, 355, 356, 357, 358, 359, 360, 365, 366, 367, 368, 372, 374, 382, 390, 391, 392, 400, 404, 405, 406, 407, 408, 409, 416, 436, 463, 468, 480, 481, 482, 483, 505, 506, 514, 524, 525, 526, 533, 534, 550, 574, 707], "channel_shuffl": 348, "channels_last": [497, 505, 506, 711], "channels_last_3d": [506, 711], "chao": 276, "char": 205, "charact": 620, "characterist": 651, "chartensor": 711, "cheap": 332, "check": [1, 3, 73, 253, 263, 293, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 487, 497, 515, 518, 531, 541, 634, 635, 636, 637, 638, 704], "check_invari": [634, 635, 636, 637, 638], "check_reduct": 497, "check_sparse_tensor_invari": [634, 635, 636, 637, 638], "checkout": 703, "checkpoint": [275, 497, 703, 704], "child": [428, 525], "children": 704, "choic": [429, 438, 579], "choke": [349, 451, 452, 453], "choleski": [129, 130, 276], "choos": [340, 651], "choosen": 651, "chosen": [161, 266, 365, 620, 633, 669], "chunk": [124, 364, 497, 639, 704], "chunk_siz": 694, "cifar10": 703, "circular": [349, 350, 351, 355, 356, 357, 404, 405, 406], "circumst": [137, 347, 355, 356, 357, 358, 359, 360], "ciss\u00e9": 332, "claim": [505, 506], "clamp": [133, 340, 381], "class": [1, 2, 3, 103, 104, 177, 332, 341, 342, 343, 344, 347, 363, 364, 367, 371, 390, 391, 392, 413, 428, 429, 430, 431, 432, 433, 435, 438, 439, 445, 461, 468, 473, 475, 476, 482, 483, 487, 497, 499, 515, 518, 520, 521, 522, 523, 524, 525, 526, 527, 539, 546, 551, 704, 707, 711, 712], "classif": [142, 341, 347, 363, 431, 433, 435, 461], "classmethod": [520, 521, 522, 523, 524, 525, 526, 527], "click": 712, "clip": [146, 502, 503, 504, 707], "clip_grad_norm_": [502, 503], "clip_grad_value_": 504, "clip_valu": 504, "clone": [2, 103, 104, 119, 370, 665, 674, 703, 711], "clone_st": 2, "cloned_coeffici": 674, "cloned_st": 2, "close": [255, 293, 341, 460, 478, 650, 674], "closer": [221, 478, 573], "closest": 125, "clr": 127, "cluster": 332, "cmake": 703, "cmake_prefix_path": 703, "cmath": 566, "cn": [398, 585], "cnn": 460, "co": [15, 16, 62, 115, 137, 142, 225, 226, 361, 362, 365, 566, 634, 635, 637, 638], "coalesc": [636, 682], "coalescion": 636, "code": [103, 137, 275, 457, 497, 619, 704, 711], "codec": 275, "coeffici": [146, 225, 674], "coin": 458, "col": [676, 678], "col2im": 374, "col_indic": [635, 638], "collect": [125, 174, 230, 305, 529, 557, 581, 585, 699, 706], "color": 392, "column": [135, 146, 150, 156, 186, 192, 193, 232, 276, 314, 437, 480, 512, 562, 572, 634, 635, 637, 638, 650, 651, 672, 676, 678, 688], "columns_prun": 534, "com": [305, 424, 425, 426, 472, 550, 612, 687, 703, 706, 711], "combin": [68, 230, 298, 308, 341, 374, 388, 476, 480, 525], "combinations_with_replac": 136, "come": [137, 173, 202, 275, 366, 367, 368, 372, 393], "comma": 173, "command": 703, "comment": [550, 612, 711], "common": [64, 79, 110, 113, 118, 145, 168, 173, 196, 197, 198, 199, 209, 267, 275, 313, 342, 343, 344, 347, 468, 488, 489, 491, 492, 493, 494, 495, 592, 604, 647], "commonli": [305, 704, 711], "commun": 497, "compar": [73, 79, 90, 103, 104, 177, 178, 197, 198, 210, 224, 255, 269, 292, 302, 307, 325, 497, 551, 651, 683], "compat": [118, 143, 144, 505, 506, 550, 595, 703, 712], "compil": [142, 712], "compiler_custom_backend": 137, "complet": [1, 3, 515, 548, 572, 616], "complex": [64, 71, 129, 130, 143, 144, 168, 174, 175, 176, 194, 199, 221, 237, 245, 256, 258, 259, 262, 263, 265, 274, 276, 284, 290, 302, 303, 307, 313, 319, 355, 356, 357, 394, 512, 553, 566, 579, 585, 586, 592, 613, 623, 646, 647, 650, 687, 691, 692, 693, 711], "complex128": [139, 194, 204, 245, 355, 356, 357, 566, 613, 711], "complex32": [355, 356, 357, 613], "complex64": [129, 130, 139, 204, 245, 355, 356, 357, 566, 613, 711], "complex_double_tensor": 711, "complex_float_tensor": 711, "complexfloat": 553, "complic": [616, 706], "compon": [472, 473, 474, 475, 476, 487, 562, 646, 692, 693, 703], "compos": [128, 329, 330, 331, 333, 334, 335, 337, 338, 339, 355, 356, 357, 358, 359, 360, 375, 376, 395, 396, 397, 416, 421, 422, 423, 477, 482, 483, 577, 578, 694, 703], "composit": 512, "compress": [634, 635, 637, 638, 671], "compris": 704, "comput": [60, 62, 76, 77, 103, 104, 109, 110, 111, 112, 113, 114, 125, 127, 128, 129, 130, 136, 144, 146, 151, 156, 165, 167, 170, 173, 177, 178, 194, 196, 197, 198, 200, 209, 210, 211, 221, 224, 227, 228, 229, 230, 243, 264, 265, 267, 269, 273, 274, 276, 284, 285, 286, 287, 288, 290, 291, 292, 293, 302, 303, 304, 307, 319, 321, 325, 332, 336, 337, 338, 339, 342, 343, 344, 358, 359, 360, 362, 363, 365, 370, 371, 379, 382, 390, 391, 392, 393, 395, 396, 397, 398, 400, 401, 402, 403, 410, 411, 412, 418, 421, 422, 423, 424, 425, 426, 434, 435, 437, 442, 443, 444, 462, 464, 468, 477, 478, 481, 487, 490, 496, 497, 499, 503, 505, 506, 507, 509, 512, 514, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 532, 533, 540, 546, 550, 551, 553, 560, 566, 572, 573, 577, 578, 592, 593, 616, 623, 646, 650, 651, 667, 672, 691, 694, 704, 707, 710], "compute_mask": [520, 521, 522, 523, 524, 525, 526, 527], "compute_mod": 125, "compute_pivot": 293, "compute_uv": 650, "concat": [434, 704], "concaten": [124, 135, 172, 232, 347, 355, 356, 357, 358, 359, 360, 398, 503, 518, 643, 696], "concept": [706, 711, 712], "concret": [137, 481], "concurr": 704, "conda": 703, "conda_prefix": 703, "condit": [4, 73, 142, 263, 476, 541, 546, 674, 697], "condition": [104, 142], "conduct": [497, 562, 651], "confer": 381, "confid": [505, 506, 704], "config": 137, "configur": [137, 497, 539, 617, 687], "conform": 539, "conj": [71, 144, 596, 597], "conj_phys": 143, "conjug": [71, 129, 130, 143, 144, 246, 276, 512, 560, 596, 646, 650, 691], "conjunct": 497, "connect": [355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409, 457], "connectionist": 347, "conquer": 650, "consecut": [541, 672, 683, 684], "consequ": [398, 650], "consid": [73, 150, 160, 161, 162, 163, 164, 255, 259, 262, 363, 374, 431, 480, 498, 499, 512, 520, 521, 522, 523, 524, 525, 526, 527, 548, 610, 642, 646, 675, 676, 677, 678, 704, 711], "consider": [98, 263, 371, 497, 505, 506], "consist": [128, 129, 130, 142, 476, 515, 518, 572, 650, 704], "const": 381, "constant": [156, 191, 192, 193, 263, 276, 352, 353, 354, 371, 374, 381, 437, 460, 477, 480, 513, 672], "constitu": 704, "constrain": 465, "constraint": [142, 497, 513, 539, 704], "construct": [92, 93, 139, 160, 176, 230, 268, 274, 275, 290, 305, 370, 371, 487, 497, 500, 501, 539, 546, 562, 566, 613, 634, 635, 636, 637, 638, 651, 665, 668, 694, 704, 711], "constructor": [433, 438, 439, 457, 482, 483, 497, 546, 711], "consum": [173, 704], "consume_prefix_in_state_dict_if_pres": 497, "consumpt": 551, "contain": [2, 65, 76, 91, 105, 106, 107, 115, 117, 121, 145, 146, 150, 173, 194, 203, 225, 226, 229, 230, 237, 241, 257, 264, 275, 293, 297, 304, 314, 320, 332, 341, 363, 364, 370, 371, 374, 379, 380, 382, 387, 398, 399, 420, 428, 429, 430, 435, 438, 444, 446, 457, 461, 480, 487, 490, 491, 497, 505, 506, 513, 514, 515, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 546, 547, 550, 552, 562, 565, 590, 604, 608, 645, 646, 650, 667, 674, 676, 678, 683, 684, 685, 690, 694, 703, 704, 706, 710, 711, 712], "content": [642, 671, 701, 710], "context": [103, 104, 177, 487, 497, 499, 516, 518, 551, 711, 712], "context_id": 497, "contigu": [373, 431, 497, 505, 506, 589, 595, 650], "contiguous_format": [174, 497, 505, 506, 711], "continu": [221, 346, 347, 704, 712], "contract": [173, 667], "contrast": [379, 704], "contribut": [229, 230, 363, 370, 371, 435], "control": [1, 3, 90, 94, 106, 115, 142, 160, 161, 162, 163, 164, 225, 226, 293, 332, 355, 356, 357, 358, 359, 360, 374, 414, 422, 423, 480, 497, 560, 616, 617, 633, 646, 650, 669, 675, 676, 677, 678], "conv": [355, 356, 357, 358, 359, 360, 429, 435, 507, 508], "conv1": [428, 457], "conv1d": [358, 366, 404, 687], "conv2": [428, 457], "conv2d": [359, 367, 405, 428, 429, 435, 457, 480, 505, 533, 687], "conv3d": [360, 368, 406, 506, 687], "conv_b": 508, "conv_w": 508, "conveni": [487, 616, 694], "convent": [126, 173, 195, 342, 343, 344, 390, 391, 392, 468, 601, 604, 680], "converg": [276, 460, 512], "converged_count": 276, "convers": [122, 251, 505, 506, 539], "convert": [93, 94, 123, 136, 157, 202, 428, 438, 439, 468, 475, 487, 500, 501, 505, 506, 574, 575, 580, 634, 635, 636, 637, 638, 685, 707], "convert_sync_batchnorm": 468, "convolut": [137, 355, 356, 357, 358, 359, 360, 366, 367, 368, 372, 404, 405, 406, 407, 408, 409, 440, 441, 447, 477, 478, 480, 505, 506, 507, 508, 616], "convolv": [355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409], "convtranspos": [513, 547], "convtranspose1d": [407, 687], "convtranspose2d": [408, 505, 687], "convtranspose3d": [409, 506, 687], "coo": [634, 635, 636, 637, 638, 711], "coord": 221, "coordin": [98, 221, 230, 305, 566, 636, 676, 678, 685], "copi": [93, 94, 103, 104, 126, 134, 137, 190, 191, 192, 193, 195, 275, 276, 324, 364, 374, 480, 497, 539, 549, 589, 595, 601, 665, 674, 680, 704, 711], "copy_": 481, "core": [137, 706, 712], "corner": [116, 481], "corrcoef": 150, "correct": [3, 150, 241, 364, 381, 393, 487, 497, 539, 619, 644, 645, 689, 690], "correctli": 703, "correl": [146, 355, 356, 357, 358, 359, 360, 366, 367, 368, 372], "correspond": [94, 145, 168, 221, 230, 255, 274, 276, 290, 305, 314, 341, 364, 370, 398, 451, 475, 497, 513, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 547, 553, 565, 566, 576, 599, 608, 613, 623, 636, 644, 645, 650, 682, 685, 686, 689, 690, 704], "corrupt": 364, "cosh": [17, 18, 63], "cosin": [62, 63, 147, 148, 361, 362], "cosine_similar": 478, "cost": [127, 137, 347, 355, 356, 357, 358, 359, 360, 612, 704, 711], "could": [263, 275, 293, 505, 506, 651, 683], "count": [108, 149, 205, 229, 230, 539, 683, 684, 704], "count_include_pad": [337, 338, 339], "counter": [103, 364], "counterpart": [497, 707, 710, 712], "cov": 146, "covari": [118, 146, 150, 342, 343, 344, 468, 562], "cover": [173, 421, 704], "cpu": [1, 2, 79, 94, 106, 115, 148, 174, 176, 186, 199, 203, 205, 206, 216, 218, 219, 220, 225, 226, 242, 264, 274, 275, 290, 293, 304, 364, 370, 497, 503, 504, 539, 540, 554, 557, 572, 581, 583, 585, 587, 588, 612, 617, 618, 619, 621, 629, 634, 635, 636, 637, 638, 650, 665, 666, 667, 676, 678, 683, 687, 699, 704, 711, 712], "creat": [2, 92, 93, 94, 103, 104, 116, 118, 129, 130, 134, 135, 137, 145, 161, 176, 203, 204, 205, 206, 263, 268, 274, 290, 305, 314, 340, 361, 374, 388, 394, 419, 420, 431, 432, 433, 457, 460, 461, 468, 477, 478, 480, 497, 518, 539, 546, 551, 611, 612, 630, 636, 665, 672, 704, 706, 710, 712], "creation": [497, 499, 520], "crelu": 448, "criteria": [276, 651], "criterion": [276, 340, 341, 361, 363, 388, 394, 419, 420, 431, 432, 433, 460, 461, 477, 478, 579, 703], "critic": [513, 547], "cross": [340, 355, 356, 357, 358, 359, 360, 363], "crossentropyloss": [435, 703], "crow_indic": [635, 638], "crucial": 2, "csc": 637, "csr": [371, 638], "ctc_loss": 347, "ctcloss": 687, "cube": [331, 335, 579], "cubic": 376, "cubla": 687, "cublas_workspace_config": [505, 506, 687], "cuda": [1, 2, 3, 79, 91, 93, 106, 108, 115, 137, 174, 175, 176, 186, 203, 206, 216, 225, 226, 264, 266, 274, 275, 290, 293, 309, 347, 355, 356, 357, 358, 359, 360, 364, 370, 487, 497, 500, 501, 503, 504, 505, 506, 552, 554, 557, 572, 581, 583, 585, 587, 588, 612, 616, 621, 634, 635, 636, 637, 638, 650, 665, 667, 676, 678, 683, 687, 699, 703, 704, 710, 711, 712], "cuda1": 711, "cuda_visible_devic": 497, "cudacachingalloc": 704, "cudagraph": 137, "cudnn": [347, 355, 356, 357, 358, 359, 360, 505, 506, 616], "cumsum": [156, 687], "cumul": [152, 153, 154, 155, 156, 283, 342, 343, 344, 377, 401, 402, 403, 468], "cupi": 93, "current": [1, 2, 3, 79, 93, 94, 106, 115, 142, 174, 176, 186, 203, 204, 206, 214, 215, 216, 217, 225, 226, 249, 250, 264, 274, 276, 290, 305, 367, 370, 374, 468, 476, 480, 497, 519, 523, 524, 525, 526, 527, 532, 533, 534, 535, 557, 572, 581, 583, 585, 587, 588, 612, 616, 634, 635, 636, 637, 638, 646, 665, 676, 678, 683, 699, 704, 711, 712], "current_devic": 711, "current_st": 2, "cusolv": 650, "custom": [137, 472, 476, 477, 478, 520, 529, 546, 706], "custom_decod": 472, "custom_encod": 472, "cutoff": 332, "cwd": 604, "cx": 399, "d": [65, 69, 79, 94, 105, 106, 108, 115, 116, 117, 121, 124, 127, 160, 162, 172, 173, 186, 191, 192, 193, 208, 225, 226, 232, 241, 263, 297, 308, 316, 331, 339, 340, 344, 357, 361, 362, 366, 367, 368, 370, 372, 374, 379, 381, 392, 398, 400, 412, 423, 437, 443, 444, 468, 477, 478, 480, 496, 513, 547, 552, 553, 561, 579, 585, 588, 600, 608, 613, 642, 646, 660, 661, 667, 670, 675, 676, 677, 678, 688, 694, 696, 703, 704], "d_": [331, 335, 339, 351, 354, 357, 360, 397, 423, 426, 452, 455, 481, 486, 675, 676, 677, 678], "d_1": [363, 435], "d_2": [363, 435], "d_k": [363, 435], "d_model": [472, 473, 474, 475, 476], "danger": 0, "data": [79, 93, 94, 106, 115, 121, 154, 155, 174, 175, 176, 186, 187, 188, 190, 191, 192, 193, 202, 203, 205, 206, 207, 225, 226, 228, 245, 248, 264, 274, 275, 276, 290, 295, 303, 305, 319, 321, 322, 345, 347, 355, 356, 357, 364, 382, 390, 391, 392, 400, 415, 435, 481, 497, 498, 499, 500, 501, 505, 506, 539, 540, 541, 542, 544, 553, 557, 558, 562, 570, 573, 574, 575, 581, 582, 584, 585, 586, 587, 588, 595, 608, 634, 635, 636, 637, 638, 649, 650, 665, 674, 676, 678, 686, 687, 699, 700, 703, 710, 711, 712], "data_dependent_output": 712, "data_ptr": 94, "dataload": [497, 703], "dataparallel": [497, 542], "dataset": [332, 341, 393, 703], "datatyp": [94, 263, 500, 501, 616], "david": 332, "ddot": 265, "ddp": [468, 497], "ddp_logging_data": 497, "ddp_model": 497, "ddp_sync_bn_network": 468, "deadlock": 497, "deal": 667, "dealloc": 205, "debug": [137, 215, 490, 491, 492, 493, 615, 622], "debug_mod": 615, "decai": 436, "decemb": 579, "decid": 529, "decim": 601, "decod": [275, 472, 473, 474], "decoder_lay": [473, 474], "decompos": 201, "decomposit": [128, 129, 130, 211, 293, 295, 512, 560, 562, 566, 572, 650, 651], "deconvolut": [358, 359, 360], "decor": [103, 177, 551], "decoupl": [514, 550], "decreas": [366, 367, 368, 372, 441, 540, 541, 711], "deduc": 308, "deep": [342, 343, 344, 369, 468], "def": [103, 137, 142, 177, 428, 429, 430, 438, 439, 444, 478, 487, 518, 551, 694], "default": [1, 3, 73, 76, 79, 93, 94, 106, 115, 121, 125, 128, 129, 130, 134, 137, 150, 151, 154, 155, 156, 161, 162, 163, 164, 165, 168, 173, 174, 175, 176, 186, 203, 205, 206, 207, 211, 213, 214, 220, 221, 225, 226, 229, 230, 242, 255, 257, 263, 264, 265, 274, 275, 276, 290, 293, 295, 301, 303, 304, 305, 309, 318, 319, 321, 322, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 436, 437, 442, 443, 444, 446, 447, 448, 449, 456, 460, 461, 465, 466, 468, 471, 472, 474, 475, 476, 477, 478, 480, 481, 490, 496, 497, 498, 499, 500, 501, 503, 504, 507, 508, 512, 513, 514, 515, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 540, 541, 543, 545, 546, 547, 548, 550, 552, 553, 557, 558, 560, 562, 570, 572, 573, 577, 578, 579, 581, 582, 583, 584, 585, 586, 587, 588, 591, 594, 600, 601, 604, 608, 612, 613, 614, 615, 616, 620, 622, 634, 635, 636, 637, 638, 643, 644, 645, 646, 649, 650, 651, 665, 666, 672, 674, 676, 678, 683, 684, 687, 688, 689, 690, 694, 699, 700, 703, 704, 711, 712], "default_gener": 712, "default_mask": [520, 521, 522, 523, 524, 525, 526, 527], "default_protocol": 604, "defin": [156, 173, 174, 199, 206, 209, 211, 227, 229, 230, 255, 267, 275, 309, 364, 369, 375, 376, 383, 384, 385, 386, 393, 395, 396, 397, 434, 447, 462, 464, 469, 471, 487, 490, 497, 524, 526, 533, 534, 554, 557, 572, 581, 583, 585, 592, 620, 672, 675, 676, 677, 678, 697, 699, 704, 706, 710, 712], "definit": [128, 129, 130, 150, 199, 265, 276, 314, 393, 553, 592, 672], "degre": [150, 157, 437, 477, 580, 600, 644, 645, 689, 690], "delai": 497, "delay_all_reduce_named_param": 497, "delta": [150, 379, 388, 398, 460, 644, 645, 672, 689, 690], "demonstr": 347, "denomin": [66, 342, 343, 344, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 443, 468, 496, 576], "denorm": 617, "denot": [150, 265, 355, 356, 393, 515, 518, 634, 635, 637, 638, 691], "dens": [106, 115, 225, 226, 264, 276, 634, 635, 637, 638, 651, 687, 711], "dense_dim": 636, "denses": [634, 635, 637, 638], "densiti": [229, 230], "depend": [1, 92, 293, 298, 340, 341, 361, 363, 374, 387, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 480, 481, 487, 497, 518, 519, 525, 560, 562, 595, 634, 635, 637, 638, 650, 674, 697, 703, 704], "deprec": [127, 128, 151, 212, 293, 294, 340, 341, 361, 363, 386, 387, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 482, 483, 488, 497, 502, 547, 548, 550, 553, 572, 588, 614, 646, 650, 674], "depth": [3, 339, 357, 360, 397, 423, 481], "depthwis": [171, 172, 355, 356, 357], "deriv": [221, 263, 293, 476, 487], "descend": [90, 633, 650], "describ": [122, 173, 221, 265, 332, 337, 338, 339, 340, 341, 342, 343, 344, 355, 356, 357, 358, 359, 360, 363, 365, 366, 367, 368, 369, 372, 374, 375, 376, 382, 385, 388, 390, 391, 392, 394, 400, 419, 421, 422, 423, 434, 435, 442, 443, 447, 460, 468, 476, 477, 478, 480, 496, 672], "descript": [3, 238, 239, 240, 276, 572, 616], "descriptor": [477, 478], "deseri": [275, 487], "design": [264, 341, 662, 704], "desir": [1, 2, 3, 79, 93, 106, 115, 134, 154, 155, 174, 175, 176, 186, 203, 205, 206, 207, 225, 226, 264, 274, 290, 296, 303, 319, 321, 322, 340, 341, 479, 487, 539, 553, 557, 558, 563, 570, 573, 574, 575, 581, 582, 583, 584, 585, 586, 587, 588, 621, 634, 635, 636, 637, 638, 649, 665, 676, 678, 699, 700, 711], "destin": [208, 310, 311], "destroi": 364, "det": 284, "detach": [134, 347, 665], "detach_": 497, "detail": [3, 87, 120, 148, 156, 173, 190, 211, 215, 217, 221, 247, 254, 276, 282, 284, 304, 314, 332, 336, 346, 358, 359, 360, 364, 370, 371, 372, 373, 375, 376, 379, 398, 440, 441, 444, 456, 477, 487, 492, 493, 497, 499, 542, 552, 560, 572, 604, 615, 629, 672, 683, 687, 701, 703, 704, 706, 712], "detect": [137, 497, 687], "detector": 365, "determin": [106, 115, 122, 127, 175, 207, 225, 226, 229, 230, 284, 298, 375, 376, 437, 517, 520, 521, 522, 523, 524, 525, 526, 527, 548, 558, 582, 584, 586, 613, 634, 635, 636, 637, 638, 646, 700, 704, 711], "determinist": [2, 87, 127, 173, 174, 175, 176, 215, 247, 293, 301, 304, 306, 347, 351, 352, 353, 355, 356, 357, 358, 359, 360, 370, 371, 454, 455, 484, 485, 513, 546, 609, 615, 687, 704], "dev": 703, "develop": 703, "deviat": [336, 342, 343, 344, 382, 390, 391, 392, 400, 468, 554, 644, 645], "devic": [1, 2, 3, 65, 68, 79, 91, 93, 94, 105, 106, 108, 115, 117, 137, 174, 175, 176, 186, 203, 206, 207, 213, 216, 225, 226, 264, 274, 275, 290, 293, 296, 298, 304, 308, 332, 342, 343, 344, 345, 355, 356, 357, 358, 359, 360, 364, 370, 371, 379, 380, 382, 390, 391, 392, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 434, 436, 443, 444, 445, 446, 468, 472, 474, 476, 487, 496, 497, 500, 501, 503, 504, 505, 506, 539, 546, 552, 554, 557, 558, 572, 581, 582, 583, 584, 585, 586, 587, 588, 609, 612, 616, 634, 635, 636, 637, 638, 650, 665, 667, 676, 678, 687, 699, 700, 704, 712], "device_id": [275, 364, 468, 497], "device_mesh": 497, "device_typ": [703, 712], "dfrac": [362, 513, 514, 547, 550], "diag": [562, 650, 651], "diag_emb": [163, 650], "diagflat": 160, "diagon": [116, 146, 150, 160, 161, 162, 164, 173, 186, 211, 670, 674, 675, 676, 677, 678], "dict": [137, 142, 275, 276, 364, 374, 429, 438, 480, 487, 497, 529, 548, 694], "dictat": 497, "dictionari": [137, 275, 276, 370, 371, 429, 438, 529], "did": 321, "didn": 704, "differ": [65, 68, 74, 75, 79, 93, 94, 105, 117, 118, 150, 156, 161, 163, 165, 173, 191, 192, 193, 197, 198, 205, 221, 241, 298, 308, 332, 341, 342, 343, 344, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 364, 379, 380, 388, 390, 391, 392, 393, 398, 399, 415, 431, 434, 450, 451, 453, 454, 455, 457, 460, 468, 474, 476, 478, 481, 484, 485, 486, 487, 497, 500, 501, 512, 548, 553, 562, 572, 594, 644, 645, 650, 672, 683, 684, 687, 689, 690, 694, 711], "differenti": [134, 293, 346, 347, 370, 497, 518, 687], "difficult": 694, "digit": [121, 620], "dilat": [355, 356, 357, 358, 359, 360, 374, 404, 405, 406, 407, 408, 409, 421, 422, 423, 480, 577, 578], "dim": [72, 74, 75, 76, 78, 88, 89, 90, 124, 131, 140, 142, 149, 151, 152, 153, 154, 155, 156, 165, 171, 190, 191, 208, 221, 231, 238, 239, 240, 241, 243, 266, 283, 291, 301, 303, 304, 306, 309, 311, 312, 319, 320, 321, 322, 323, 324, 362, 363, 364, 367, 371, 373, 378, 393, 399, 418, 434, 435, 436, 462, 464, 476, 478, 479, 497, 513, 514, 520, 524, 526, 533, 534, 547, 550, 553, 563, 570, 573, 593, 594, 599, 600, 605, 606, 607, 610, 611, 630, 632, 633, 639, 642, 643, 644, 645, 646, 649, 662, 666, 667, 668, 669, 672, 673, 681, 682, 683, 684, 686, 689, 690, 694, 695, 711], "dim0": [653, 671], "dim1": [161, 163, 164, 653, 671], "dim2": [161, 163, 164], "dim_feedforward": [472, 474, 476], "dimens": [65, 71, 72, 74, 75, 76, 78, 88, 89, 90, 91, 100, 101, 102, 116, 124, 127, 128, 129, 130, 131, 151, 152, 153, 154, 155, 156, 161, 162, 163, 164, 165, 171, 173, 190, 208, 221, 230, 231, 241, 243, 263, 265, 266, 283, 284, 291, 294, 298, 301, 303, 304, 305, 306, 309, 311, 312, 319, 320, 321, 322, 323, 324, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 356, 357, 359, 360, 361, 362, 363, 364, 367, 369, 373, 374, 377, 378, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 398, 400, 408, 409, 414, 415, 416, 417, 418, 419, 422, 423, 427, 434, 435, 436, 437, 440, 441, 442, 443, 447, 448, 449, 451, 456, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 474, 476, 477, 478, 479, 480, 496, 505, 506, 512, 513, 514, 520, 521, 522, 523, 524, 525, 526, 527, 533, 534, 540, 541, 543, 545, 547, 550, 552, 553, 560, 563, 570, 572, 573, 574, 579, 593, 594, 595, 599, 608, 610, 611, 620, 630, 633, 634, 635, 636, 637, 638, 639, 642, 643, 644, 645, 646, 649, 650, 660, 662, 666, 667, 668, 669, 671, 672, 674, 675, 676, 677, 678, 681, 682, 683, 684, 685, 686, 689, 690, 691, 692, 693, 694, 695, 711], "dimension": [94, 100, 101, 102, 116, 123, 135, 161, 163, 164, 173, 190, 192, 193, 205, 221, 230, 231, 274, 290, 298, 305, 332, 349, 350, 351, 352, 353, 354, 363, 364, 400, 418, 435, 443, 450, 451, 452, 453, 454, 455, 462, 464, 468, 484, 485, 486, 496, 512, 552, 579, 634, 635, 636, 637, 638, 646, 662, 665, 666, 672, 710, 711, 712], "direct": [192, 193, 379, 398, 444, 514, 550, 562, 579, 600, 704], "directli": [156, 202, 211, 462, 481, 540, 672, 704], "directori": 703, "dirnam": 703, "dirti": 604, "disabl": [103, 104, 137, 173, 177, 434, 468, 476, 499, 548, 551, 617, 620], "disallow": 711, "disambigu": 281, "discard": [263, 516], "disclaim": 173, "discov": 137, "discrep": 579, "discret": 712, "discrimin": [513, 547], "discuss": [388, 704], "disk": [275, 604], "dispatch": 706, "dissimilar": 387, "dist": [128, 129, 130, 291, 294, 437, 468, 512, 650], "dist_autograd": 497, "dist_optim": 497, "distanc": [125, 263, 387, 437, 477, 478, 646, 650], "distance_funct": 478, "distant": 478, "distinct": [284, 341], "distribut": [74, 75, 107, 314, 332, 336, 341, 363, 364, 365, 366, 367, 368, 372, 377, 381, 393, 442, 447, 468, 497, 554, 565, 579, 581, 582, 583, 584, 585, 586, 712], "distributeddataparallel": [364, 468], "distributedoptim": 497, "distributedsampl": 497, "div": [169, 196, 199, 332, 440, 441, 592, 679, 711], "div_valu": 332, "diverg": 393, "divid": [168, 171, 196, 230, 231, 340, 341, 347, 348, 361, 387, 388, 394, 419, 420, 431, 432, 433, 442, 460, 461, 477, 478, 650, 695], "dividend": [168, 196, 199, 592, 679], "divis": [66, 131, 168, 196, 199, 355, 356, 357, 358, 359, 360, 362, 382, 394, 419, 437, 592, 639, 666], "divisor": [168, 196, 199, 209, 338, 339, 374, 480, 592, 679], "divisor_overrid": [338, 339], "dlpack": [94, 202], "dltensor": 202, "do": [103, 123, 136, 137, 152, 153, 154, 155, 202, 203, 205, 208, 230, 253, 263, 276, 283, 293, 295, 304, 314, 324, 336, 346, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 384, 385, 386, 414, 424, 447, 448, 449, 456, 471, 482, 487, 497, 505, 506, 554, 560, 566, 616, 687, 704, 706, 711], "doc": [137, 687, 694], "doctest": 347, "doctest_show": 305, "document": [87, 88, 89, 90, 122, 173, 211, 215, 217, 247, 254, 321, 332, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 492, 493, 515, 524, 533, 553, 571, 598, 615, 687, 707, 712], "doe": [74, 75, 94, 104, 117, 164, 173, 177, 205, 241, 270, 276, 293, 297, 298, 304, 308, 316, 342, 343, 344, 355, 356, 357, 358, 359, 360, 363, 367, 374, 379, 380, 390, 391, 392, 398, 399, 401, 402, 403, 410, 411, 412, 422, 423, 429, 435, 438, 444, 446, 468, 480, 497, 499, 505, 506, 515, 518, 522, 548, 551, 553, 558, 561, 566, 608, 611, 612, 616, 630, 650, 671, 674, 687, 694, 700, 704, 711], "doesn": [94, 142, 275, 284, 355, 356, 357, 364, 393, 462, 497, 498, 499, 529, 612, 694], "doi": [276, 381], "domain": [63, 99, 187, 188, 221], "don": [297, 390, 391, 392, 481, 487, 497, 554, 615], "done": [293, 342, 343, 344, 364, 367, 379, 390, 391, 392, 402, 403, 410, 411, 412, 413, 438, 468, 474, 476, 497, 642, 703, 711], "donot_use_mm_for_euclid_dist": 125, "dot": [152, 153, 154, 155, 243, 265, 298, 340, 341, 363, 374, 387, 394, 419, 434, 435, 478, 646, 691, 692, 693, 694], "doubl": [122, 129, 130, 139, 151, 188, 194, 221, 284, 285, 286, 287, 288, 294, 487, 560, 566, 634, 635, 637, 638, 650, 665, 674, 697, 704, 711], "double_tensor": 711, "doubler": [103, 177, 551], "doubletensor": [65, 66, 67, 68, 69, 105, 614, 711], "down": [168, 193, 199, 573, 601], "download": 703, "downsampl": [359, 481], "downscal": 441, "downscale_factor": 441, "draw": [107, 314, 579], "drawn": [314, 554, 579, 583, 584, 712], "driver": [211, 703], "drop": [336, 548, 616, 646], "dropout": [336, 366, 367, 368, 372, 379, 398, 434, 444, 445, 472, 474, 476], "dropout1d": 367, "dry": 487, "dstack": 305, "dtype": [66, 68, 71, 72, 76, 78, 79, 93, 94, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 122, 129, 130, 139, 142, 143, 144, 150, 151, 154, 155, 174, 175, 176, 186, 194, 199, 201, 203, 204, 205, 206, 207, 214, 225, 226, 237, 264, 274, 285, 286, 287, 288, 290, 293, 294, 298, 302, 303, 304, 307, 308, 314, 318, 319, 320, 322, 332, 341, 342, 343, 344, 345, 347, 348, 349, 350, 355, 356, 357, 358, 359, 360, 363, 370, 371, 374, 379, 380, 382, 390, 391, 392, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 434, 435, 436, 443, 444, 445, 446, 450, 451, 452, 453, 454, 468, 472, 474, 476, 480, 481, 482, 483, 487, 496, 500, 501, 505, 506, 515, 518, 519, 539, 553, 557, 558, 560, 566, 570, 571, 574, 575, 576, 577, 578, 581, 582, 583, 584, 585, 586, 587, 588, 590, 598, 601, 613, 614, 616, 617, 632, 634, 635, 636, 637, 638, 649, 650, 662, 665, 676, 678, 683, 687, 692, 693, 697, 699, 700, 703], "dtype_byt": 704, "dual": 551, "due": [94, 146, 293, 367, 381, 481, 546, 651], "duersch": 276, "duerschetal2018": 276, "duplic": [106, 115, 136, 225, 226, 683, 684], "dure": [275, 336, 342, 343, 344, 364, 365, 370, 371, 390, 391, 392, 447, 468, 474, 476, 487, 497, 500, 501, 546, 676, 678, 704], "dx": [156, 340, 672], "dynam": [137, 275, 512], "dynamic_output_shap": 712, "e": [94, 103, 116, 118, 121, 142, 173, 183, 202, 216, 218, 245, 246, 248, 251, 263, 275, 276, 277, 279, 281, 298, 309, 340, 341, 342, 343, 344, 347, 355, 356, 357, 363, 364, 366, 367, 368, 370, 371, 372, 374, 379, 382, 387, 390, 391, 392, 393, 394, 398, 400, 401, 402, 403, 419, 429, 434, 435, 437, 438, 442, 444, 460, 468, 476, 477, 478, 480, 487, 497, 498, 499, 500, 501, 505, 506, 513, 528, 529, 530, 532, 533, 534, 535, 539, 540, 546, 550, 553, 565, 576, 594, 601, 608, 612, 616, 618, 623, 636, 646, 650, 704, 706, 711], "e1_cuda": 1, "e2_cuda": 1, "e_cuda": [1, 3], "each": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 72, 74, 75, 78, 79, 91, 100, 101, 102, 105, 108, 117, 121, 125, 126, 128, 131, 135, 137, 150, 152, 153, 156, 157, 168, 171, 173, 192, 193, 195, 200, 205, 208, 221, 227, 229, 230, 231, 255, 256, 257, 258, 259, 260, 261, 262, 266, 275, 276, 291, 293, 301, 303, 304, 305, 306, 309, 311, 314, 320, 322, 332, 337, 340, 341, 345, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 370, 371, 372, 374, 379, 380, 382, 387, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 408, 409, 413, 415, 419, 420, 431, 432, 433, 434, 435, 436, 442, 444, 446, 457, 460, 461, 463, 468, 471, 477, 478, 480, 487, 497, 505, 506, 539, 540, 542, 552, 553, 554, 565, 569, 570, 573, 580, 588, 593, 594, 599, 603, 608, 616, 620, 626, 634, 635, 637, 638, 639, 649, 650, 666, 668, 669, 672, 683, 684, 685, 688, 694, 695, 704, 711], "eager": [137, 619, 703, 704], "earli": [366, 367, 368, 372], "earlier": [505, 506, 650, 704], "easier": 704, "easili": [435, 601], "ed": [366, 367], "edg": [221, 229, 230], "edge_ord": 221, "edgeitem": 620, "edouard": 332, "edu": [347, 579], "effect": [156, 305, 332, 347, 358, 359, 360, 365, 366, 367, 368, 372, 481, 490, 498, 499, 525, 650, 672, 694, 704, 706, 711], "effici": [127, 211, 276, 295, 332, 366, 367, 368, 371, 372, 379, 434, 440, 441, 444, 476, 710, 711, 712], "eg": [121, 601, 608], "eigenpair": 276, "eigenproblem": 276, "eigensolv": 276, "eigenvalu": [276, 562], "eigenvector": 276, "einstein": 173, "either": [103, 124, 137, 173, 205, 221, 243, 259, 274, 275, 290, 303, 305, 319, 330, 331, 334, 335, 338, 339, 340, 341, 355, 356, 357, 359, 360, 361, 363, 381, 387, 394, 396, 397, 419, 420, 422, 423, 431, 432, 433, 434, 435, 442, 444, 446, 460, 461, 476, 477, 479, 481, 482, 483, 491, 497, 531, 553, 569, 571, 616, 646, 650, 697], "elaps": 1, "elapsed_tim": 1, "element": [60, 62, 63, 66, 67, 72, 73, 77, 78, 88, 90, 91, 92, 95, 96, 97, 98, 99, 107, 116, 119, 126, 132, 136, 142, 144, 146, 147, 148, 152, 153, 154, 155, 156, 157, 160, 162, 163, 164, 168, 170, 173, 176, 178, 179, 183, 190, 195, 197, 198, 200, 203, 205, 208, 209, 210, 211, 221, 224, 227, 228, 229, 230, 243, 251, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 269, 277, 278, 280, 283, 285, 286, 287, 288, 292, 293, 301, 302, 303, 304, 305, 306, 307, 312, 314, 319, 320, 322, 323, 324, 325, 326, 336, 337, 340, 341, 342, 343, 344, 346, 347, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 369, 371, 372, 374, 379, 380, 383, 384, 385, 386, 387, 388, 393, 394, 398, 400, 404, 405, 406, 407, 408, 409, 414, 417, 419, 420, 421, 422, 423, 427, 431, 432, 433, 435, 436, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 456, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 477, 478, 480, 496, 520, 521, 522, 523, 524, 525, 526, 527, 532, 533, 539, 540, 542, 543, 552, 553, 554, 556, 565, 566, 569, 570, 577, 578, 580, 591, 594, 595, 599, 601, 603, 620, 623, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 640, 641, 644, 645, 649, 661, 663, 664, 668, 669, 670, 672, 674, 675, 676, 677, 678, 680, 682, 683, 684, 685, 689, 690, 691, 694, 697, 711, 712], "elementari": 211, "elementwis": [73, 145, 194, 196, 328, 390, 391, 392, 688], "elementwise_affin": [400, 443, 496], "elif": 393, "elimin": [683, 684], "ell": [340, 341, 363, 387, 388, 394, 419, 435, 460, 478], "ell_c": 341, "ellipsi": 173, "elman": [444, 446], "els": [108, 142, 393, 468, 596, 597, 704], "elsewher": [178, 186, 210, 224, 256, 258, 259, 262, 269, 292, 325], "emb": [164, 611, 630], "embed": [164, 332, 361, 371, 387, 400, 478, 611, 704], "embed_dim": 434, "embedding_dim": [370, 371, 400], "embedding_sum": 371, "embeddingbag": 687, "emit": 622, "empir": 447, "empti": [107, 108, 118, 124, 173, 175, 270, 285, 286, 287, 288, 295, 341, 363, 435, 546, 558, 636, 650, 665, 700, 712], "en": [3, 173], "enabl": [103, 104, 137, 142, 173, 177, 249, 250, 475, 497, 515, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 551, 617, 620, 687, 703, 704, 710, 712], "enable_grad": 712, "enable_nested_tensor": 475, "enable_tim": 1, "encod": [275, 340, 341, 472, 475, 476, 616, 634, 635, 637, 638], "encoder_lay": [475, 476], "encount": [505, 506], "end": [1, 79, 106, 145, 163, 173, 190, 205, 221, 227, 228, 263, 265, 270, 274, 276, 290, 323, 324, 339, 340, 341, 349, 350, 351, 361, 363, 369, 373, 379, 380, 383, 384, 385, 386, 387, 388, 394, 398, 399, 414, 419, 422, 423, 435, 436, 444, 447, 460, 466, 471, 478, 497, 512, 588, 620, 623, 630, 672, 683, 684, 697, 704], "end_dim": [190, 373], "end_ev": 1, "enforce_sort": [540, 541, 542], "engin": [579, 694], "enough": [478, 634, 635, 636, 637, 638, 687, 711], "ensur": [2, 3, 336, 341, 421, 431, 497, 505, 506, 619, 703], "enter": 103, "entir": [76, 137, 221, 366, 367, 368, 372, 390, 391, 392, 400, 497, 514, 524, 526, 550], "entri": [163, 192, 193, 241, 265, 370, 371, 524, 525, 533], "entropi": [340, 363, 432], "entrywis": [199, 592], "enumer": [430, 439, 703], "env": [1, 2, 3, 103, 293, 305, 505, 506, 512, 513, 518, 667], "envelop": 263, "environ": 687, "ep": [289, 328, 342, 343, 344, 362, 381, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 437, 442, 443, 468, 472, 474, 476, 477, 496, 513, 547, 576], "epilogue_fus": 137, "epsilon": [79, 342, 343, 344, 362, 382, 390, 391, 392, 400, 437, 443, 468, 496, 508, 510, 513, 547, 576], "epub": 276, "equal": [73, 74, 75, 90, 106, 113, 115, 126, 127, 139, 150, 162, 178, 195, 210, 225, 226, 228, 229, 230, 251, 255, 269, 293, 294, 305, 325, 329, 330, 331, 333, 334, 335, 340, 341, 347, 356, 357, 359, 360, 364, 371, 374, 375, 376, 379, 381, 398, 433, 434, 442, 444, 480, 497, 543, 560, 573, 639, 646, 666, 682, 697], "equal_nan": [73, 255], "equat": [130, 173, 211, 225, 340, 674], "equidist": 601, "equival": [1, 71, 90, 118, 120, 123, 125, 128, 135, 136, 142, 161, 165, 168, 171, 172, 173, 175, 207, 231, 232, 243, 264, 305, 310, 312, 319, 342, 343, 344, 355, 356, 357, 358, 359, 360, 363, 371, 382, 388, 390, 391, 392, 393, 398, 400, 444, 460, 468, 480, 482, 497, 558, 582, 585, 586, 610, 616, 623, 633, 652, 653, 660, 665, 684, 694, 695, 696, 700, 711], "erf": [19, 20], "erfc": [21, 22], "error": [0, 79, 92, 94, 137, 171, 231, 275, 293, 314, 340, 341, 347, 377, 388, 394, 419, 458, 460, 497, 500, 501, 503, 548, 553, 568, 608, 615, 636, 642, 646, 687, 694, 695], "error_if_nonfinit": [502, 503], "especi": [119, 137], "essenti": 293, "estim": [146, 150, 221, 263, 342, 343, 344, 377, 381, 382, 390, 391, 392, 400, 468, 513, 651], "et": [347, 440, 441, 477, 478, 651], "etc": [142, 263, 363, 428, 594, 712], "euclidean": 125, "eval": [342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 434, 468, 476, 507, 509, 513, 703], "evalu": [72, 78, 332, 336, 342, 343, 344, 365, 382, 390, 391, 392, 400, 428, 442, 447, 468, 516, 579, 712], "even": [150, 251, 298, 304, 364, 468, 505, 506, 512, 551, 553, 601, 612, 650, 692, 704, 711], "evenli": [74, 75, 171, 231, 274, 290, 695], "event": [3, 281, 712], "everi": [137, 156, 173, 221, 230, 293, 336, 365, 366, 367, 368, 372, 421, 462, 464, 468, 489, 490, 491, 494, 495, 497, 513, 547, 550, 551, 612, 650, 684, 704, 711], "everywher": 646, "exact": [3, 88, 89, 90, 137, 304, 359, 398, 476, 497, 712], "exactli": [131, 173, 197, 198, 263, 374, 375, 376, 457, 460, 497, 553, 616, 704], "exampl": [1, 2, 3, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 214, 221, 224, 227, 228, 229, 230, 231, 232, 233, 237, 241, 243, 251, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 273, 274, 275, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 497, 498, 505, 506, 512, 513, 514, 516, 518, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 554, 556, 557, 558, 561, 563, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 603, 604, 608, 610, 611, 612, 613, 614, 617, 620, 623, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 649, 650, 652, 653, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 704, 711, 712], "exce": 281, "except": [63, 72, 74, 75, 78, 99, 124, 131, 135, 165, 171, 173, 197, 198, 231, 266, 275, 291, 301, 303, 304, 306, 309, 319, 322, 324, 379, 398, 444, 481, 490, 513, 539, 546, 547, 551, 553, 570, 594, 610, 613, 636, 644, 645, 649, 672, 689, 690, 694, 695, 704, 711], "excess": 622, "exchang": 161, "exclud": [230, 371, 616, 675, 676, 677, 678], "exclus": [230, 497, 583, 584, 587], "execut": [3, 137, 275, 364, 490, 497, 618, 703, 704, 712], "exist": [92, 276, 321, 643, 704, 707], "exp": [23, 24, 194, 283, 291, 341, 346, 363, 369, 393, 417, 418, 432, 442, 456, 459, 461, 462, 464, 465, 469, 512, 569, 646], "expand": [92, 120, 305, 479, 682], "expect": [76, 191, 192, 193, 241, 263, 304, 343, 344, 363, 379, 380, 381, 382, 391, 392, 393, 398, 399, 400, 410, 411, 412, 434, 435, 443, 444, 446, 462, 468, 472, 474, 476, 481, 487, 496, 497, 540, 660, 692, 704], "expens": 512, "experi": [458, 497, 694], "experiment": [137, 497], "expit": 624, "explain": [616, 704], "explicit": [221, 253, 612, 667, 704, 711], "explicitli": [161, 163, 173, 230, 311, 498, 616, 646, 703, 704], "explod": 460, "expm1": [25, 26], "expon": [194, 201, 268, 332, 416, 569, 616, 711], "exponenti": [183, 281, 282, 283, 291, 346, 369, 712], "exponential_": 712, "export": [142, 540, 541, 703], "exportdb": 712, "expos": 205, "express": [142, 550, 646], "ext_tensor": 202, "extend": [439, 706], "extens": [275, 276, 604, 623], "extern": 202, "extra": [173, 275, 435, 512, 646, 694, 712], "extract": [129, 130, 370, 374, 480], "ey": [129, 130, 265, 512, 572, 694], "ezyang": 706, "f": [150, 221, 275, 393, 395, 396, 397, 399, 428, 478, 604, 656, 694], "f_t": 398, "facil": 275, "facilit": [161, 505, 506, 613], "fact": [106, 115, 144, 221, 225, 226, 704], "factor": [68, 69, 70, 105, 128, 293, 294, 295, 365, 388, 416, 440, 441, 572, 650], "factori": [173, 551, 612, 711], "fail": [275, 276, 293, 481, 711], "failur": [137, 704], "faithfulli": 657, "fake": [187, 188], "fake_quant": [187, 188], "fall": [137, 230, 275, 388, 460, 503, 504], "fallback_random": 137, "fals": [1, 72, 73, 74, 75, 76, 78, 79, 88, 89, 90, 94, 103, 104, 106, 109, 112, 114, 115, 121, 122, 128, 129, 130, 136, 137, 142, 143, 173, 174, 175, 176, 178, 179, 186, 203, 205, 206, 207, 208, 210, 224, 225, 226, 229, 230, 251, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 269, 274, 275, 285, 286, 287, 288, 290, 291, 292, 293, 295, 297, 301, 303, 304, 306, 309, 314, 319, 320, 321, 322, 325, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 361, 363, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 379, 380, 381, 382, 384, 385, 386, 387, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 410, 411, 412, 413, 414, 415, 419, 420, 421, 422, 423, 427, 431, 432, 433, 434, 435, 437, 442, 444, 445, 446, 447, 448, 449, 456, 458, 460, 461, 468, 471, 472, 474, 476, 477, 478, 481, 490, 497, 500, 502, 503, 507, 508, 512, 515, 517, 518, 519, 531, 540, 541, 542, 543, 545, 548, 551, 552, 553, 557, 558, 560, 570, 572, 573, 577, 578, 579, 581, 582, 583, 584, 585, 586, 587, 588, 596, 597, 604, 608, 616, 617, 620, 622, 626, 633, 634, 635, 636, 637, 638, 644, 645, 646, 649, 650, 665, 669, 674, 683, 687, 688, 689, 690, 697, 699, 700, 703, 704, 712], "false_branch": 142, "false_fn": 142, "faq": [364, 542], "fashion": [281, 529], "fast": [369, 390, 391, 392, 460, 476, 505, 506, 560, 601, 616, 711], "faster": [276, 462, 497, 503, 504, 512, 616, 634, 635, 637, 638], "fastest": [91, 497, 552], "fastpath": 434, "fault": 205, "favor": [128, 293, 294, 386, 482, 483, 488, 502, 572, 650, 674], "fc1": 487, "fc2": 487, "featur": [68, 142, 298, 308, 329, 330, 331, 332, 333, 334, 335, 342, 360, 365, 366, 367, 368, 372, 375, 376, 379, 380, 390, 398, 399, 434, 444, 446, 463, 472, 474, 476, 477, 478, 479, 497, 562, 687, 712], "feature_s": 694, "feature_vec": 694, "feedforward": [472, 474, 476], "fep": 276, "fetch": [520, 521, 522, 523, 524, 525, 526, 527], "few": [173, 703, 712], "fewer": [72, 74, 75, 78, 131, 265, 266, 291, 301, 303, 304, 306, 309, 319, 322, 381, 570, 644, 645, 649, 668, 689, 690], "fft_size": 263, "field": [332, 340, 341, 361, 363, 387, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 539], "fifo": 3, "file": [103, 203, 275, 604], "filenam": 203, "filepath": 275, "fill": [108, 161, 174, 175, 176, 206, 207, 557, 558, 581, 582, 583, 584, 585, 586, 650, 687, 699, 700], "fill_": [270, 593], "fill_uninitialized_memori": [174, 175, 176, 687], "fill_valu": [206, 207, 347], "filter": [263, 264, 355, 356, 357, 358, 359, 360, 646], "final": [65, 68, 69, 105, 123, 136, 173, 190, 221, 275, 293, 298, 348, 379, 381, 398, 444, 457, 487, 672, 704], "find": [173, 221, 266, 276, 358, 359, 360, 398, 562, 573, 608, 651, 711], "find_unused_paramet": 497, "fine": [202, 497], "finfo": [328, 443, 496], "finish": 703, "finit": [255, 256, 293, 314, 318, 340, 650], "first": [3, 65, 68, 70, 73, 88, 89, 98, 105, 109, 110, 112, 113, 114, 117, 119, 121, 135, 151, 161, 163, 164, 165, 170, 173, 178, 190, 205, 210, 221, 224, 232, 233, 243, 255, 264, 269, 275, 276, 292, 298, 301, 304, 305, 306, 308, 312, 314, 320, 325, 328, 332, 338, 339, 345, 356, 357, 359, 360, 373, 378, 379, 393, 396, 397, 398, 413, 420, 422, 423, 444, 457, 487, 497, 505, 506, 515, 516, 518, 529, 539, 545, 562, 572, 573, 599, 600, 608, 616, 636, 666, 667, 671, 676, 678, 684, 688, 691, 694, 696, 703, 704], "fit": [263, 594], "fix": [370, 371, 447, 497, 704], "fixm": [347, 478], "fkuo": 579, "fl": 381, "flag": [87, 103, 104, 106, 115, 128, 129, 130, 137, 202, 225, 226, 247, 254, 275, 295, 497, 515, 518, 548, 616, 622, 636, 674, 687, 694], "flashattent": 476, "flat": [594, 685, 704], "flat_param": 704, "flatten": [88, 89, 162, 230, 480, 511, 553, 573, 589, 594, 599, 662, 682, 683, 684, 685, 707], "flava": 704, "flexible_layout": 712, "flip": [143, 192, 193], "float": [1, 64, 66, 71, 73, 77, 79, 94, 106, 107, 115, 122, 125, 129, 130, 139, 145, 146, 150, 151, 156, 167, 168, 174, 175, 176, 178, 196, 197, 198, 199, 201, 210, 214, 224, 225, 226, 229, 230, 248, 255, 256, 258, 259, 260, 261, 264, 268, 270, 274, 276, 281, 290, 292, 294, 303, 313, 314, 318, 319, 320, 321, 322, 325, 328, 332, 336, 342, 343, 344, 346, 349, 350, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 375, 376, 381, 382, 383, 386, 387, 388, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 414, 416, 420, 433, 436, 437, 442, 443, 447, 450, 451, 452, 453, 454, 460, 465, 466, 468, 471, 472, 474, 476, 477, 478, 481, 482, 483, 496, 503, 504, 508, 510, 513, 523, 524, 526, 527, 529, 532, 533, 534, 535, 542, 543, 547, 553, 554, 560, 566, 569, 573, 574, 575, 576, 588, 592, 593, 613, 614, 617, 620, 647, 650, 654, 657, 672, 674, 687, 707, 711, 712], "float16": [65, 68, 105, 117, 204, 248, 298, 308, 355, 356, 357, 358, 359, 360, 380, 399, 415, 505, 506, 601, 613, 703, 711], "float32": [94, 139, 187, 188, 204, 214, 217, 248, 328, 341, 348, 481, 482, 483, 566, 571, 583, 598, 613, 614, 616, 636, 692, 711], "float64": [94, 139, 194, 203, 204, 214, 248, 566, 574, 613, 614, 617, 634, 635, 636, 637, 638, 665, 692, 697, 711], "float_tensor": 711, "floattensor": [65, 66, 67, 68, 69, 105, 431, 614, 711], "floor": [27, 28, 168, 196, 337, 338, 339, 395, 396, 397, 421, 422, 423, 577, 578, 592, 601, 646], "floor_divid": 168, "flow": [134, 142, 497], "flush": [604, 617], "fly": [520, 521, 522, 523, 524, 525, 526, 527], "fma": 616, "fmod": 592, "fn": 694, "fold": 480, "fold_param": [374, 480], "folder": 703, "follow": [121, 126, 130, 142, 173, 195, 205, 221, 265, 276, 295, 298, 332, 341, 347, 363, 371, 374, 379, 398, 444, 460, 476, 480, 489, 490, 491, 494, 495, 497, 505, 506, 512, 553, 562, 573, 601, 608, 636, 646, 651, 672, 680, 687, 703, 704, 707, 711], "foo": [137, 548], "foo_ti": 548, "footprint": 497, "forc": [94, 137, 622, 636, 712], "force_stop": 276, "foreach": [502, 503, 504], "forget": 398, "fork": 497, "fork_rng": 220, "forkserv": 497, "form": [128, 161, 330, 331, 334, 335, 347, 375, 376, 379, 398, 444, 480, 481, 518, 560, 667], "formal": [121, 608, 704], "format": [134, 173, 174, 175, 207, 263, 347, 371, 476, 497, 505, 506, 540, 542, 543, 558, 582, 584, 586, 604, 634, 635, 636, 637, 638, 646, 700, 707, 711], "former": 398, "formul": [346, 369, 383, 418, 465, 466], "formula": [2, 106, 115, 225, 226, 270, 295, 296, 442, 575], "forth": 688, "fortran": 650, "forward": [103, 104, 142, 165, 177, 336, 340, 342, 343, 344, 364, 365, 366, 367, 368, 370, 371, 372, 379, 398, 413, 424, 425, 426, 428, 429, 430, 435, 438, 439, 444, 445, 457, 476, 487, 490, 491, 497, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 536, 547, 550, 551, 687, 704, 712], "forward_pre_hook": 531, "forward_prefetch": 704, "found": [121, 151, 152, 153, 266, 301, 304, 306, 309, 320, 336, 346, 372, 456, 608, 704], "four": 356, "fourier": [263, 646], "fourth": 173, "fp16": [497, 505, 506, 703], "fp32": [158, 497, 704], "fparam": 276, "frac": [29, 30, 66, 79, 106, 115, 146, 150, 168, 196, 221, 225, 226, 264, 274, 290, 332, 337, 338, 339, 340, 341, 342, 343, 344, 345, 348, 355, 356, 357, 358, 359, 360, 363, 365, 374, 379, 380, 381, 382, 390, 391, 392, 393, 395, 396, 397, 398, 399, 400, 413, 415, 416, 417, 418, 421, 422, 423, 431, 432, 433, 435, 443, 444, 446, 447, 459, 461, 462, 464, 465, 467, 468, 469, 480, 496, 576, 585, 588, 591, 603, 623, 644, 645, 646, 650, 672, 689, 690], "fraction": [194, 200, 358, 359, 360, 375, 376, 434, 476, 523, 524, 526, 527, 529, 532, 533, 534, 535, 573], "fractionalmaxpool2d": 687, "fractionalmaxpool3d": 687, "frame": [137, 263, 646], "framework": [379, 497, 512, 620], "free": [276, 704, 711], "freed": 704, "freedom": [150, 644, 645, 689, 690], "frequenc": [108, 150, 263, 332, 370, 371, 646], "frequent": 332, "fresh": [164, 611, 630], "fro": [524, 533, 553], "frobeniu": 553, "from": [1, 2, 3, 79, 93, 94, 106, 107, 115, 116, 121, 134, 157, 173, 174, 175, 176, 191, 192, 193, 202, 204, 205, 206, 225, 226, 230, 243, 263, 268, 274, 275, 276, 290, 294, 295, 308, 314, 323, 324, 332, 336, 342, 343, 344, 345, 355, 356, 357, 358, 359, 360, 361, 364, 365, 366, 367, 368, 370, 371, 372, 374, 379, 380, 381, 382, 388, 390, 391, 392, 393, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 429, 434, 443, 444, 446, 447, 468, 476, 478, 480, 481, 487, 496, 497, 503, 505, 506, 514, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 533, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 550, 554, 560, 562, 565, 573, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 594, 595, 598, 600, 601, 608, 620, 634, 635, 636, 637, 638, 646, 647, 651, 662, 665, 674, 676, 678, 683, 684, 687, 688, 697, 704, 707, 711, 712], "from_": 122, "from_dlpack": 94, "from_numpi": [93, 94, 612, 665], "from_pretrain": 371, "frombuff": [94, 612], "front": [137, 276, 431], "fsdp": 712, "full": [106, 115, 137, 207, 225, 226, 276, 293, 341, 347, 381, 442, 472, 620, 650, 651, 694, 704], "full_lik": 270, "full_matric": [518, 650], "full_mlp": 487, "fullgraph": 137, "fulli": [424, 425, 426], "fullyshardeddataparallel": 704, "func": [103, 548, 694], "function": [1, 2, 68, 72, 73, 77, 78, 91, 92, 103, 104, 106, 115, 117, 125, 127, 131, 134, 137, 142, 143, 144, 156, 161, 163, 164, 171, 173, 177, 190, 194, 197, 198, 199, 202, 205, 211, 212, 221, 225, 226, 227, 229, 231, 238, 239, 240, 253, 263, 264, 265, 266, 268, 273, 275, 276, 279, 281, 290, 293, 294, 298, 301, 304, 306, 308, 309, 310, 316, 319, 320, 336, 340, 341, 346, 347, 349, 350, 351, 352, 353, 354, 361, 365, 369, 372, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 393, 395, 396, 397, 398, 399, 414, 417, 418, 420, 427, 428, 433, 434, 436, 444, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 462, 464, 465, 466, 467, 469, 470, 472, 474, 476, 477, 478, 480, 482, 484, 485, 486, 488, 492, 493, 497, 498, 505, 506, 512, 513, 518, 529, 539, 540, 541, 543, 546, 547, 548, 550, 551, 553, 554, 558, 560, 561, 562, 566, 572, 583, 588, 601, 610, 611, 612, 614, 615, 621, 623, 630, 632, 636, 646, 651, 652, 653, 662, 666, 668, 672, 682, 683, 684, 687, 691, 692, 693, 694, 695, 700, 711, 712], "further": [3, 211, 332, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 560, 704], "furthermor": [293, 365], "fuse": [137, 505, 506, 507, 508, 509, 510, 616, 707], "fusion": [137, 505, 506], "futur": [1, 3, 66, 127, 128, 137, 142, 143, 144, 151, 212, 263, 293, 294, 305, 367, 488, 503, 547, 548, 553, 572, 588, 646, 650, 674, 712], "fvar": 276, "fw": 150, "fweight": 150, "g": [103, 118, 142, 173, 202, 216, 218, 221, 263, 275, 347, 348, 364, 366, 367, 368, 372, 374, 379, 387, 393, 398, 399, 429, 438, 444, 460, 497, 498, 499, 500, 501, 505, 506, 514, 550, 553, 594, 601, 612, 616, 618, 636, 646, 704, 706, 711], "g_": 305, "g_0": 305, "g_cpu": 2, "g_cpu_oth": 2, "g_cuda": 2, "g_cuda_oth": 2, "g_i": 305, "g_t": 398, "gamma": [273, 342, 343, 344, 382, 390, 391, 392, 400, 443, 468, 496, 576], "gammainc": 235, "gammaincc": 236, "gan": [513, 547], "gap": [79, 588], "gate": [378, 379, 380, 398, 458], "gather": [662, 687, 704], "gaussian": [377, 381, 458], "gb": 704, "ge": [223, 297, 379, 384, 385, 398, 436], "gel": 211, "gelu": [458, 472, 474, 476], "gener": [107, 137, 173, 220, 225, 242, 265, 276, 296, 304, 314, 363, 374, 388, 480, 481, 487, 513, 520, 521, 522, 523, 524, 525, 526, 527, 547, 550, 554, 560, 562, 565, 579, 581, 583, 584, 585, 587, 609, 621, 651, 667, 671, 688, 694, 704, 711], "geometr": [688, 712], "geometric_": 712, "geq": [145, 210, 337, 338, 339, 363, 414, 435, 447, 512], "geqrf": 560, "gesdd": 650, "gesvd": 650, "gesvdj": 650, "gesvdjbatch": 650, "get": [2, 65, 103, 121, 160, 213, 214, 349, 350, 351, 395, 396, 397, 424, 425, 426, 456, 497, 499, 513, 540, 547, 593, 608, 704], "get_default_devic": 612, "get_default_dtyp": [79, 274, 290, 588, 711], "get_devic": 711, "get_info": 293, "get_rank": 468, "get_stat": 2, "get_vjp": 694, "girshick": 460, "git": 703, "github": [305, 424, 425, 426, 472, 550, 612, 703, 711], "give": [150, 355, 356, 357, 433, 480, 481, 512, 552, 646, 687, 704], "given": [1, 3, 72, 74, 75, 77, 78, 79, 90, 107, 108, 111, 119, 123, 124, 129, 130, 131, 136, 137, 144, 146, 149, 150, 151, 158, 160, 165, 173, 191, 216, 233, 263, 266, 270, 276, 283, 285, 286, 287, 288, 291, 301, 303, 305, 306, 309, 322, 332, 340, 341, 347, 355, 356, 357, 359, 360, 361, 363, 364, 370, 371, 375, 376, 379, 387, 398, 420, 424, 425, 426, 432, 433, 435, 437, 444, 463, 477, 478, 481, 482, 483, 490, 491, 513, 514, 539, 546, 547, 550, 553, 554, 560, 565, 570, 573, 574, 575, 588, 594, 599, 610, 611, 616, 630, 633, 634, 635, 636, 637, 638, 639, 642, 643, 646, 649, 651, 661, 662, 667, 669, 671, 681, 683, 685, 687, 704, 707, 712], "global": [79, 87, 106, 115, 142, 174, 176, 186, 203, 206, 225, 226, 247, 254, 264, 274, 290, 424, 482, 489, 490, 491, 492, 493, 494, 495, 525, 529, 557, 581, 583, 585, 588, 612, 699, 707, 711], "gloo": 497, "go": [276, 337, 338, 339, 421, 422, 423, 505, 506, 711], "goal": 305, "goe": [205, 336], "gomez": [472, 474, 476], "good": [137, 436, 704, 706], "gpu": [137, 199, 275, 304, 332, 364, 468, 497, 539, 650, 704, 710, 711, 712], "grad": [94, 103, 104, 177, 249, 276, 497, 551, 687, 694], "grad_fn": [94, 513], "grad_mod": [103, 104], "gradient": [74, 75, 94, 103, 104, 108, 134, 177, 208, 276, 293, 295, 301, 304, 306, 340, 347, 358, 359, 360, 363, 364, 370, 371, 381, 395, 396, 397, 435, 460, 497, 499, 502, 503, 504, 512, 518, 551, 560, 650, 694, 704, 707], "gradient_as_bucket_view": 497, "gradscal": 703, "graham": [375, 376], "grangier": 332, "graph": [2, 137, 497, 704, 707], "graph_diagram": 137, "graphsafe_get_st": 2, "graphsafe_set_st": 2, "grave": [332, 347], "greater": [113, 126, 127, 132, 210, 224, 340, 477, 513, 547, 687], "greatest": [209, 318], "greedi": 173, "grid": 305, "grid_i": 305, "grid_sampl": 687, "grid_x": 305, "griffin": 263, "ground": 363, "group": [94, 348, 355, 356, 357, 358, 359, 360, 382, 404, 405, 406, 407, 408, 409, 468, 497, 684, 704], "gru": [380, 445], "gt": 222, "gu": 276, "guarante": [90, 137, 364, 633, 687], "guard": [137, 712], "guid": [550, 703, 706], "guidelin": 529, "gunnar": [562, 651], "h": [129, 130, 330, 331, 338, 339, 341, 343, 344, 356, 357, 359, 367, 368, 370, 372, 379, 380, 391, 392, 398, 399, 400, 411, 412, 422, 423, 440, 441, 444, 446, 463, 479, 482, 483, 512, 513, 547, 562, 650, 651], "h0": [379, 398, 444], "h_": [330, 331, 334, 335, 338, 339, 345, 350, 351, 353, 354, 356, 357, 359, 360, 375, 376, 379, 380, 396, 397, 398, 415, 422, 423, 424, 425, 426, 440, 441, 444, 446, 451, 452, 454, 455, 481, 482, 483, 485, 486], "h_0": [379, 398, 399, 444], "h_1": 399, "h_i": 463, "h_l": 221, "h_n": [379, 398, 444], "h_r": 221, "h_t": [379, 398, 444], "h_t_minus_1": 444, "ha": [1, 3, 68, 72, 74, 75, 76, 78, 88, 89, 91, 107, 125, 128, 129, 130, 137, 142, 143, 144, 145, 151, 161, 163, 177, 199, 221, 230, 231, 241, 263, 265, 266, 275, 284, 291, 293, 298, 301, 303, 304, 305, 306, 308, 309, 319, 320, 321, 322, 340, 341, 342, 343, 344, 355, 356, 357, 358, 359, 360, 363, 364, 365, 371, 374, 375, 376, 379, 382, 387, 390, 391, 392, 398, 400, 401, 402, 403, 410, 411, 412, 420, 421, 422, 423, 424, 425, 426, 432, 433, 435, 436, 443, 444, 460, 462, 468, 476, 480, 481, 490, 491, 496, 497, 512, 515, 517, 520, 524, 526, 529, 539, 540, 547, 548, 552, 554, 560, 570, 572, 573, 574, 575, 592, 594, 604, 616, 626, 636, 642, 643, 644, 645, 646, 649, 650, 662, 668, 674, 685, 689, 690, 694, 710, 711, 712], "had": [487, 668], "hadamard": [379, 380, 398, 399], "half": [139, 187, 355, 356, 357, 358, 359, 360, 375, 376, 378, 505, 506, 601, 646, 711], "halftensor": 711, "halko": [562, 651], "halv": 221, "ham": [125, 225], "hand": [130, 167, 173, 336, 438, 457, 674, 687], "handl": [145, 173, 197, 198, 364, 476, 478, 488, 489, 490, 491, 492, 493, 494, 495, 520, 521, 522, 523, 524, 525, 526, 527, 592, 626, 651, 694, 712], "handler": 525, "hann": 226, "hann_window": [225, 646], "happen": [468, 512, 650, 704], "hard": [173, 276, 383, 704], "harder": [355, 356, 357, 358, 359, 360, 374, 422, 423, 480], "hardwar": 687, "hat": [342, 343, 344, 390, 391, 392, 468], "have": [3, 68, 72, 74, 75, 76, 78, 94, 103, 106, 107, 115, 124, 125, 137, 142, 150, 164, 172, 179, 202, 208, 209, 225, 226, 229, 230, 241, 263, 266, 267, 275, 284, 286, 291, 298, 301, 303, 304, 305, 306, 308, 309, 314, 319, 320, 322, 324, 332, 336, 340, 355, 356, 357, 358, 359, 360, 363, 364, 370, 371, 375, 376, 381, 386, 390, 391, 392, 420, 428, 431, 432, 433, 434, 435, 476, 478, 489, 490, 491, 494, 495, 497, 498, 499, 503, 504, 505, 506, 507, 509, 512, 515, 518, 542, 546, 551, 553, 570, 596, 597, 611, 613, 614, 616, 623, 634, 635, 637, 638, 644, 645, 646, 649, 650, 662, 666, 672, 674, 687, 689, 690, 692, 694, 696, 703, 704, 711, 712], "head": [332, 434, 472, 474, 476], "head_1": 434, "head_bia": 332, "head_h": 434, "head_i": 434, "height": [338, 339, 356, 357, 359, 360, 396, 397, 422, 423, 435, 463, 481], "help": [264, 305, 366, 367, 368, 372, 512, 622, 694, 712], "henc": [107, 205, 424, 425, 426, 481, 505, 506, 636, 704], "henry2019": 616, "here": [148, 173, 342, 343, 344, 358, 359, 360, 390, 391, 392, 436, 468, 505, 506, 515, 616, 629, 703, 704, 710], "hermitian": [129, 130, 146], "herv\u00e9": 332, "heteroscedast": 381, "heurist": [173, 704], "hf": [398, 399], "hg": [398, 399], "hh": [444, 446], "hi": [398, 399], "hidden": [379, 380, 398, 399, 444, 446, 499], "hidden_s": [379, 380, 398, 399, 444, 445, 446], "hide": 694, "high": [347, 475, 583, 584, 616], "higher": [3, 165, 228, 243, 321, 363, 420, 435, 573, 651, 694, 706, 711], "highest": [583, 584, 616], "highli": [332, 497], "hing": [431, 433], "hint": 0, "hist": [229, 230], "histc": 687, "histogram": [228, 230], "histor": [66, 367], "histori": [93, 94, 665], "hit": 497, "hn": [379, 380, 398, 444], "ho": [398, 399], "hold": [276, 374, 429, 430, 438, 439, 480, 487, 500, 501, 515, 525, 539, 634, 635, 636, 637, 638, 711], "home": 709, "homoscedast": 381, "hook": [364, 488, 489, 490, 491, 492, 493, 494, 495, 497, 514, 520, 521, 522, 523, 524, 525, 526, 527, 531, 536, 547, 550, 707], "hop": [263, 646], "hop_length": [263, 646], "hopefulli": 704, "horizont": [135, 231, 232], "host": [3, 91, 497, 518, 552, 712], "household": [211, 512, 560], "householder_product": [211, 512, 559], "how": [103, 104, 156, 177, 221, 275, 374, 480, 481, 497, 539, 551, 592, 616, 630, 704, 706, 707], "howev": [161, 163, 275, 276, 293, 340, 342, 343, 344, 355, 356, 357, 358, 359, 360, 364, 371, 487, 497, 539, 553, 634, 635, 636, 637, 638, 694], "hr": [379, 380, 398], "hstack": 135, "html": [137, 173, 478, 687], "http": [137, 142, 173, 276, 305, 347, 398, 424, 425, 426, 448, 472, 475, 478, 514, 550, 562, 579, 612, 616, 687, 703, 706, 711], "huber": [388, 460], "huberloss": 460, "huge": 651, "hx": [380, 399, 446], "hyper": 460, "hyperbol": [63, 96, 99, 148, 469, 629, 664], "hypotenus": 233, "hz": [379, 380], "i": [0, 1, 2, 4, 60, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 113, 115, 117, 118, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 165, 171, 172, 173, 174, 175, 176, 177, 178, 183, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 214, 216, 220, 221, 224, 225, 226, 227, 229, 230, 231, 232, 233, 237, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 284, 286, 290, 291, 292, 293, 294, 295, 296, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 312, 314, 316, 318, 319, 320, 321, 322, 323, 324, 325, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 450, 451, 452, 453, 454, 455, 457, 458, 460, 461, 462, 464, 465, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 539, 540, 541, 542, 543, 546, 547, 548, 550, 551, 552, 553, 554, 558, 560, 561, 562, 565, 566, 568, 569, 570, 571, 572, 573, 579, 581, 582, 583, 585, 586, 588, 589, 591, 592, 593, 594, 595, 596, 597, 599, 600, 601, 603, 604, 608, 610, 612, 613, 614, 615, 616, 617, 618, 619, 620, 622, 623, 625, 627, 629, 633, 634, 635, 636, 637, 638, 639, 640, 642, 644, 645, 646, 649, 650, 651, 652, 653, 657, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 671, 672, 674, 675, 676, 677, 678, 682, 683, 684, 685, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 700, 702, 703, 704, 706, 710, 711, 712], "i0": 264, "i_": 667, "i_0": [264, 265, 667], "i_1": 265, "i_d": 667, "i_n": [265, 667, 694], "i_t": [265, 398], "icml_2006": 347, "icnn": 381, "id": [468, 497], "idea": [173, 332], "ident": [161, 276, 293, 319, 320, 336, 365, 505, 506, 512, 515, 691, 697], "identifi": [1, 230, 275, 468], "idx": [332, 370, 513, 683], "ieee": [263, 381], "iff": 434, "ig": [398, 399], "ignor": [65, 68, 69, 70, 105, 127, 129, 130, 150, 211, 228, 265, 275, 295, 319, 320, 321, 337, 338, 339, 340, 341, 361, 363, 379, 381, 387, 393, 394, 398, 419, 420, 421, 422, 423, 431, 432, 433, 435, 442, 444, 460, 461, 477, 497, 553, 560, 620, 646, 650, 674], "ignore_index": [363, 435], "ignore_w": [127, 173, 293, 349, 351, 352, 353, 370, 371, 424, 450, 451, 452, 453, 454, 455, 480, 481, 482, 484, 485, 512, 513, 546], "ih": [444, 446], "ii": [146, 173, 398, 399], "ij": [146, 173, 283, 291, 305, 431], "ik": [173, 276], "illia": [472, 474, 476], "im": 585, "im2col": 480, "imag": [139, 330, 334, 335, 355, 356, 357, 358, 359, 360, 363, 374, 375, 376, 391, 400, 435, 440, 441, 463, 480, 482, 483, 597], "imaginari": [139, 146, 237, 256, 258, 259, 262, 585, 646, 692, 693], "imbal": 341, "imbalanc": 332, "immedi": [505, 506, 704], "immut": 202, "impact": 616, "implement": [66, 92, 94, 142, 148, 173, 194, 199, 205, 275, 276, 304, 332, 347, 364, 379, 382, 395, 396, 397, 400, 434, 440, 443, 444, 445, 448, 465, 474, 476, 496, 497, 503, 504, 512, 513, 518, 529, 542, 546, 547, 550, 572, 579, 592, 601, 604, 629, 650, 651, 667, 683, 687, 707], "impli": 704, "implicit": [211, 221, 337, 338, 339, 355, 356, 357, 358, 359, 360, 374, 421, 422, 423, 480, 560, 704], "implicitli": [156, 211, 221, 275, 337, 338, 339, 421, 422, 423, 613, 672], "import": [0, 103, 116, 123, 150, 202, 205, 263, 305, 428, 497, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 531, 532, 533, 541, 542, 543, 544, 545, 546, 553, 566, 685, 703, 710, 711], "importance_scor": [520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533], "impos": [612, 711], "imposs": 694, "improv": [146, 221, 365, 475, 497], "in1": 345, "in1_featur": 345, "in2": 345, "in2_featur": 345, "in_channel": [355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409], "in_dim": 694, "in_featur": [332, 413, 415, 487, 512, 513, 514, 546, 547, 550], "inbuilt": 518, "incept": 363, "includ": [229, 337, 338, 339, 345, 347, 364, 373, 381, 415, 424, 425, 426, 479, 505, 506, 540, 541, 543, 675, 676, 677, 678, 703, 704, 712], "include_last_offset": 371, "include_self": [240, 607], "inclus": [2, 228, 230, 274, 290, 296, 583, 584, 643], "incom": [345, 415], "incompat": [118, 263, 505, 506], "inconsist": [79, 588], "incorrect": [119, 275, 553, 636, 646], "incorrectli": 196, "increas": [121, 173, 229, 230, 332, 341, 347, 355, 356, 357, 358, 359, 360, 440, 608, 616, 672, 688], "increment": [205, 230, 364], "incur": 127, "independ": [221, 230, 365, 366, 367, 368, 372, 514, 550, 572], "index": [74, 75, 91, 121, 152, 153, 208, 238, 239, 240, 241, 266, 283, 291, 293, 297, 301, 304, 305, 306, 309, 314, 320, 323, 324, 332, 347, 363, 429, 430, 435, 438, 439, 478, 480, 524, 526, 533, 534, 539, 552, 573, 605, 606, 607, 608, 610, 611, 612, 630, 634, 635, 637, 638, 646, 661, 682, 683, 685, 686, 687, 694, 711], "index_add": 687, "index_add_": [238, 239], "index_copi": 687, "index_put": 687, "index_reduce_": 240, "index_select": 687, "indexerror": [524, 526], "indic": [1, 3, 74, 75, 88, 89, 90, 91, 92, 121, 128, 129, 130, 142, 152, 153, 176, 208, 221, 241, 266, 275, 283, 291, 293, 295, 301, 304, 306, 309, 314, 320, 324, 332, 333, 334, 335, 363, 370, 371, 375, 376, 422, 423, 424, 425, 426, 431, 433, 520, 521, 522, 523, 524, 525, 526, 527, 532, 533, 552, 553, 573, 608, 633, 634, 635, 636, 637, 638, 661, 662, 666, 669, 675, 676, 677, 678, 683, 684, 685, 687, 694, 697], "indices_or_sect": [171, 231, 666, 695], "individu": [128, 347, 468, 503, 704], "inductor": [137, 703], "inexact": 601, "inf": [63, 65, 68, 69, 70, 99, 105, 121, 255, 256, 258, 260, 261, 284, 318, 418, 462, 503, 524, 533, 553, 601, 608], "infer": [79, 93, 94, 103, 205, 206, 230, 250, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 434, 481, 487, 551, 588, 595, 613, 614, 634, 635, 636, 637, 638, 665, 682], "inference_mod": [434, 476], "inferencemod": 103, "infin": [148, 256, 258, 260, 261, 318, 340, 421, 422, 423, 503, 629], "infiniband": 497, "infinit": [258, 276, 340, 347, 566], "info": 293, "inform": [103, 104, 108, 177, 263, 355, 356, 357, 358, 359, 360, 388, 424, 425, 426, 434, 456, 472, 474, 476, 539, 551, 571, 598, 616, 622, 687, 707, 711], "infti": [125, 263, 340, 395, 396, 397, 460], "ingredi": [390, 391, 392], "inherit": 531, "init": [436, 456, 546, 703], "init_method": 497, "init_process_group": 497, "initi": [2, 93, 174, 175, 176, 214, 242, 275, 276, 293, 342, 343, 344, 345, 347, 358, 359, 360, 364, 370, 371, 379, 380, 382, 390, 391, 392, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 436, 443, 444, 445, 446, 468, 478, 487, 496, 497, 500, 501, 512, 518, 546, 612, 613, 614, 634, 635, 636, 637, 638, 665, 704], "initial_se": 2, "initialis": 456, "inner": [156, 672], "innermost": [221, 230, 608], "inp": 480, "inp_unf": 480, "inplac": [137, 336, 346, 365, 366, 367, 368, 369, 372, 384, 385, 386, 414, 427, 447, 448, 449, 456, 458, 471, 490, 687], "inplace_view": 712, "input": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 126, 128, 129, 130, 131, 132, 133, 134, 136, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 207, 208, 209, 210, 211, 212, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 248, 251, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 294, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 431, 432, 433, 434, 435, 436, 437, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 489, 490, 491, 494, 495, 496, 497, 505, 506, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 539, 540, 541, 548, 551, 552, 553, 555, 556, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 580, 582, 584, 586, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 603, 605, 606, 607, 610, 611, 612, 613, 616, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641, 642, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 657, 660, 661, 662, 663, 664, 666, 668, 669, 670, 671, 674, 675, 677, 680, 681, 682, 683, 684, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 697, 698, 700, 704, 707, 711], "input1": [345, 361, 362, 420, 437], "input2": [345, 361, 362, 420, 437], "input_3x3": 481, "input_length": 347, "input_on": [374, 480], "input_s": [379, 380, 398, 399, 444, 445, 446], "input_var": 364, "insecur": 275, "insensit": 389, "insert": [429, 608, 611, 620, 630, 643, 686], "inspect": 711, "instal": 703, "instanc": [173, 202, 276, 374, 390, 391, 392, 400, 473, 475, 476, 480, 497, 513, 525, 539, 547, 636, 666, 704], "instancenorm": 382, "instancenorm1d": 410, "instancenorm2d": 411, "instancenorm3d": 412, "instanti": [371, 515, 539, 546], "instead": [94, 121, 127, 212, 253, 275, 304, 337, 338, 339, 340, 341, 342, 343, 344, 361, 363, 364, 366, 367, 368, 372, 379, 387, 393, 394, 395, 396, 397, 398, 419, 420, 421, 422, 423, 431, 432, 433, 435, 442, 444, 456, 460, 461, 462, 468, 477, 497, 548, 550, 577, 578, 588, 608, 612, 646, 650, 687, 694, 712], "instruct": 616, "int": [2, 3, 72, 74, 75, 76, 78, 88, 89, 90, 92, 106, 108, 115, 122, 124, 131, 136, 137, 149, 150, 151, 152, 153, 154, 155, 156, 160, 161, 162, 163, 164, 165, 171, 174, 176, 186, 190, 203, 205, 206, 208, 215, 218, 219, 221, 225, 226, 228, 229, 230, 231, 241, 242, 263, 264, 266, 274, 276, 283, 290, 291, 296, 301, 303, 304, 306, 309, 311, 314, 319, 320, 321, 322, 323, 324, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 370, 371, 373, 374, 375, 376, 378, 380, 382, 390, 391, 392, 395, 396, 397, 399, 400, 404, 405, 406, 407, 408, 409, 413, 415, 416, 418, 421, 422, 423, 424, 425, 426, 430, 433, 435, 436, 439, 440, 441, 443, 446, 450, 451, 452, 453, 454, 455, 462, 464, 468, 472, 473, 474, 475, 476, 477, 479, 480, 481, 482, 483, 484, 485, 486, 496, 497, 513, 514, 523, 524, 526, 527, 529, 532, 533, 534, 535, 539, 540, 542, 547, 550, 553, 554, 556, 557, 562, 563, 570, 573, 574, 575, 576, 577, 578, 579, 581, 583, 584, 585, 587, 593, 594, 595, 598, 599, 600, 601, 604, 609, 610, 611, 615, 618, 619, 630, 633, 639, 642, 643, 644, 645, 646, 649, 651, 655, 657, 662, 666, 667, 669, 671, 672, 675, 676, 677, 678, 681, 682, 683, 684, 685, 686, 688, 689, 690, 694, 695, 699, 711, 712], "int16": [204, 286, 711], "int32": [121, 175, 187, 188, 201, 204, 205, 293, 347, 571, 608, 711], "int64": [79, 108, 121, 174, 187, 188, 204, 539, 583, 587, 588, 608, 634, 635, 637, 638, 711], "int8": [109, 110, 111, 112, 113, 114, 204, 285, 286, 287, 288, 711], "int_repr": [574, 575], "int_tensor": 711, "int_zerodim": 711, "integ": [2, 64, 65, 66, 67, 68, 69, 79, 105, 106, 115, 126, 145, 168, 171, 173, 174, 175, 176, 194, 195, 196, 197, 198, 199, 205, 206, 209, 225, 226, 229, 230, 231, 267, 268, 276, 313, 332, 347, 355, 356, 357, 400, 443, 496, 539, 554, 557, 562, 574, 575, 581, 583, 584, 585, 587, 592, 601, 613, 639, 647, 651, 666, 667, 680, 685, 695, 699, 711, 712], "integr": [107, 109, 110, 111, 112, 113, 114, 150, 156, 229, 268, 323, 579, 591, 672, 711], "intend": [264, 490, 491, 492, 493], "intent": 613, "intention": [170, 691], "inter": [218, 618], "interact": 103, "interchang": 671, "interfac": [205, 615, 646, 687], "interior": 221, "intermedi": [118, 142, 202, 293, 371, 472, 474, 476], "intern": [284, 342, 343, 344, 381, 468, 515, 616, 636, 687, 704], "interop": 618, "interpol": [270, 321, 481, 482, 483, 573, 687], "interpret": [94, 205, 218, 230, 276, 367, 613, 618], "interv": [79, 146, 201, 581, 582, 704], "intraop": 619, "introduc": [276, 379, 398, 444, 599], "introduct": 497, "inttensor": [241, 293, 294, 370, 711], "inv": 244, "invari": [539, 634, 635, 636, 637, 638], "invers": [62, 63, 96, 99, 124, 129, 130, 263, 358, 359, 360, 370, 371, 374, 424, 425, 426, 480, 518, 542, 682], "inverse_indic": [683, 684], "invert": [257, 284, 424, 425, 426, 674], "invoc": 137, "invok": [364, 489, 491, 494, 495, 550], "involv": 616, "io": [173, 275, 398, 399, 476, 604], "iparam": 276, "ir": [379, 380], "is_avail": 703, "is_coalesc": 636, "is_complex": 711, "is_conj": [143, 596], "is_cuda": 539, "is_en": [634, 635, 636, 637, 638], "is_floating_point": 711, "is_integ": 712, "is_neg": 597, "is_pin": 539, "is_train": [104, 712], "isinst": 253, "isn": 263, "isnan": 319, "isnt": 103, "issu": [137, 202, 293, 305, 393, 424, 425, 426, 481, 550, 612, 694, 704, 711], "istep": 276, "item": [363, 518, 620], "iter": [276, 429, 430, 438, 439, 497, 498, 499, 502, 503, 504, 511, 513, 520, 521, 522, 523, 524, 525, 526, 527, 529, 547, 549, 562, 651, 703, 704], "itertool": [123, 136], "its": [88, 89, 90, 92, 93, 94, 104, 129, 130, 137, 139, 146, 150, 156, 160, 163, 173, 176, 199, 205, 229, 230, 233, 246, 298, 308, 312, 340, 342, 343, 344, 355, 356, 357, 358, 359, 360, 364, 390, 391, 392, 460, 468, 476, 487, 492, 493, 498, 499, 500, 501, 505, 506, 507, 509, 513, 514, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 540, 546, 550, 554, 563, 588, 592, 596, 597, 613, 614, 626, 651, 671, 672, 674, 682, 692, 704, 711], "itself": [72, 78, 93, 150, 462, 497, 520, 521, 522, 523, 524, 525, 526, 527, 536, 712], "ivar": 276, "iz": [379, 380], "j": [71, 139, 173, 208, 263, 276, 283, 291, 293, 298, 366, 367, 368, 372, 431, 566, 573, 646, 650, 691], "j_0": 265, "j_1": 265, "j_n": 265, "j_t": 265, "jacobian": 694, "jacobian_row": 694, "jakob": [472, 474, 476], "jed": 276, "ji": 173, "jit": [218, 618, 619], "jj": 146, "jk": 173, "joel": [562, 651], "jointli": 434, "jone": [472, 474, 476], "joulin": 332, "journal": 579, "jump": 711, "just": [66, 76, 143, 144, 293, 366, 367, 368, 372, 497, 518, 519, 612, 675, 676, 677, 678, 710, 711], "j\u00e9gou": 332, "k": [130, 160, 173, 208, 230, 266, 276, 294, 298, 337, 339, 345, 355, 356, 357, 358, 359, 360, 363, 375, 376, 379, 380, 398, 399, 413, 415, 416, 421, 423, 434, 435, 444, 446, 512, 560, 562, 572, 600, 634, 635, 637, 638, 646, 651, 669, 674, 711], "k_": 667, "k_0": [265, 667], "k_1": 265, "k_n": 265, "k_t": 265, "kaiming_norm": 456, "kaiming_normal_": 456, "kaiser": [264, 472, 474, 476], "kd": [339, 423], "kdim": 434, "keep": [275, 342, 343, 344, 370, 390, 391, 392, 437, 468, 525, 593, 616], "keepdim": [72, 74, 75, 76, 78, 88, 89, 266, 291, 301, 303, 304, 306, 309, 319, 320, 321, 322, 437, 553, 570, 573, 644, 645, 649, 689, 690], "kei": [275, 429, 434, 438, 532, 548], "kept": [76, 342, 343, 344, 390, 391, 392, 468, 704], "kernel": [3, 137, 337, 338, 339, 355, 356, 357, 358, 359, 360, 374, 375, 376, 395, 396, 397, 404, 405, 406, 407, 408, 409, 421, 422, 423, 424, 425, 426, 480, 505, 506, 516, 704], "kernel_s": [337, 338, 339, 355, 356, 357, 358, 359, 360, 374, 375, 376, 395, 396, 397, 404, 405, 406, 407, 408, 409, 421, 422, 423, 424, 425, 426, 480, 577, 578], "kesheng": 276, "key_padding_mask": 434, "keyword": [2, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 94, 95, 96, 97, 98, 99, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 117, 121, 124, 126, 128, 129, 130, 132, 134, 135, 139, 144, 145, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 160, 165, 168, 170, 172, 174, 175, 176, 178, 183, 186, 194, 195, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 209, 210, 211, 221, 224, 225, 226, 227, 228, 229, 230, 232, 233, 241, 243, 260, 261, 264, 265, 266, 267, 268, 269, 270, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 292, 294, 295, 297, 298, 301, 302, 303, 304, 306, 307, 308, 309, 312, 313, 314, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 364, 386, 389, 490, 491, 518, 520, 525, 529, 548, 552, 554, 557, 558, 560, 561, 565, 566, 569, 570, 572, 573, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 593, 594, 601, 603, 608, 623, 625, 626, 627, 629, 633, 634, 635, 636, 637, 638, 640, 641, 643, 644, 645, 647, 649, 650, 662, 663, 664, 665, 669, 672, 674, 675, 676, 677, 678, 680, 687, 689, 690, 691, 696, 697, 699, 700], "kh": [338, 339, 375, 376, 422, 423], "ki": 173, "kind": [264, 498, 499, 571, 711], "kl": 393, "kl_loss": 393, "know": [202, 497, 704], "known": [275, 355, 356, 357, 358, 359, 360, 374, 458, 460, 480, 487, 651, 665], "knyazev": 276, "knyazev2001": 276, "kroneck": 265, "kt": 376, "kth": 266, "kthvalu": 687, "kullback": 393, "kw": [338, 339, 375, 376, 422, 423], "kw_i": 434, "kwarg": [293, 379, 389, 398, 417, 428, 444, 459, 463, 467, 469, 470, 487, 520, 525, 529, 539, 546, 548, 551, 604, 684, 694], "l": [106, 115, 121, 128, 129, 130, 173, 225, 226, 264, 293, 295, 337, 340, 341, 342, 355, 363, 366, 367, 374, 379, 387, 388, 390, 393, 394, 398, 410, 419, 421, 430, 435, 444, 460, 477, 478, 480, 524, 533, 541, 543, 608, 646], "l1": [387, 388, 460, 523, 532], "l1loss": [388, 460], "l1unstructur": 529, "l2": [388, 419, 460], "l_": [295, 329, 333, 337, 341, 355, 356, 357, 358, 395, 421], "l_1": [340, 341, 363, 387, 388, 394, 419, 435, 460, 478], "l_c": 341, "l_i": 478, "l_infin": 478, "l_n": [340, 341, 363, 387, 388, 394, 419, 435, 460, 478], "l_p": 478, "label": [173, 332, 341, 347, 361, 363, 387, 420, 431, 432, 540, 704], "label_smooth": 363, "lambd": [383, 466], "lambda": [125, 275, 383, 466, 478, 694], "languag": [332, 472], "lapack": [211, 572, 650], "larg": [148, 150, 332, 374, 480, 629, 651, 711], "larger": [108, 332, 364, 370, 371, 420, 478, 481], "largest": [108, 195, 276, 513, 669], "last": [71, 91, 103, 106, 115, 121, 131, 156, 161, 165, 190, 225, 226, 230, 243, 251, 263, 266, 304, 309, 332, 337, 338, 339, 345, 363, 371, 373, 379, 398, 400, 415, 435, 442, 443, 444, 457, 480, 496, 499, 505, 506, 552, 599, 608, 616, 633, 634, 635, 637, 638, 639, 646, 650, 667, 669, 672, 692, 693], "later": [2, 275, 421, 422, 423, 458, 497, 650, 703], "latest": 525, "latin1": 275, "latter": [66, 398, 435], "launch": 497, "law": 332, "layer": [337, 338, 339, 341, 342, 343, 344, 345, 355, 356, 357, 358, 359, 360, 366, 367, 368, 372, 379, 380, 382, 390, 391, 392, 398, 399, 400, 413, 415, 421, 422, 423, 434, 435, 443, 444, 446, 457, 468, 472, 473, 474, 475, 476, 496, 497, 505, 506, 512, 704], "layer_norm": 400, "layer_norm_ep": [472, 474, 476], "layernorm": [382, 390, 391, 392, 472, 474, 476], "layout": [68, 79, 106, 115, 174, 175, 176, 186, 203, 206, 207, 225, 226, 264, 274, 290, 298, 308, 324, 557, 558, 581, 582, 583, 584, 585, 586, 587, 588, 634, 635, 636, 637, 638, 671, 676, 678, 699, 700], "lazi": [143, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413], "lazili": [401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 487], "lazy_mlp": 487, "lazylinear": 487, "lazymlp": 487, "lazymodul": 487, "lazymodulemixin": [401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413], "lbrace": [675, 676, 677, 678], "lceil": [79, 126], "ldexp": 201, "ldot": [274, 290, 305, 400, 421, 422, 423, 443, 496], "le": [272, 384, 385], "lead": [202, 460, 636, 642, 694, 704], "leaf": [93, 665, 704], "leaki": 447, "leakyrelu": 429, "learn": [345, 361, 366, 367, 368, 369, 372, 387, 400, 413, 415, 436, 458, 472, 474, 476, 477, 478, 497, 706, 707], "learnabl": [342, 343, 344, 345, 355, 356, 357, 358, 359, 360, 370, 371, 379, 380, 382, 390, 391, 392, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 436, 443, 444, 446, 468, 496], "least": [76, 108, 161, 163, 164, 173, 192, 193, 203, 221, 229, 230, 263, 267, 276, 298, 318, 332, 540, 704], "leav": [516, 519, 642], "leave_parametr": 519, "left": [79, 106, 110, 113, 115, 116, 121, 126, 173, 192, 195, 196, 200, 221, 225, 226, 230, 263, 264, 281, 282, 314, 332, 337, 338, 339, 340, 341, 355, 356, 357, 374, 381, 394, 395, 396, 397, 416, 417, 418, 419, 421, 422, 423, 431, 432, 433, 437, 438, 477, 480, 481, 482, 483, 504, 560, 588, 601, 608, 646, 667, 672, 688, 704], "leftmost": 230, "leg": 233, "legaci": 711, "legitim": 436, "leibler": 393, "len": [72, 74, 75, 78, 291, 303, 319, 322, 364, 524, 526, 542, 636, 639, 644, 645, 649, 688, 689, 690], "length": [136, 205, 241, 263, 264, 323, 324, 342, 347, 355, 364, 371, 374, 379, 395, 398, 444, 480, 539, 540, 541, 542, 543, 544, 545, 634, 635, 637, 638, 646, 672, 694], "lens_unpack": 542, "leq": [73, 106, 107, 145, 255, 265, 269, 347, 369, 431, 433, 435, 646], "less": [150, 173, 195, 199, 269, 276, 292, 293, 332, 388, 442, 451, 460, 466, 542, 592, 676, 678, 704], "let": [129, 130, 132, 221, 264, 497, 512, 665, 704, 706], "letter": 173, "level": [211, 341, 364, 497, 704, 706], "leverag": 137, "lexicograph": [91, 552], "lfloor": [195, 200, 332, 337, 338, 339, 355, 356, 357, 374, 395, 396, 397, 421, 422, 423, 480, 481, 482, 483, 588, 646], "lgamma": [31, 32], "lh": 130, "li": [321, 573], "librari": [148, 202, 293, 629, 706], "librosa": 646, "lie": [462, 464], "lift": 694, "like": [92, 106, 115, 142, 168, 173, 174, 194, 197, 198, 205, 225, 226, 264, 275, 332, 340, 371, 374, 390, 391, 392, 429, 430, 438, 439, 457, 480, 487, 497, 499, 500, 501, 513, 539, 557, 566, 581, 585, 604, 612, 613, 616, 650, 662, 694, 699, 703, 704, 711, 712], "likelihood": [332, 381, 435, 442], "likewis": 671, "lim": 263, "lim_": 340, "limit": [142, 347, 370, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 497, 529, 620, 703], "limit_all_gath": 704, "limits_": 283, "linalg": [127, 128, 129, 130, 151, 159, 211, 244, 284, 293, 294, 295, 299, 300, 512, 513, 518, 553, 559, 564, 566, 572, 631, 650, 651, 674, 691], "line": [103, 173, 620], "linear": [130, 173, 221, 270, 294, 321, 340, 346, 369, 377, 378, 386, 413, 430, 444, 446, 447, 448, 456, 458, 465, 472, 474, 476, 479, 481, 487, 509, 510, 512, 513, 514, 518, 528, 529, 530, 531, 532, 534, 535, 536, 537, 538, 546, 547, 550, 562, 573, 687, 694, 704], "linear_b": 510, "linear_rank_on": 518, "linear_w": 510, "linearli": [481, 572], "linewidth": 620, "link": [355, 356, 357, 358, 359, 360, 374, 421, 422, 423, 480], "linspac": [108, 132, 305], "linux": 703, "lipschitz": 513, "list": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 93, 100, 101, 102, 119, 120, 123, 127, 131, 136, 137, 142, 158, 171, 173, 174, 191, 206, 221, 231, 303, 305, 322, 364, 370, 400, 430, 439, 443, 457, 468, 479, 496, 497, 498, 499, 518, 520, 521, 522, 523, 524, 525, 526, 527, 536, 539, 540, 541, 542, 543, 544, 545, 553, 557, 575, 577, 578, 581, 585, 600, 634, 635, 636, 637, 638, 639, 644, 645, 649, 665, 666, 667, 683, 684, 687, 689, 690, 695, 699, 711, 712], "list_backend": 137, "list_mode_opt": 137, "list_opt": 137, "live": 704, "ll": [128, 129, 130, 379, 380, 398, 399], "llama": 704, "llion": [472, 474, 476], "llm": 704, "ln": 273, "load": [137, 371, 487, 497, 604], "load_state_dict": [275, 487], "loc": 275, "local": [103, 104, 177, 276, 366, 367, 368, 372, 374, 416, 480, 497, 499, 551], "local_rank": 468, "locat": [93, 119, 121, 152, 153, 266, 275, 301, 306, 309, 314, 364, 374, 463, 480, 497, 518, 573, 608, 687, 703], "log": [33, 40, 183, 279, 281, 283, 284, 291, 332, 340, 341, 363, 381, 393, 417, 418, 432, 435, 442, 461, 462, 465, 497, 712], "log10": [34, 35], "log1p": [36, 37], "log2": [38, 39], "log_": [277, 278, 279, 280], "log_2": 282, "log_input": 442, "log_normal_": 712, "log_prob": [332, 347], "log_softmax": [347, 393, 435], "log_target": 393, "logaddexp": 282, "logarithm": [273, 277, 278, 279, 280, 281, 282, 283, 284, 290, 347], "logic": [109, 111, 112, 114, 285, 286, 287, 288, 298, 571, 598, 659], "logist": [458, 461], "logit": [341, 363], "logsoftmax": [363, 435, 462], "logsumexp": 281, "long": [242, 304, 320, 347, 363, 371, 398, 399, 435, 571, 662, 666, 676, 678, 683, 711], "long_tensor": 711, "long_zerodim": 711, "longer": [66, 263, 497, 550, 553], "longest": [347, 540, 542, 543], "longtensor": [88, 89, 208, 241, 266, 314, 370, 431, 552, 608, 633, 636, 661, 669, 697, 711], "look": [142, 298, 332, 531, 634, 635, 637, 638], "lookup": 370, "loop": [497, 516, 694], "loss": [263, 332, 340, 341, 347, 361, 363, 370, 381, 387, 388, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 478, 497, 540, 616, 703], "loss_fn": 435, "loss_func": 497, "loss_pointwis": 393, "lost": [364, 424, 425, 426], "low": [211, 347, 562, 579, 583, 584, 601, 651, 706], "lower": [116, 121, 128, 129, 130, 132, 187, 188, 228, 229, 304, 314, 321, 332, 447, 571, 573, 593, 608, 616, 674, 675, 676, 707], "lowest": [127, 318, 523, 524, 532, 533, 583, 584], "lr": [487, 497, 703], "lrelu": 429, "lrn": 416, "lstm": [399, 445], "lstsq": 211, "lt": 271, "lu": [294, 295], "lu_data": [294, 295], "lu_factor": [293, 294, 295], "lu_factor_ex": 293, "lu_pivot": [294, 295], "lu_unpack": 293, "lukasz": [472, 474, 476], "lvert": [73, 255, 477], "m": [1, 65, 68, 69, 70, 105, 117, 121, 125, 186, 230, 265, 276, 293, 294, 298, 308, 314, 316, 329, 330, 331, 333, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 349, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 365, 366, 367, 368, 369, 370, 372, 373, 375, 376, 377, 378, 382, 383, 384, 385, 386, 389, 390, 391, 392, 395, 396, 397, 414, 415, 417, 418, 421, 422, 423, 427, 436, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 479, 481, 482, 483, 484, 485, 486, 497, 512, 514, 518, 528, 530, 531, 532, 533, 534, 535, 536, 537, 538, 546, 547, 550, 560, 561, 562, 572, 579, 608, 646, 650, 651, 667, 674], "m1": [692, 693], "m2": [546, 692, 693], "machin": 465, "made": [428, 474, 476, 589], "mae": 394, "magic": 712, "magma": [293, 572, 650], "magnitud": [145, 514, 550, 623], "mai": [68, 108, 119, 131, 137, 143, 144, 146, 148, 173, 190, 194, 199, 202, 205, 230, 263, 266, 275, 276, 281, 298, 308, 332, 347, 355, 356, 357, 358, 359, 360, 363, 393, 424, 425, 426, 435, 474, 476, 481, 487, 497, 512, 515, 516, 518, 553, 572, 592, 595, 613, 614, 616, 622, 629, 646, 650, 651, 674, 687, 712], "main": [137, 160, 161, 162, 163, 164, 675, 676, 677, 678, 703, 704, 712], "mainli": 347, "maintain": [336, 367, 372, 539, 553], "major": [650, 704], "make": [1, 3, 128, 161, 191, 192, 193, 276, 340, 347, 355, 356, 357, 358, 359, 360, 388, 476, 497, 512, 529, 546, 604, 613, 633, 634, 635, 637, 638, 669, 687, 703, 711], "malici": 275, "manag": [2, 103, 104, 177, 445, 515, 516, 518, 551, 704, 711, 712], "mani": [2, 173, 347, 630, 668, 675, 676, 677, 678, 710, 711, 712], "manifold": 512, "manner": [2, 707], "mantissa": [201, 268, 616], "manual": [92, 230, 340, 341, 363, 432, 433, 435, 457, 476, 518, 539], "manual_se": [2, 621], "map": [63, 99, 118, 203, 221, 230, 275, 276, 358, 359, 360, 366, 367, 368, 372, 374, 424, 425, 426, 429, 438, 512, 529, 573, 575, 683, 684, 694, 707], "map_loc": [275, 497], "map_priv": 203, "map_shar": 203, "margin": [361, 387, 420, 431, 433, 477, 478], "mark": 497, "martinsson": [562, 651], "mask": [297, 336, 347, 372, 434, 476, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535], "mask_check": 475, "master": 472, "mat": [69, 316, 579], "mat1": [68, 265, 308], "mat2": [68, 117, 265, 308], "match": [1, 72, 78, 92, 142, 151, 165, 173, 243, 275, 297, 362, 371, 481, 497, 518, 548, 554, 574, 608, 634, 635, 636, 637, 638, 667, 683, 694, 703, 711], "materi": [143, 500, 501, 596, 597], "math": [183, 562, 579, 651, 704], "mathbb": [150, 221, 363, 435, 512], "mathbf": [265, 513, 514, 547, 550], "mathbin": [65, 68, 69, 105, 117], "mathcal": [345, 355, 356, 357, 358, 359, 360, 370, 371, 379, 380, 398, 399, 413, 415, 444, 446, 447, 468, 585], "mathemat": [199, 221, 340, 342, 343, 344, 390, 391, 392, 393, 468, 497, 553, 592, 710, 712], "mathrlap": 512, "mathrm": [107, 342, 343, 344, 382, 390, 391, 392, 400, 437, 442, 443, 468, 496, 512, 576], "matmul": [117, 137, 308, 480, 562, 572, 616, 650], "matplotlib": 305, "matric": [65, 68, 105, 117, 118, 127, 128, 129, 130, 161, 211, 265, 276, 284, 293, 295, 308, 378, 437, 512, 518, 560, 562, 572, 620, 650, 651, 674, 675, 677], "matrix": [65, 68, 69, 70, 105, 107, 116, 117, 125, 127, 128, 129, 130, 137, 146, 150, 156, 160, 161, 163, 173, 211, 217, 265, 276, 284, 293, 295, 298, 308, 314, 316, 370, 371, 379, 398, 480, 512, 518, 547, 553, 560, 561, 562, 572, 616, 634, 635, 636, 637, 638, 650, 651, 667, 670, 672, 674, 675, 676, 677, 678, 688, 694], "matrix_exp": 512, "matrix_norm": [513, 553], "matrix_rank": 518, "matter": [161, 173, 497], "max": [74, 75, 76, 88, 108, 125, 132, 133, 137, 150, 152, 187, 188, 228, 333, 334, 335, 346, 347, 361, 362, 371, 375, 376, 381, 386, 387, 395, 396, 397, 414, 416, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 436, 448, 449, 456, 477, 478, 480, 503, 542, 577, 578, 644, 645, 657, 687, 689, 690, 703], "max_": [421, 422, 423, 513, 547], "max_autotun": 137, "max_idx": 662, "max_indic": 301, "max_norm": [370, 371, 502, 503], "max_pool1d": 577, "max_pool2d": 578, "max_val": 386, "max_valu": [132, 386], "maxim": [88, 301, 361, 424, 425, 426], "maximum": [74, 76, 88, 152, 153, 174, 175, 176, 197, 228, 229, 230, 276, 301, 386, 504, 579, 593], "maxnorm": 593, "maxpool": [375, 376], "maxpool1d": 424, "maxpool2d": [425, 429], "maxpool3d": [426, 687], "maxunpool1d": [333, 421, 687], "maxunpool2d": [334, 375, 422, 687], "maxunpool3d": [335, 376, 423, 687], "mean": [105, 118, 142, 150, 304, 314, 319, 323, 324, 330, 331, 332, 334, 335, 336, 340, 341, 342, 343, 344, 345, 346, 347, 361, 363, 365, 369, 371, 372, 373, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 398, 400, 401, 402, 403, 410, 411, 412, 414, 415, 417, 418, 419, 420, 427, 431, 432, 433, 435, 436, 442, 443, 444, 447, 448, 449, 456, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 477, 478, 479, 496, 497, 508, 510, 554, 576, 585, 586, 616, 644, 645, 651, 687, 689, 690, 704], "meant": 539, "meantim": [340, 341, 361, 363, 387, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477], "measur": [1, 340, 341, 361, 387, 394, 419, 420, 477, 478], "mebibyt": 497, "mechan": [103, 104, 177, 551, 704], "median": [320, 687], "medium": 616, "meet": 142, "meiyu": 276, "member": [381, 712], "memori": [92, 94, 119, 134, 137, 173, 174, 175, 176, 202, 203, 204, 205, 207, 275, 371, 398, 399, 473, 474, 476, 497, 505, 506, 512, 539, 551, 558, 581, 582, 584, 585, 586, 587, 612, 634, 635, 636, 637, 638, 665, 687, 694, 700, 704, 707, 711, 712], "memory_format": [134, 174, 175, 207, 497, 505, 506, 558, 582, 584, 586, 700], "merg": [429, 438], "messag": 4, "met": [142, 276, 476, 636], "meta": 711, "metadata": [142, 275, 604], "method": [2, 88, 89, 90, 202, 221, 275, 276, 321, 324, 332, 340, 342, 343, 369, 370, 385, 429, 430, 434, 438, 439, 445, 447, 457, 487, 497, 502, 513, 518, 520, 522, 525, 528, 529, 530, 532, 533, 534, 535, 536, 542, 547, 573, 646, 650, 651, 711, 712], "mh": [71, 128, 129, 130, 650], "mha": 434, "mi": [692, 693], "mib": 497, "midpoint": [321, 573], "might": [151, 497, 499, 505, 506], "migrat": [305, 550, 703], "millisecond": 1, "min": [74, 75, 76, 89, 132, 133, 153, 187, 188, 228, 293, 314, 346, 386, 414, 416, 436, 449, 456, 560, 562, 572, 650, 651, 658, 675, 676, 677, 678], "min_": 650, "min_indic": 306, "min_val": 386, "min_valu": [132, 386], "mind": 370, "ming": 276, "mini": [342, 343, 344, 370, 371, 382, 387, 390, 391, 392, 400, 420, 431, 433, 443, 468, 477, 496], "minibatch": [293, 332, 340, 341, 361, 363, 387, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 481], "minim": [89, 306], "minimum": [75, 76, 89, 108, 153, 198, 228, 229, 230, 306, 347, 386, 478, 634, 635, 636, 637, 638, 711], "minkowski": 125, "minlength": 108, "mismatch": 94, "miss": [68, 298, 308, 361, 390, 391, 392, 548], "mitig": 704, "mix": [497, 703], "mixed_precis": 497, "mixin": 487, "mixtur": 363, "mkl": 703, "mlp": 487, "mm": [298, 438, 439, 572, 650, 687], "mmap": [203, 275], "mmape": 275, "mn": 560, "mobilenetv3": 385, "mod": 548, "mode": [103, 104, 137, 177, 215, 249, 250, 275, 305, 342, 343, 344, 355, 356, 357, 371, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 428, 445, 468, 481, 482, 499, 507, 509, 513, 518, 551, 572, 615, 617, 687, 703, 704, 712], "model": [103, 137, 275, 332, 364, 381, 392, 393, 428, 434, 457, 468, 472, 474, 475, 476, 497, 498, 499, 505, 506, 511, 513, 516, 529, 548, 549, 646, 694, 703, 704], "model_ddp": 497, "model_state_dict": 703, "modern": 550, "modif": [204, 205], "modifi": [143, 144, 221, 263, 264, 370, 424, 450, 472, 474, 476, 481, 482, 489, 490, 491, 494, 495, 497, 503, 504, 528, 529, 530, 532, 533, 534, 535], "modul": [65, 68, 103, 105, 117, 137, 216, 275, 298, 305, 308, 332, 336, 342, 343, 344, 345, 355, 356, 357, 358, 359, 360, 364, 365, 366, 367, 368, 370, 371, 372, 380, 382, 390, 391, 392, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 429, 430, 438, 439, 443, 445, 457, 462, 468, 472, 473, 475, 476, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 499, 505, 506, 507, 508, 509, 510, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 542, 546, 547, 548, 550, 604, 694, 704, 712], "module_cl": 546, "moduledict": [512, 513, 514], "modulelist": 457, "modulo": [199, 592], "modulu": [199, 592], "moment": 146, "momentum": [342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468, 703], "monoton": [427, 608], "more": [87, 100, 101, 102, 103, 104, 108, 116, 119, 121, 127, 128, 129, 130, 137, 142, 156, 162, 171, 173, 177, 191, 192, 193, 194, 205, 215, 217, 221, 230, 231, 247, 251, 253, 254, 276, 279, 282, 284, 294, 295, 314, 320, 332, 336, 341, 346, 347, 355, 356, 357, 358, 359, 360, 370, 371, 372, 388, 398, 424, 425, 426, 434, 440, 441, 442, 456, 476, 487, 492, 493, 497, 499, 505, 506, 512, 515, 516, 551, 552, 553, 560, 571, 572, 598, 604, 608, 616, 650, 672, 674, 683, 687, 694, 695, 703, 704, 706, 707, 711, 712], "moreov": 497, "most": [103, 137, 156, 173, 251, 309, 332, 476, 497, 505, 506, 518, 616, 672, 704, 711], "mostli": 497, "motiv": 704, "moustapha": 332, "move": [1, 275, 311, 342, 343, 344, 401, 402, 403, 468, 500, 501, 711], "movedim": 310, "mp": 711, "mseloss": [388, 460], "mt": [128, 572, 650], "mtia": [216, 712], "mu_i": 150, "mu_x": 150, "much": [276, 371, 529, 704], "mul": [243, 315, 711], "multi": [173, 230, 341, 364, 379, 398, 431, 432, 433, 434, 444, 474, 481, 497, 710, 711, 712], "multi_dot": 127, "multidimension": [243, 390], "multigammaln": 317, "multihead": [434, 474], "multihead_attn": 434, "multiheadattent": [472, 474, 476], "multilay": [379, 398], "multipl": [65, 67, 68, 74, 75, 88, 89, 92, 125, 127, 137, 146, 150, 171, 173, 176, 205, 211, 217, 231, 266, 267, 298, 301, 306, 308, 340, 341, 358, 359, 360, 361, 363, 374, 379, 387, 393, 394, 416, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 480, 497, 520, 521, 522, 523, 524, 525, 526, 527, 560, 616, 634, 635, 637, 638, 666, 667, 674, 682, 687, 694, 695, 704], "multipli": [64, 65, 66, 67, 68, 69, 70, 105, 117, 156, 173, 221, 268, 298, 308, 313, 316, 340, 355, 356, 357, 360, 379, 398, 481, 482, 483, 518, 560, 616, 646, 647, 650, 672], "multiprocess": [364, 497], "multivari": 314, "must": [1, 2, 65, 66, 67, 68, 69, 70, 76, 92, 98, 105, 107, 109, 110, 111, 112, 113, 114, 117, 121, 124, 139, 142, 150, 161, 163, 164, 165, 167, 170, 171, 173, 192, 193, 202, 203, 205, 208, 209, 221, 230, 231, 233, 243, 263, 267, 270, 274, 276, 290, 294, 296, 297, 298, 303, 304, 311, 314, 319, 320, 323, 324, 328, 341, 347, 355, 356, 357, 358, 359, 360, 364, 370, 374, 375, 376, 381, 382, 388, 421, 428, 431, 432, 435, 460, 466, 481, 497, 507, 509, 529, 539, 540, 546, 548, 553, 561, 562, 565, 566, 569, 577, 578, 599, 608, 611, 619, 634, 635, 636, 637, 638, 646, 651, 662, 666, 667, 671, 676, 678, 682, 685, 687, 691, 692, 694, 695, 697, 704], "mutat": [137, 142], "mv": 687, "my": [364, 708, 710], "my_model": 497, "mymodul": [429, 430, 438, 439], "mypi": 253, "n": [65, 68, 69, 70, 91, 105, 106, 108, 115, 117, 121, 127, 128, 129, 130, 150, 154, 155, 165, 186, 191, 221, 225, 226, 230, 263, 264, 265, 276, 284, 293, 298, 300, 305, 308, 316, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 366, 367, 368, 370, 371, 372, 374, 375, 376, 378, 379, 380, 381, 382, 387, 388, 390, 391, 392, 394, 395, 396, 397, 398, 400, 410, 411, 412, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 435, 437, 443, 444, 446, 450, 451, 452, 453, 454, 455, 460, 462, 463, 464, 468, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 496, 497, 512, 524, 533, 552, 560, 561, 562, 567, 572, 573, 585, 587, 600, 608, 644, 645, 646, 650, 651, 666, 667, 672, 676, 678, 688, 689, 690, 691, 694], "n0": 694, "n1": [594, 694], "n2": 594, "n3": 594, "n_class": 332, "n_fft": [263, 646], "n_i": [337, 338, 339, 355, 356, 357, 421, 422, 423, 477, 478], "n_power_iter": [513, 547], "n_sampl": 314, "n_t": 379, "na": [562, 651], "name": [76, 203, 275, 479, 489, 494, 495, 497, 512, 513, 514, 515, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 547, 548, 550, 604, 614, 688, 712], "namedshap": 479, "namedtensor": 479, "namedtupl": [152, 153, 211, 266, 295, 301, 304, 306, 309, 320, 332, 562, 572, 633, 650, 669, 674], "nan": [63, 65, 68, 69, 70, 73, 76, 77, 95, 99, 105, 121, 174, 175, 176, 197, 198, 199, 228, 255, 256, 258, 259, 279, 284, 302, 303, 307, 318, 319, 320, 321, 322, 503, 566, 603, 608, 640, 674], "nanmean": 303, "narrow": 324, "nathan": [562, 651], "nativ": [503, 504, 616], "natur": [273, 277, 279, 284, 332, 476, 704], "nbatch": [340, 341], "nccl": [497, 704], "nccl2": 497, "nchannel": 436, "nchw": 576, "ncol": [634, 635, 637, 638], "ncolblock": 634, "nd": 704, "ndarrai": [93, 202, 204, 634, 635, 636, 637, 638, 665], "ndhwc": [506, 711], "ne": [513, 547, 555], "nearbi": [187, 188], "nearest": [321, 481, 483, 573, 601], "nearli": 562, "necessari": [2, 241, 540, 541, 711], "necessarili": [304, 363, 435, 505, 506], "need": [118, 119, 127, 161, 163, 173, 194, 203, 297, 314, 363, 370, 424, 425, 426, 434, 472, 474, 476, 497, 505, 506, 518, 520, 524, 526, 554, 589, 594, 608, 643, 672, 703, 704, 711], "needs_fixed_stride_ord": 712, "neg": [2, 3, 41, 42, 77, 108, 113, 145, 148, 194, 205, 256, 258, 260, 284, 296, 314, 318, 323, 324, 332, 341, 349, 350, 351, 372, 381, 414, 421, 422, 423, 431, 435, 437, 442, 460, 477, 478, 565, 566, 597, 601, 626, 629, 667, 675, 676, 677, 678, 685, 686], "negat": [597, 659], "negative_id": 478, "negative_slop": 414, "neginf": 318, "neglig": 616, "neighbor": [221, 263, 481, 483, 646], "neighborhood": [374, 480], "neighbour": 416, "neither": [156, 194, 434, 476, 553, 672], "nelement": [432, 461], "neq": [325, 431, 433, 650], "nest": [142, 428, 434, 475, 476, 505, 506, 694, 704], "nestedtensor": [434, 476], "net": [364, 497, 529], "network": [336, 342, 343, 344, 347, 358, 359, 360, 364, 365, 366, 367, 368, 369, 372, 381, 393, 398, 428, 435, 440, 441, 447, 456, 458, 468, 472, 474, 476, 487, 513, 516, 542, 547], "neural": [336, 347, 365, 372, 381, 393, 427, 428, 435, 440, 441, 456, 458, 472, 474, 476, 516], "neuron": 365, "never": [93, 125, 137, 263, 275, 497, 539, 711], "new": [2, 3, 63, 93, 95, 96, 97, 98, 99, 120, 121, 124, 126, 135, 145, 147, 148, 157, 161, 183, 187, 188, 192, 193, 195, 237, 241, 255, 256, 259, 262, 277, 278, 279, 280, 297, 323, 326, 342, 343, 344, 379, 390, 391, 392, 434, 468, 479, 481, 489, 494, 495, 507, 508, 509, 510, 513, 518, 520, 524, 525, 526, 528, 529, 530, 532, 533, 534, 535, 543, 547, 550, 551, 580, 590, 591, 595, 596, 597, 603, 604, 608, 613, 614, 623, 625, 627, 629, 640, 641, 643, 661, 663, 664, 680, 682, 686, 692, 693, 694, 703, 706, 707], "new_a": 548, "new_group": 468, "new_stat": [2, 621], "newer": 547, "newli": [2, 187, 188, 370, 371, 574, 575], "next": [328, 380, 399, 446, 541, 704, 711], "nhead": [472, 473, 474, 475, 476], "nhwc": [505, 506, 711], "nice": [355, 356, 357, 358, 359, 360, 374, 421, 422, 423, 480], "niederreit": 579, "niki": [472, 474, 476], "nine": 616, "ninja": 703, "niter": [276, 562, 651], "nix": 381, "nll": 435, "nllloss": [363, 462, 687], "nlp": [390, 391, 392, 400], "nn": [137, 173, 488, 489, 490, 491, 492, 493, 494, 495, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 632, 646, 687, 703, 704], "nnz": [324, 634, 635, 636, 637, 638], "no_grad": [103, 177, 370, 434, 476, 499, 703, 712], "noam": [472, 474, 476], "node": [347, 364, 497, 712], "nola": 263, "non": [2, 77, 79, 91, 108, 121, 124, 127, 137, 143, 144, 149, 173, 197, 198, 205, 243, 276, 286, 293, 298, 303, 314, 319, 320, 324, 337, 338, 339, 351, 352, 353, 356, 357, 359, 360, 363, 370, 371, 373, 379, 396, 397, 398, 421, 422, 423, 424, 425, 426, 427, 431, 433, 435, 444, 446, 454, 455, 460, 484, 485, 497, 513, 546, 552, 565, 608, 609, 623, 634, 635, 636, 637, 638, 667, 683, 685, 694, 704, 711], "non_block": 539, "nondeterminist": [108, 174, 175, 176, 266, 347, 355, 356, 357, 358, 359, 360, 424, 425, 426, 615, 687], "nondeterministic_bitwis": 712, "nondeterministic_seed": 712, "none": [1, 2, 3, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 35, 37, 39, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 121, 124, 126, 127, 128, 129, 130, 132, 133, 135, 137, 139, 140, 141, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 165, 166, 168, 169, 170, 172, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 189, 194, 195, 196, 197, 198, 199, 200, 201, 203, 206, 207, 208, 209, 210, 211, 212, 216, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 235, 236, 238, 239, 240, 241, 243, 244, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 370, 371, 373, 375, 376, 377, 379, 380, 381, 382, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 442, 443, 444, 445, 446, 460, 461, 462, 463, 464, 468, 472, 473, 474, 475, 476, 477, 478, 479, 481, 482, 483, 487, 489, 490, 491, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 512, 513, 514, 517, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 539, 541, 542, 544, 547, 548, 550, 551, 552, 553, 554, 555, 557, 558, 560, 561, 562, 565, 566, 567, 569, 570, 572, 573, 576, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 593, 594, 599, 601, 602, 603, 608, 620, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 662, 663, 664, 665, 667, 669, 672, 674, 675, 676, 677, 678, 679, 680, 683, 684, 688, 689, 690, 691, 694, 696, 697, 698, 699, 700, 711], "nonfinit": 255, "nonlinear": [340, 361, 387, 444, 446, 456], "nonmask": 525, "nonneg": [478, 562, 651], "nonzero": [263, 285, 287, 288, 293, 697], "nor": [434, 476, 497, 553, 571, 650], "norm": [125, 167, 370, 371, 419, 437, 443, 473, 474, 475, 476, 477, 496, 502, 503, 513, 514, 523, 524, 529, 532, 533, 547, 550, 593], "norm_first": [472, 474, 476], "norm_typ": [370, 371, 395, 396, 397, 502, 503], "normal": [150, 229, 263, 281, 336, 342, 343, 344, 366, 367, 368, 372, 382, 390, 391, 392, 400, 410, 411, 412, 416, 443, 456, 468, 472, 473, 474, 475, 476, 503, 504, 513, 514, 529, 537, 538, 547, 550, 576, 585, 586, 593, 646, 687, 703, 712], "normal_": 712, "normalized_shap": [400, 443, 496], "notabl": 137, "notat": [173, 393, 620], "note": [0, 79, 93, 98, 103, 108, 121, 127, 137, 142, 151, 156, 161, 173, 202, 205, 208, 221, 253, 263, 276, 298, 337, 338, 339, 340, 341, 347, 355, 356, 357, 358, 359, 360, 361, 363, 370, 371, 375, 379, 381, 387, 393, 394, 398, 419, 420, 424, 425, 426, 429, 431, 432, 433, 434, 435, 438, 439, 442, 444, 451, 460, 461, 468, 472, 477, 481, 487, 497, 499, 505, 506, 553, 572, 634, 635, 637, 638, 646, 650, 665, 672, 687, 694, 707], "noth": 518, "notic": [68, 298, 308, 340, 481, 683], "notion": [342, 343, 344, 390, 391, 392, 468], "now": [202, 203, 214, 263, 425, 481, 487, 502, 518, 529, 550, 613, 642, 646, 703, 704], "np": [125, 168, 173, 191, 192, 193, 566], "nrow": [634, 635, 637, 638], "nrowblock": 635, "nuc": [524, 533, 553], "nuclear": 553, "num": [314, 379, 382, 398, 444], "num_channel": 382, "num_decoder_lay": 472, "num_direct": [379, 398, 444], "num_embed": [370, 371], "num_encoder_lay": 472, "num_featur": [342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468], "num_gpu": 704, "num_group": 382, "num_head": 434, "num_lay": [379, 398, 444, 445, 473, 475], "num_paramet": 436, "num_sampl": 314, "number": [2, 3, 64, 65, 66, 67, 68, 69, 70, 77, 79, 91, 105, 107, 108, 113, 117, 119, 123, 131, 132, 136, 145, 149, 150, 165, 168, 170, 173, 174, 178, 186, 194, 196, 199, 203, 205, 207, 208, 210, 218, 219, 220, 224, 228, 229, 230, 241, 242, 263, 265, 268, 269, 276, 281, 292, 296, 304, 313, 314, 318, 322, 325, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 345, 346, 347, 348, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 369, 370, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 393, 394, 398, 399, 404, 405, 406, 407, 408, 409, 414, 415, 417, 418, 419, 420, 421, 422, 423, 427, 431, 432, 433, 434, 435, 436, 442, 444, 446, 447, 448, 449, 456, 458, 459, 460, 461, 462, 464, 465, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 487, 513, 518, 523, 524, 526, 527, 529, 532, 533, 534, 535, 539, 540, 541, 543, 547, 552, 553, 554, 556, 557, 562, 565, 569, 579, 581, 582, 583, 585, 586, 587, 592, 594, 595, 598, 599, 600, 601, 609, 613, 616, 617, 618, 619, 620, 621, 634, 635, 636, 637, 638, 643, 644, 645, 646, 647, 651, 666, 667, 668, 676, 678, 683, 684, 688, 689, 690, 691, 692, 693, 699, 711], "numel": [135, 150, 251], "numer": [66, 121, 291, 293, 341, 342, 343, 344, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 443, 462, 465, 468, 477, 496, 513, 547, 576, 608, 650], "numpi": [72, 73, 78, 91, 93, 94, 121, 168, 170, 171, 173, 190, 191, 192, 193, 197, 198, 203, 204, 231, 305, 310, 566, 591, 594, 601, 613, 620, 634, 635, 636, 637, 638, 650, 652, 653, 662, 665, 666, 668, 691, 694, 695, 711], "nvidia": [687, 710, 712], "o": [275, 399, 434, 604, 703], "o_t": 398, "obj": [94, 252, 253, 604], "object": [1, 2, 3, 94, 137, 173, 190, 202, 205, 252, 253, 275, 276, 296, 364, 366, 367, 368, 372, 390, 391, 392, 438, 516, 531, 540, 541, 544, 545, 546, 604, 654, 655, 659, 706, 707, 711], "observ": [146, 150, 305, 340, 341, 342, 343, 344, 361, 363, 387, 390, 391, 392, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 468, 477], "obtain": [2, 211, 347, 435, 497, 562, 579, 651], "occupi": 416, "occur": [137, 173, 263, 347, 468, 553], "occurr": [304, 539, 683, 684], "odict_kei": 532, "odot": [379, 380, 398, 399], "off": [104, 106, 115, 225, 226, 263, 337, 338, 339, 341, 421, 422, 423], "offer": [497, 687], "offici": [332, 703], "offset": [92, 161, 162, 163, 164, 205, 371, 497, 574, 575, 676, 678], "often": [309, 370, 390, 391, 392, 487, 512], "oh": [375, 376], "ok": 711, "old": [202, 367, 550, 558, 604, 700], "omega": 646, "omit": [381, 442], "onc": [173, 275, 364, 497, 516, 518, 550, 572, 618, 622, 704, 712], "one": [3, 76, 94, 100, 103, 104, 108, 119, 121, 131, 135, 142, 162, 173, 177, 190, 194, 197, 198, 199, 221, 230, 231, 245, 248, 251, 264, 265, 274, 290, 298, 302, 307, 314, 320, 332, 337, 338, 339, 340, 341, 342, 343, 344, 347, 355, 358, 359, 360, 371, 375, 376, 381, 390, 391, 392, 394, 395, 396, 397, 407, 408, 409, 419, 432, 468, 476, 481, 487, 497, 499, 513, 514, 515, 519, 529, 540, 550, 551, 552, 553, 574, 575, 592, 608, 616, 620, 623, 642, 650, 666, 671, 672, 674, 682, 683, 685, 686, 687, 694, 704, 711, 712], "oneapi": 703, "oneapi_root": 703, "ones": [103, 107, 119, 137, 156, 164, 186, 263, 265, 275, 341, 361, 370, 374, 381, 382, 400, 432, 433, 435, 437, 443, 480, 487, 496, 520, 521, 522, 523, 524, 525, 526, 527, 529, 530, 543, 545, 548, 558, 576, 593, 611, 616, 630, 668, 672, 697, 711], "onesid": [263, 646], "onli": [74, 75, 92, 106, 107, 115, 137, 142, 170, 174, 176, 190, 197, 198, 202, 203, 204, 220, 221, 225, 226, 230, 237, 242, 247, 255, 264, 275, 276, 293, 298, 332, 358, 359, 360, 363, 364, 370, 371, 374, 398, 400, 431, 433, 436, 468, 476, 480, 481, 487, 490, 491, 492, 493, 497, 500, 501, 505, 506, 519, 539, 540, 541, 553, 560, 572, 581, 585, 587, 589, 612, 616, 618, 621, 622, 634, 635, 636, 637, 638, 642, 646, 650, 657, 665, 676, 678, 683, 684, 687, 691, 692, 693, 694, 703, 704, 711, 712], "onnx": [540, 541], "onto": [275, 518], "op": [127, 137, 218, 275, 281, 560, 618, 674], "op1": 173, "op2": 173, "opaqu": 202, "open": [68, 121, 201, 275, 298, 308], "oper": [65, 68, 79, 103, 105, 106, 108, 110, 113, 115, 117, 119, 124, 127, 134, 137, 142, 144, 152, 153, 154, 155, 168, 173, 174, 175, 176, 186, 199, 202, 205, 206, 207, 215, 219, 225, 226, 264, 274, 283, 290, 298, 303, 308, 319, 322, 336, 341, 346, 347, 348, 355, 356, 357, 358, 359, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 375, 376, 382, 384, 385, 386, 387, 389, 390, 391, 392, 394, 400, 414, 419, 424, 425, 426, 441, 443, 447, 448, 449, 456, 471, 472, 474, 476, 480, 496, 500, 501, 542, 548, 553, 557, 558, 560, 569, 570, 581, 582, 583, 584, 585, 586, 587, 588, 592, 598, 615, 616, 634, 635, 636, 637, 638, 642, 649, 665, 683, 687, 694, 697, 699, 700, 706, 710, 711], "operand": [113, 142, 173, 711], "operatornam": [200, 340, 341, 347, 387, 388, 394, 419, 460, 478, 562, 585, 625, 651], "opposit": [121, 650, 671], "opt": 703, "opt_einsum": 173, "optim": [137, 173, 276, 342, 343, 344, 363, 370, 390, 391, 392, 431, 432, 433, 434, 461, 468, 476, 487, 497, 505, 506, 512, 518, 562, 703], "optimizer_param": 497, "optimizer_state_dict": 703, "option": [1, 2, 3, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 90, 92, 93, 94, 95, 96, 97, 98, 99, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 121, 124, 126, 127, 128, 129, 130, 132, 134, 135, 136, 137, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 160, 161, 162, 163, 164, 165, 167, 168, 170, 172, 173, 174, 175, 176, 178, 183, 186, 194, 195, 196, 197, 198, 199, 201, 203, 205, 206, 207, 208, 209, 210, 211, 221, 224, 225, 226, 227, 228, 229, 232, 233, 241, 243, 255, 257, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 332, 336, 340, 341, 346, 347, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 371, 372, 374, 375, 376, 377, 381, 384, 385, 386, 387, 388, 393, 394, 400, 404, 405, 406, 407, 408, 409, 414, 419, 420, 424, 425, 426, 429, 430, 431, 432, 433, 435, 437, 438, 439, 442, 447, 448, 449, 456, 460, 461, 468, 471, 473, 475, 477, 478, 480, 481, 482, 483, 498, 499, 507, 508, 510, 512, 513, 514, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 537, 538, 539, 540, 541, 542, 543, 545, 547, 548, 550, 552, 553, 554, 557, 558, 560, 561, 562, 565, 569, 570, 572, 573, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 593, 594, 601, 603, 608, 620, 623, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 640, 641, 642, 643, 644, 645, 646, 647, 649, 650, 651, 662, 663, 664, 665, 666, 669, 671, 674, 675, 676, 677, 678, 680, 683, 684, 687, 688, 689, 690, 691, 696, 697, 699, 700, 703, 704, 711], "ord": 553, "order": [3, 90, 116, 127, 161, 164, 165, 173, 190, 191, 192, 193, 221, 264, 276, 305, 311, 312, 314, 332, 341, 347, 364, 429, 438, 456, 457, 487, 497, 525, 539, 540, 541, 542, 553, 560, 563, 573, 608, 611, 633, 650, 669, 676, 678, 683, 687, 688, 694, 704, 711, 712], "ordereddict": [429, 438, 457, 487, 529], "ordin": [634, 635, 637, 638, 711], "ordinari": 497, "org": [137, 142, 276, 398, 448, 475, 478, 514, 550, 562, 616], "orig_func": [177, 551], "origin": [122, 127, 190, 241, 263, 297, 311, 332, 336, 348, 363, 364, 379, 458, 505, 506, 512, 513, 514, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 539, 542, 545, 547, 548, 550, 563, 599, 610, 633, 639, 672, 683, 684, 704], "original0": [514, 515, 518, 550], "original1": [514, 515, 518, 550], "orlando": 381, "ormqr": 211, "orth_linear": 512, "ortho": 276, "ortho_bparam": 276, "ortho_fparam": 276, "ortho_iparam": 276, "orthogon": [276, 560, 572], "orthogonal_map": 512, "orthonorm": [512, 650], "ot": 376, "other": [3, 64, 73, 79, 85, 92, 93, 98, 103, 104, 109, 110, 112, 113, 114, 116, 121, 137, 145, 151, 161, 167, 168, 169, 177, 178, 179, 196, 197, 198, 199, 202, 208, 209, 210, 222, 223, 224, 232, 233, 235, 236, 241, 243, 255, 265, 267, 268, 269, 271, 272, 281, 282, 283, 285, 287, 288, 291, 292, 298, 301, 302, 306, 307, 311, 313, 315, 325, 328, 355, 356, 357, 358, 359, 360, 362, 364, 374, 379, 381, 393, 424, 428, 429, 438, 450, 457, 472, 476, 480, 481, 482, 487, 497, 503, 504, 505, 506, 529, 539, 551, 555, 560, 588, 592, 608, 613, 614, 616, 634, 635, 636, 637, 638, 642, 647, 648, 665, 671, 675, 677, 683, 691, 692, 697, 698, 704, 710], "otherwis": [2, 65, 66, 67, 68, 69, 72, 74, 75, 76, 78, 79, 105, 121, 173, 179, 190, 202, 257, 263, 266, 275, 276, 291, 296, 301, 303, 304, 306, 308, 309, 319, 322, 338, 339, 361, 363, 366, 367, 368, 372, 379, 383, 384, 385, 386, 388, 398, 414, 432, 433, 435, 436, 444, 447, 460, 466, 468, 471, 472, 474, 476, 477, 478, 497, 512, 517, 518, 539, 540, 542, 543, 551, 560, 562, 570, 572, 579, 588, 595, 608, 616, 623, 644, 645, 646, 649, 682, 683, 684, 689, 690, 697, 711], "otim": [70, 265, 378], "our": [340, 505, 506, 616, 704], "out": [3, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 91, 95, 96, 97, 98, 99, 103, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 121, 124, 126, 127, 128, 129, 130, 132, 133, 135, 137, 139, 140, 141, 144, 145, 147, 148, 151, 152, 153, 154, 155, 157, 160, 165, 166, 168, 169, 170, 172, 173, 174, 178, 180, 181, 182, 183, 184, 185, 186, 189, 194, 195, 196, 197, 198, 199, 200, 201, 205, 206, 208, 209, 210, 211, 212, 222, 223, 224, 227, 228, 229, 230, 232, 233, 234, 235, 236, 238, 239, 240, 241, 243, 244, 260, 261, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 300, 301, 302, 303, 304, 306, 307, 308, 309, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 324, 325, 326, 327, 328, 329, 333, 334, 335, 337, 338, 339, 345, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 365, 366, 367, 368, 370, 372, 375, 376, 379, 380, 395, 396, 397, 398, 413, 415, 421, 422, 423, 424, 425, 426, 440, 441, 444, 446, 450, 451, 452, 453, 454, 455, 472, 473, 474, 475, 476, 480, 481, 482, 483, 484, 485, 486, 505, 506, 523, 524, 525, 526, 552, 553, 554, 555, 557, 558, 560, 561, 565, 566, 567, 569, 572, 573, 580, 581, 583, 585, 587, 588, 591, 592, 593, 597, 601, 602, 603, 605, 606, 607, 608, 623, 624, 625, 626, 627, 628, 629, 633, 640, 641, 643, 644, 645, 647, 648, 650, 662, 663, 664, 667, 669, 671, 674, 675, 677, 679, 680, 687, 689, 690, 691, 694, 696, 697, 698, 699, 700, 704, 711], "out_channel": [355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409], "out_dim": 694, "out_featur": [345, 413, 415, 487, 512, 513, 514, 546, 547, 550], "out_i": 264, "out_int32": [121, 608], "out_j": 357, "out_rnn": 516, "out_unf": 480, "outer": [70, 173, 212], "outermost": 221, "outlier": [388, 460], "outlin": 703, "output": [60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 88, 89, 92, 95, 96, 97, 98, 99, 100, 101, 102, 105, 107, 108, 109, 110, 111, 112, 113, 114, 117, 121, 124, 125, 126, 127, 128, 129, 130, 132, 135, 142, 144, 145, 147, 148, 151, 152, 153, 154, 155, 157, 160, 161, 163, 165, 168, 170, 172, 173, 174, 175, 176, 178, 183, 186, 187, 188, 194, 195, 196, 197, 198, 199, 201, 206, 207, 208, 209, 210, 211, 221, 224, 227, 228, 229, 230, 232, 233, 241, 243, 260, 261, 263, 265, 266, 267, 268, 269, 270, 273, 274, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 312, 313, 314, 316, 318, 319, 320, 321, 322, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 431, 432, 433, 434, 435, 436, 437, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 490, 496, 497, 513, 514, 516, 519, 540, 542, 543, 547, 550, 552, 553, 554, 557, 558, 560, 561, 569, 570, 573, 576, 577, 578, 580, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 593, 594, 596, 597, 601, 603, 608, 616, 620, 623, 625, 626, 627, 629, 633, 640, 641, 643, 644, 645, 646, 647, 649, 650, 662, 663, 664, 669, 672, 674, 675, 677, 680, 682, 683, 684, 685, 687, 688, 689, 690, 691, 694, 696, 697, 699, 700, 703, 704, 711], "output1": 332, "output2": 332, "output_2d": 416, "output_4d": 416, "output_devic": [364, 468, 497], "output_pad": [358, 359, 360, 407, 408, 409], "output_ratio": [375, 376], "output_s": [329, 330, 331, 333, 334, 335, 359, 374, 375, 376, 424, 425, 426, 480, 594], "output_scal": 576, "output_zero_point": 576, "outsid": [63, 99, 497], "outweigh": [505, 506], "over": [76, 124, 152, 153, 154, 155, 173, 221, 229, 275, 283, 303, 305, 322, 329, 330, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 347, 355, 356, 357, 358, 359, 360, 361, 363, 371, 374, 375, 376, 382, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 400, 416, 419, 420, 421, 422, 423, 431, 432, 433, 435, 442, 443, 457, 460, 461, 463, 468, 477, 480, 491, 496, 503, 514, 550, 577, 578, 593, 644, 645, 646, 649, 667, 682, 689, 690, 694, 704, 710, 712], "overal": 475, "overestim": [562, 651], "overflow": [154, 155, 303, 319, 322, 570, 601, 649, 676, 678], "overhead": [137, 497, 505, 506], "overlap": [92, 176, 263, 374, 480, 497, 646, 687, 704, 711], "overlin": 691, "overrid": [340, 341, 361, 363, 387, 394, 419, 420, 431, 432, 433, 435, 442, 445, 460, 461, 477, 520, 604, 620], "overspeci": 137, "overview": 497, "overwritten": 93, "ow": [375, 376], "owen": 579, "own": [205, 230, 275, 355, 356, 357, 358, 359, 360, 515, 518, 704, 707], "p": [65, 68, 105, 107, 117, 125, 167, 265, 293, 295, 298, 308, 317, 336, 365, 366, 367, 368, 370, 371, 372, 393, 395, 396, 397, 433, 437, 439, 477, 478, 503, 516, 518, 524, 533, 553, 593], "p_": [127, 295], "p_c": 341, "p_i": [477, 478], "pack": [295, 364, 379, 398, 444, 539, 540, 541, 542], "pack_padded_sequ": [379, 398, 444, 539, 541, 542], "pack_sequ": [379, 398, 444, 542, 544], "packag": [703, 710, 712], "packed_sequ": 544, "packedsequ": [379, 398, 444, 540, 541, 542, 544], "pad": [137, 263, 337, 338, 339, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 370, 371, 374, 404, 405, 406, 407, 408, 409, 421, 422, 423, 424, 425, 426, 431, 434, 450, 451, 452, 453, 454, 455, 475, 476, 480, 484, 485, 486, 540, 542, 543, 545, 577, 578, 646], "pad_mod": 646, "pad_sequ": [541, 545], "padded_sequ": 545, "padding_idx": [370, 371], "padding_mod": [355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409], "padding_sid": 543, "padding_valu": [542, 543], "page": [276, 472, 474, 476, 708, 709], "pai": 341, "pair": [79, 125, 150, 305, 420, 429, 438, 588], "pairwis": [387, 437, 477], "pairwisedist": 478, "paper": [332, 336, 342, 343, 344, 346, 358, 359, 360, 365, 366, 367, 368, 369, 372, 375, 376, 379, 382, 385, 390, 391, 392, 400, 434, 440, 441, 443, 447, 456, 460, 468, 472, 474, 476, 477, 478, 496], "paper119": 478, "parallel": [218, 219, 364, 434, 468, 618, 619], "param": [438, 439, 495, 497], "param_to_hook_all_reduc": 497, "paramet": [1, 2, 3, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 178, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 237, 241, 243, 245, 246, 248, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 311, 312, 313, 314, 316, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 460, 461, 462, 464, 465, 466, 468, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 490, 495, 496, 497, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558, 560, 561, 562, 563, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 603, 604, 608, 610, 611, 612, 613, 614, 615, 616, 617, 620, 621, 622, 623, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 649, 650, 654, 655, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 671, 672, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 703, 704, 707], "parameter": 707, "parameter_nam": 548, "parameters_and_buff": 548, "parameters_to_prun": 529, "parameters_to_vector": 529, "parametr": [512, 513, 514, 516, 517, 518, 519, 522, 547, 548, 550, 707], "parametrizationlist": [512, 513, 514, 518], "parametrizedlinear": [512, 513, 514], "parent": 428, "parmar": [472, 474, 476], "part": [139, 173, 256, 258, 259, 262, 468, 497, 498, 516, 573, 585, 672, 675, 676, 677, 678, 704], "parti": 703, "partial": [163, 221, 294, 424, 425, 426, 525, 704], "particip": 497, "particular": [2, 298, 364, 694, 704, 712], "particularli": [363, 364, 435], "partit": [332, 672], "pass": [94, 121, 137, 163, 190, 203, 205, 230, 275, 332, 333, 334, 335, 342, 343, 344, 364, 371, 375, 376, 433, 434, 457, 476, 481, 490, 491, 497, 516, 518, 520, 525, 539, 542, 546, 548, 604, 608, 612, 650, 704, 711], "past": [1, 497], "patch": [374, 480], "path": [173, 476, 704], "path_find": 173, "pathlik": [275, 604], "pattern": [364, 542], "pca": 562, "pdf": 347, "pdist": 437, "peak": [497, 704], "pearson": 146, "penal": 478, "per": [137, 156, 187, 276, 337, 338, 339, 340, 341, 342, 343, 344, 361, 363, 364, 371, 382, 387, 390, 391, 392, 393, 394, 400, 419, 420, 428, 431, 432, 433, 435, 442, 443, 460, 461, 468, 477, 496, 497, 514, 550, 554, 562, 574, 620, 622, 651, 668, 672, 694, 704, 707], "per_channel_affin": 574, "per_sample_weight": 371, "per_tensor_affin": [575, 576, 577, 578], "perf_hint": 137, "perfectli": 616, "perform": [65, 66, 67, 68, 69, 70, 103, 105, 117, 137, 143, 144, 154, 155, 168, 194, 196, 274, 276, 281, 290, 303, 308, 316, 319, 322, 347, 355, 356, 357, 358, 359, 360, 363, 367, 370, 371, 436, 457, 472, 475, 487, 497, 500, 501, 513, 518, 539, 546, 548, 553, 562, 570, 598, 612, 616, 649, 651, 687, 704, 707, 711, 712], "period": [106, 115, 225, 226, 264], "perm": 293, "perman": [520, 521, 522, 523, 524, 525, 526, 527, 536], "permut": [173, 293, 295, 505, 506, 587], "persist": [498, 500], "perspect": 704, "phase": 650, "phi": [377, 650], "phy": 579, "pi": [77, 115, 225, 226, 377, 442, 566, 646], "pick": 137, "pickl": [275, 604], "pickle_load_arg": 275, "pickle_modul": [275, 604], "pickle_protocol": 604, "pictur": 137, "pid": 468, "pin": [174, 176, 203, 539, 581, 585, 587, 634, 635, 636, 637, 638, 665, 712], "pin_memori": [174, 176, 203, 581, 585, 587, 634, 635, 636, 637, 638, 665], "pinv": 564, "pip": 703, "pivot": [293, 294, 295, 572], "pixel": [356, 363, 366, 367, 368, 372, 435, 440, 441, 481], "pixel_shuffl": 440, "pixel_unshuffl": 441, "pixelshuffl": 441, "place": [2, 119, 142, 173, 202, 314, 336, 346, 364, 365, 366, 367, 368, 369, 370, 372, 384, 385, 386, 414, 446, 447, 448, 449, 456, 471, 487, 497, 503, 504, 505, 506, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 548, 599, 601, 605, 606, 607, 667], "placehold": 389, "placement": 487, "plain": [341, 429, 438, 512], "plan": [497, 572], "plane": [161, 329, 330, 331, 333, 334, 335, 337, 338, 339, 355, 356, 357, 358, 359, 360, 375, 376, 395, 396, 397, 400, 416, 421, 422, 423, 514, 550, 577, 578, 600], "platform": [572, 650, 703], "pleas": [68, 119, 142, 156, 263, 298, 308, 347, 358, 393, 497, 547, 548, 550, 586, 612, 614, 621, 636, 694, 703, 704, 706, 707, 711], "plot": 305, "plot_surfac": 305, "plt": 305, "plu": [205, 704], "point": [1, 2, 3, 77, 79, 94, 106, 107, 115, 137, 145, 146, 150, 174, 175, 176, 197, 198, 199, 214, 221, 225, 226, 230, 248, 263, 268, 270, 274, 276, 281, 290, 303, 319, 321, 328, 337, 338, 339, 355, 356, 357, 358, 359, 360, 363, 374, 421, 422, 423, 480, 481, 497, 505, 506, 553, 573, 574, 575, 579, 588, 601, 613, 614, 620, 687, 703, 704, 706, 707, 711], "pointwis": [137, 281, 282, 393], "poisson": 442, "polosukhin": [472, 474, 476], "pool": [329, 330, 331, 333, 334, 335, 337, 338, 339, 375, 376, 395, 396, 397, 421, 422, 423, 424, 425, 426, 429, 577, 578], "popul": [304, 320], "portion": [200, 364, 460, 520, 521, 522, 523, 524, 525, 526, 527], "pos_weight": 341, "posinf": 318, "posit": [2, 106, 108, 115, 128, 129, 130, 205, 225, 226, 258, 261, 276, 296, 311, 318, 323, 324, 341, 355, 356, 357, 362, 363, 364, 381, 388, 465, 477, 478, 490, 491, 599, 601, 675, 676, 677, 678, 686], "positive_id": 478, "possibl": [93, 94, 131, 137, 174, 175, 176, 199, 275, 341, 347, 434, 518, 519, 592, 595, 610, 639, 646, 665, 704, 706, 711], "possibli": 142, "post": 706, "potenti": [347, 355, 356, 357, 358, 359, 360, 497, 687, 704, 711], "pow": 194, "power": [194, 268, 395, 396, 397, 513, 547, 569, 593, 688], "pp": [263, 381], "pr": [562, 651], "practic": 704, "pre": [491, 493, 520, 521, 522, 523, 524, 525, 526, 527, 528, 531], "preced": [491, 671], "precis": [65, 68, 105, 117, 194, 217, 298, 308, 337, 338, 339, 341, 355, 356, 357, 358, 359, 360, 380, 399, 415, 421, 422, 423, 481, 497, 601, 616, 620, 703, 707, 711], "precondit": 276, "precondition": 276, "pred": [142, 393, 497], "predict": [341, 381], "preemptiv": 497, "prefer": [92, 276, 435, 608, 646, 665], "prefix": 497, "prelu": 429, "prepend": [165, 298, 668], "prerequisit": 636, "presenc": 319, "present": [216, 293, 332, 398, 539, 646, 711], "preserv": [2, 90, 93, 192, 193, 429, 438, 481, 604, 608, 633, 657, 665, 711], "preserve_format": [134, 175, 207, 558, 582, 584, 586, 700, 711], "pretti": 620, "prevent": [1, 154, 155, 174, 175, 176, 263, 303, 319, 322, 365, 460, 487, 570, 649, 676, 678, 687, 704], "previou": [137, 196, 221, 274, 290, 379, 398, 444, 497, 520, 521, 522, 523, 524, 525, 526, 527, 646], "previous": [77, 644, 645, 689, 690, 694], "primarili": 324, "primit": 275, "princip": 562, "print": [293, 345, 389, 415, 440, 441, 450, 481, 518, 528, 529, 530, 531, 534, 544, 548, 620, 703, 710], "prior": [276, 474, 476, 529], "prioriti": 3, "privateuse1": 712, "prob_dist": 314, "probabilist": [562, 651], "probabl": [107, 229, 281, 314, 332, 336, 340, 347, 363, 365, 366, 367, 368, 372, 379, 381, 398, 434, 435, 444, 572], "problem": [173, 276, 363, 435, 612, 711], "procedur": 276, "proceed": [1, 381], "process": [203, 276, 340, 341, 361, 363, 387, 394, 419, 420, 424, 425, 426, 431, 432, 433, 435, 442, 460, 461, 468, 472, 474, 476, 477, 497, 586, 622, 704], "process_group": [468, 497], "prod": [370, 374, 480, 685, 687], "prod_": [356, 357, 359, 360, 373, 479], "prod_d": [374, 480], "produc": [2, 108, 128, 202, 221, 264, 301, 304, 305, 306, 347, 355, 356, 357, 358, 359, 360, 404, 405, 406, 407, 408, 409, 553, 572, 579, 588, 650, 687, 694, 704], "product": [65, 68, 69, 70, 105, 117, 123, 127, 146, 151, 154, 170, 173, 243, 265, 298, 305, 308, 316, 379, 380, 398, 399, 512, 560, 561, 570, 616, 667, 682, 691, 694], "profil": [137, 490, 491, 492, 493, 620, 704], "program": [143, 144, 616], "progress": 688, "proj": 398, "proj_siz": [398, 445], "project": [305, 398, 434, 518, 562, 704], "promot": [64, 110, 113, 122, 168, 194, 196, 197, 198, 199, 313, 366, 367, 368, 372, 571, 591, 592, 598, 613, 647, 657, 711], "promptli": 276, "propag": [65, 68, 69, 70, 74, 75, 76, 77, 105, 197, 198, 319, 505, 506], "proper": [164, 611], "properli": [305, 429, 430, 438, 439, 497, 703, 711], "properti": [94, 336, 462, 498, 499, 500, 501, 539, 711, 712], "proport": [395, 396, 397, 434, 476], "proportion": 481, "protocol": [94, 202, 205, 604], "prototyp": [142, 476, 711, 712], "proven": [365, 497], "provid": [68, 116, 121, 124, 150, 173, 221, 229, 230, 263, 276, 308, 358, 359, 360, 363, 379, 380, 388, 393, 398, 399, 424, 425, 426, 434, 435, 444, 446, 457, 472, 474, 476, 497, 505, 506, 520, 540, 548, 562, 598, 608, 634, 635, 636, 637, 638, 646, 676, 678, 694, 703, 710, 711, 712], "prune": [520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 707], "pruned_tensor": [520, 521, 522, 523, 524, 525, 526, 527], "pruning_method": 529, "pruning_typ": [525, 529], "pseudo": 2, "pseudorandom": [107, 314, 554, 562, 565, 581, 583, 585, 587, 651], "pt": [203, 275, 604], "pt2_compliant_tag": 712, "pth": 703, "pti": 703, "publish": 276, "purpos": [298, 347, 379, 490, 491, 492, 493, 620], "push": 694, "put": [275, 382, 704], "put_": 687, "py": [497, 703], "pycapsul": 202, "pyplot": 305, "python": [1, 2, 3, 4, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 214, 221, 224, 227, 228, 229, 230, 231, 232, 233, 237, 241, 242, 243, 251, 253, 255, 256, 257, 258, 259, 260, 261, 262, 265, 266, 267, 268, 269, 270, 273, 274, 275, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 429, 430, 431, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 497, 505, 506, 512, 513, 514, 518, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 554, 556, 557, 558, 561, 563, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 583, 585, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 603, 604, 608, 611, 612, 613, 614, 617, 620, 623, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 649, 650, 652, 653, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 703, 711], "pytorch": [77, 94, 122, 127, 128, 137, 138, 142, 173, 196, 202, 212, 252, 253, 274, 290, 293, 294, 305, 340, 341, 347, 379, 393, 424, 425, 426, 472, 497, 505, 506, 539, 547, 548, 550, 553, 572, 604, 612, 613, 614, 622, 646, 650, 674, 687, 694, 706, 707, 711, 712], "pytre": 142, "q": [211, 265, 304, 321, 393, 434, 512, 560, 562, 572, 573, 651], "qint32": [574, 575], "qint8": [574, 575], "qq": 512, "qquad": 512, "qr": [211, 512, 560], "quad": [340, 341, 363, 394, 419, 435, 478, 585], "quadrant": 98, "quadrat": 460, "quant": [187, 188], "quant_max": [187, 188], "quant_min": [187, 188], "quantifi": 478, "quantil": [304, 321], "quantiti": [393, 523, 524, 526, 527, 529, 532, 533, 534, 535], "quantiz": [158, 187, 188, 574, 575, 576, 577, 578, 687, 711], "quantization_schem": [574, 575, 576, 577, 578], "quantize_per_tensor": [576, 577, 578], "quasi": 579, "queri": [1, 3, 434, 517], "question": [550, 704], "queu": 3, "queue": 3, "quickli": 704, "quint8": [574, 575, 576, 577, 578], "quit": [103, 505, 506], "qw_i": 434, "qx": [576, 577, 578], "r": [125, 136, 146, 173, 208, 211, 221, 276, 370, 371, 380, 440, 441, 460, 512, 572, 694, 703, 711], "r1": 468, "r2": 468, "r_": [146, 667], "r_t": 379, "radian": [77, 98, 157, 580], "rais": [2, 76, 118, 127, 137, 194, 199, 275, 296, 490, 518, 519, 524, 526, 529, 539, 610, 613, 636, 687], "ram": 275, "rand": [72, 78, 150, 277, 278, 280, 340, 393, 472, 473, 474, 475, 476, 497, 518, 551, 565, 576, 577, 578, 582, 703, 712], "rand_lik": 712, "randint": [108, 150, 155, 194, 347, 478, 505, 506, 712], "randint_lik": 712, "randn": [62, 63, 64, 65, 66, 67, 68, 69, 74, 75, 78, 88, 89, 90, 92, 95, 96, 97, 98, 99, 105, 117, 124, 126, 127, 128, 129, 130, 132, 145, 146, 147, 148, 149, 151, 152, 153, 154, 160, 161, 162, 163, 167, 173, 187, 188, 195, 203, 237, 241, 243, 279, 283, 284, 291, 293, 294, 295, 297, 298, 301, 303, 304, 306, 308, 310, 311, 312, 313, 316, 326, 329, 330, 331, 333, 334, 335, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 426, 427, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 448, 449, 455, 456, 458, 459, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 477, 479, 480, 484, 485, 486, 496, 556, 563, 568, 569, 570, 572, 573, 586, 590, 591, 603, 627, 629, 633, 640, 641, 643, 649, 650, 660, 663, 664, 667, 671, 674, 675, 677, 680, 682, 687, 692, 693, 694, 697, 711, 712], "randn_lik": 712, "random": [2, 107, 108, 220, 242, 276, 296, 336, 347, 355, 356, 357, 358, 359, 360, 372, 379, 398, 424, 425, 426, 447, 487, 513, 520, 526, 527, 534, 535, 554, 562, 579, 581, 582, 583, 584, 585, 586, 587, 609, 621, 651, 694], "random_": [341, 363, 435, 712], "random_devic": 2, "random_unstructur": [531, 536], "randomli": [336, 365, 366, 367, 368, 372, 447, 526], "randperm": 712, "rang": [2, 63, 99, 107, 132, 173, 201, 228, 229, 230, 281, 296, 305, 321, 363, 373, 375, 376, 380, 386, 399, 418, 430, 435, 439, 444, 446, 462, 463, 464, 468, 504, 573, 685, 686, 703, 711, 712], "rank": [293, 420, 468, 497, 518, 562, 651, 704], "rankon": 518, "rate": [366, 367, 368, 372, 475, 497, 565], "rather": [127, 275, 324, 513, 616, 620], "ratio": [375, 376, 712], "ravel": 525, "raw": 205, "rb": 275, "rbrace": [675, 676, 677, 678], "rceil": [79, 126], "rcond": 564, "rdinat": 636, "re": [117, 202, 498, 499, 542, 585, 599], "reach": 276, "read": [142, 156, 202, 204, 205, 275], "readabl": 665, "readi": [106, 115, 225, 226, 497], "readlin": 275, "readthedoc": 173, "real": [65, 66, 67, 68, 69, 71, 77, 105, 129, 130, 139, 146, 256, 258, 259, 262, 263, 265, 274, 284, 290, 394, 437, 440, 441, 478, 512, 585, 646, 650, 691, 692, 693], "realiti": 704, "realiz": 616, "realloc": [137, 241], "rearrang": [348, 440, 441], "reason": [304, 340, 367, 518, 604, 704, 711], "recal": 341, "receiv": 497, "recent": [103, 251], "recip": [497, 520], "reciproc": [43, 44, 603], "recommend": [143, 144, 253, 276, 332, 364, 497, 579, 683, 706], "recompil": 137, "recomput": [481, 550], "recompute_scale_factor": 481, "reconstruct": [293, 340, 341], "record": [1, 3, 79, 106, 115, 174, 175, 176, 186, 205, 206, 207, 225, 226, 264, 274, 290, 364, 557, 558, 581, 582, 583, 584, 585, 586, 587, 588, 634, 635, 636, 637, 638, 665, 699, 700, 704, 712], "record_ev": [1, 3], "record_funct": 704, "recordstream": 704, "recov": [295, 497, 539, 646], "rectangular": [295, 646], "rectifi": [447, 448], "recurr": [347, 364, 379, 380, 398, 444, 516, 542], "recurs": [165, 505, 506, 703], "redirect": 712, "reduc": [65, 72, 74, 75, 76, 78, 88, 89, 137, 240, 291, 301, 303, 304, 306, 309, 319, 320, 321, 322, 337, 338, 339, 340, 341, 342, 343, 344, 361, 363, 371, 387, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 468, 477, 497, 513, 551, 570, 572, 573, 607, 644, 645, 649, 650, 672, 687, 689, 690, 704], "reduct": [137, 281, 321, 340, 341, 347, 361, 363, 371, 381, 387, 388, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 478, 497, 573], "redund": 646, "reentrant": 497, "refer": [87, 92, 119, 176, 205, 215, 217, 247, 254, 276, 314, 347, 381, 478, 492, 493, 497, 562, 579, 586, 615, 616, 651, 687, 703, 704, 707, 711, 712], "referenc": 674, "reflect": [204, 205, 263, 355, 356, 357, 404, 405, 406, 450, 451, 452, 548, 646], "reflectionpad1d": 687, "reflectionpad2d": 687, "reflectionpad3d": 687, "reflector": [211, 512, 560], "regard": [358, 359, 360, 370, 371], "regardless": [144, 490, 683], "region": [137, 337, 338, 339, 375, 376, 386, 388, 421, 422, 423], "regist": [137, 275, 428, 429, 430, 438, 439, 457, 488, 489, 490, 491, 492, 493, 494, 495, 497, 499, 512, 513, 515, 516, 518], "register_buff": [489, 498], "register_forward_hook": 490, "register_forward_pre_hook": [364, 491], "register_full_backward_hook": 492, "register_full_backward_pre_hook": 493, "register_modul": 494, "register_module_full_backward_hook": 488, "register_packag": 275, "register_paramet": 495, "register_parametr": [512, 513, 515, 516, 547, 707], "registr": [489, 494, 495, 497, 515, 518, 706], "regress": 340, "regular": [347, 365, 366, 367, 368, 372, 413, 427, 428, 429, 430, 438, 439, 487, 500, 501, 548, 712], "reimplement": [513, 547], "reinforc": 458, "rel": [73, 90, 150, 255, 477, 478, 651, 704], "relat": [221, 374, 460, 480, 497, 562], "relationship": [134, 221, 478], "relax": 518, "releas": [66, 127, 128, 151, 212, 263, 293, 294, 367, 553, 572, 588, 604, 646, 650, 674, 703], "relev": [400, 712], "reli": [173, 364, 704], "relu": [428, 444, 446, 457, 465, 472, 474, 476, 487, 694], "relu1": [457, 487], "relu2": [457, 487], "remain": [311, 370, 371, 487, 505, 506, 520, 521, 522, 523, 524, 525, 526, 527, 536, 573, 595], "remaind": [199, 221], "remap": [2, 275, 296], "remot": 497, "remov": [76, 127, 128, 212, 263, 293, 294, 298, 349, 350, 351, 488, 489, 490, 491, 492, 493, 494, 495, 497, 513, 519, 520, 521, 522, 523, 524, 525, 526, 527, 532, 533, 534, 535, 537, 538, 548, 550, 553, 572, 588, 610, 642, 650, 674, 681, 683, 707], "removablehandl": [488, 489, 490, 491, 492, 493, 494, 495], "remove_parametr": 550, "renorm": [370, 371], "reorder": 704, "reparamater": 548, "reparameter": [514, 520, 521, 522, 523, 524, 525, 526, 527, 536, 537, 538, 550], "reparametr": [520, 521, 522, 523, 524, 525, 526, 527, 530, 550], "repeat": [150, 173, 293, 424, 425, 426, 562, 594, 650, 651, 668], "repeat_interleav": 687, "repetit": [594, 668], "replac": [128, 173, 293, 294, 314, 318, 460, 471, 487, 514, 528, 529, 530, 532, 533, 534, 535, 548, 550, 572, 646, 650, 674], "replic": [221, 355, 356, 357, 364, 374, 404, 405, 406, 453, 454, 455, 480], "replica": [364, 497], "replicationpad1d": 687, "replicationpad2d": 687, "replicationpad3d": 687, "repo": 712, "repr": 620, "repres": [146, 150, 173, 221, 228, 255, 256, 259, 262, 293, 332, 347, 428, 434, 476, 478, 480, 497, 511, 515, 520, 523, 524, 525, 526, 527, 529, 532, 533, 534, 535, 539, 549, 560, 562, 573, 616, 634, 635, 637, 638, 646, 650, 683, 684, 692, 693, 711, 712], "represent": [194, 211, 318, 434, 560], "reproduc": 687, "request": [68, 93, 94, 276, 298, 308], "requir": [1, 2, 3, 94, 103, 137, 173, 192, 193, 208, 263, 274, 276, 290, 293, 305, 363, 370, 473, 474, 475, 476, 478, 487, 497, 499, 505, 506, 512, 513, 516, 518, 520, 560, 612, 646, 667, 687, 694, 703, 704, 706, 711], "requires_grad": [79, 94, 103, 104, 106, 115, 174, 175, 176, 177, 186, 205, 206, 207, 225, 226, 264, 274, 290, 340, 341, 361, 363, 370, 381, 393, 394, 419, 420, 434, 435, 442, 476, 477, 497, 499, 500, 501, 546, 551, 557, 558, 581, 582, 583, 584, 585, 586, 587, 588, 634, 635, 636, 637, 638, 665, 687, 694, 699, 700, 712], "requires_grad_": [347, 665], "rerr": 276, "rescal": [340, 341, 363, 432, 433, 435, 462, 464, 518, 547], "reset": [379, 562, 613, 614], "reshap": [71, 135, 156, 171, 172, 190, 231, 265, 324, 349, 350, 374, 450, 451, 452, 453, 454, 480, 513, 547, 553, 639, 666, 667, 672, 695, 696], "resid": [275, 497], "residu": 276, "resiz": [204, 205, 481, 703], "resize_": [266, 687], "resnet50": 703, "resnet50_weight": 703, "resolut": [440, 441, 672], "resolv": [358, 359, 360, 374, 425], "resolve_conj": 143, "resp": 284, "respect": [3, 68, 69, 70, 99, 132, 150, 161, 163, 164, 221, 276, 308, 318, 340, 341, 347, 358, 359, 360, 364, 379, 381, 398, 429, 444, 474, 476, 477, 478, 479, 481, 520, 524, 526, 548, 550, 650, 667], "respons": [416, 497, 636], "rest": [205, 666], "restor": [2, 196, 274, 290, 550, 599, 620], "restrict": [142, 275, 298, 363], "restructuredtext": 701, "result": [65, 66, 67, 68, 69, 72, 74, 75, 76, 78, 91, 93, 105, 108, 119, 123, 128, 134, 136, 137, 142, 146, 148, 152, 153, 154, 155, 156, 168, 173, 194, 196, 199, 204, 205, 211, 229, 230, 243, 257, 265, 266, 270, 283, 284, 291, 301, 303, 304, 305, 306, 308, 309, 319, 322, 337, 338, 339, 364, 366, 367, 368, 372, 374, 379, 393, 398, 444, 480, 512, 548, 551, 552, 553, 554, 560, 562, 569, 570, 573, 592, 598, 613, 629, 636, 644, 645, 646, 649, 650, 651, 661, 665, 666, 671, 672, 674, 675, 677, 687, 689, 690, 694, 711], "retain": [72, 74, 75, 78, 88, 89, 94, 266, 291, 301, 303, 304, 306, 309, 319, 320, 321, 322, 348, 553, 570, 573, 604, 644, 645, 649, 675, 676, 677, 678, 689, 690], "retain_graph": 694, "rethink": 363, "retriev": [2, 370, 374, 480, 540], "return": [1, 2, 3, 63, 71, 72, 74, 75, 76, 77, 78, 79, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 115, 116, 118, 121, 123, 125, 126, 127, 128, 130, 131, 132, 134, 136, 137, 138, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 167, 173, 174, 175, 176, 177, 178, 183, 186, 187, 188, 190, 191, 192, 193, 194, 195, 199, 202, 203, 204, 205, 206, 207, 210, 211, 213, 215, 216, 217, 218, 219, 220, 224, 225, 226, 228, 229, 230, 233, 237, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 266, 269, 270, 274, 275, 276, 277, 278, 279, 280, 283, 284, 290, 291, 292, 293, 294, 295, 296, 297, 298, 301, 302, 303, 304, 305, 306, 307, 309, 314, 319, 320, 322, 323, 324, 325, 326, 328, 332, 333, 334, 335, 340, 341, 361, 362, 363, 364, 375, 376, 387, 393, 394, 418, 419, 420, 421, 422, 423, 428, 429, 430, 431, 432, 433, 434, 435, 438, 439, 442, 444, 457, 460, 461, 462, 463, 464, 476, 477, 478, 487, 488, 489, 490, 491, 492, 493, 494, 495, 497, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 533, 534, 535, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 550, 551, 552, 553, 554, 556, 557, 558, 562, 563, 565, 568, 569, 570, 571, 572, 574, 575, 576, 577, 578, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 593, 594, 595, 596, 597, 598, 601, 603, 608, 609, 610, 611, 617, 625, 626, 627, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 645, 646, 649, 650, 651, 660, 661, 662, 663, 664, 665, 667, 669, 670, 671, 674, 675, 676, 677, 678, 680, 681, 682, 683, 684, 685, 686, 688, 690, 692, 693, 694, 697, 699, 700, 711, 712], "return_complex": [263, 646], "return_count": [683, 684], "return_indic": [333, 334, 335, 375, 376, 421, 422, 423, 424, 425, 426], "return_invers": [683, 684], "return_typ": [76, 152, 153, 230, 266, 301, 304, 306, 309, 320, 633, 669, 674], "revers": [191, 398, 441, 497, 520, 521, 522, 523, 524, 525, 526, 527, 536, 674, 688], "revert": 465, "rfloor": [195, 200, 332, 337, 338, 339, 355, 356, 357, 374, 395, 396, 397, 421, 422, 423, 480, 481, 482, 483, 588, 646], "rgb": [391, 392], "rh": 294, "riba": [477, 478], "riemann": 672, "right": [79, 103, 106, 113, 115, 116, 121, 126, 130, 167, 173, 192, 195, 196, 200, 221, 225, 226, 230, 233, 263, 264, 275, 281, 282, 314, 332, 337, 338, 339, 340, 341, 355, 356, 357, 374, 381, 394, 395, 396, 397, 416, 417, 418, 419, 421, 422, 423, 431, 432, 433, 437, 438, 477, 480, 481, 482, 483, 504, 518, 543, 588, 608, 646, 667, 672, 674, 688], "right_invers": [515, 518], "rightarrow": 221, "rightmost": [118, 229, 230], "risk": [515, 518], "rm": [443, 477, 478, 496], "rms_norm": [443, 496], "rng": 609, "rnn": [379, 380, 398, 399, 445, 446, 499, 516, 539, 540, 541, 542, 543, 544, 545], "rnn_cell": 516, "robust": 276, "rocm": [65, 68, 105, 117, 298, 308, 355, 356, 357, 358, 359, 360, 380, 399, 415], "root": [443, 496, 603, 640, 703, 704], "ross": 460, "rotat": [600, 650], "roughli": 393, "round": [45, 46, 79, 146, 148, 168, 199, 481, 572, 573, 592, 629], "rounding_mod": [168, 169, 196, 199, 592, 679], "routin": [90, 276, 633, 650], "row": [72, 78, 91, 125, 146, 150, 156, 186, 192, 193, 230, 266, 291, 293, 301, 303, 304, 306, 309, 314, 320, 321, 322, 512, 552, 570, 573, 593, 634, 635, 637, 638, 649, 669, 672, 676, 678, 688, 694, 696], "row_indic": [634, 637], "rowmajor": 497, "rpc": 497, "rref": 497, "rtol": [73, 255], "rule": [121, 122, 156, 342, 343, 344, 390, 391, 392, 468, 520, 521, 522, 523, 524, 525, 526, 527, 608, 672, 704, 711], "rummag": 694, "run": [103, 137, 275, 276, 304, 342, 343, 344, 364, 390, 391, 392, 401, 402, 403, 410, 411, 412, 457, 468, 481, 487, 490, 505, 506, 507, 508, 509, 510, 616, 619, 676, 678, 687, 694, 703, 704, 710, 712], "running_mean": [342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468, 498], "running_var": [342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468], "runtim": [92, 171, 173, 231, 500, 501, 568, 687, 695], "runtimeerror": [2, 76, 103, 118, 199, 251, 296, 314, 610, 687, 711], "rvert": [73, 255], "rvert_p": 477, "s0_sqrt": 518, "s1064827500366124": 276, "s1064827500370883": 276, "s1_cuda": [1, 3], "s2": 1, "s2_cuda": [1, 3], "s_": [305, 330, 331, 373, 479], "s_0": 305, "s_cuda": [1, 3], "s_min": 347, "s_n": 347, "safe": [2, 497, 704], "same": [65, 68, 72, 74, 75, 76, 78, 92, 93, 94, 105, 107, 108, 117, 119, 121, 124, 129, 130, 131, 137, 139, 142, 151, 156, 161, 163, 164, 170, 173, 175, 176, 179, 199, 204, 205, 207, 208, 211, 221, 229, 230, 237, 241, 257, 263, 265, 266, 291, 295, 297, 298, 301, 303, 304, 305, 306, 309, 319, 322, 323, 324, 330, 331, 334, 335, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 372, 374, 377, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 400, 410, 411, 412, 414, 415, 416, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 431, 432, 433, 434, 436, 437, 442, 443, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 480, 481, 484, 485, 486, 492, 493, 496, 497, 505, 506, 512, 518, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 539, 543, 548, 553, 554, 558, 560, 565, 566, 569, 570, 582, 584, 586, 590, 592, 594, 595, 599, 601, 608, 611, 612, 616, 623, 634, 635, 637, 638, 643, 644, 645, 649, 650, 661, 672, 683, 684, 685, 686, 687, 689, 690, 691, 694, 700, 704, 711], "sampl": [2, 107, 150, 221, 263, 293, 314, 336, 340, 341, 345, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 372, 381, 387, 390, 391, 392, 393, 394, 413, 415, 419, 420, 431, 432, 433, 435, 442, 447, 460, 461, 468, 477, 513, 554, 562, 565, 579, 581, 583, 585, 586, 587, 644, 645, 646, 689, 690, 694], "sane": 620, "satisfi": [73, 121, 199, 332, 347, 374, 529, 546, 592, 608, 646, 704, 711], "satur": 372, "save": [275, 497, 703, 704], "scalar": [66, 67, 93, 94, 110, 113, 121, 146, 150, 168, 173, 188, 199, 206, 221, 228, 243, 257, 269, 270, 298, 305, 321, 332, 340, 341, 347, 361, 363, 364, 381, 387, 388, 393, 394, 400, 420, 431, 432, 433, 435, 442, 460, 461, 477, 478, 552, 557, 558, 569, 571, 573, 591, 592, 608, 635, 636, 637, 638, 665, 683, 684, 697, 699, 700, 711], "scale": [64, 68, 69, 70, 105, 187, 188, 290, 336, 365, 370, 371, 372, 388, 400, 456, 481, 482, 483, 574, 575, 576, 577, 578, 647, 694, 703], "scale_factor": [481, 482, 483], "scale_grad_by_freq": [370, 371], "scaled_dot_product_attent": 434, "scaler": 703, "scatter": [364, 687, 704], "scatter_": 605, "scatter_add_": [606, 687], "scatter_reduc": 687, "scatter_reduce_": 607, "scenario": 341, "schedul": 704, "scheme": 712, "sci": 276, "sci_mod": 620, "scientif": 620, "scipi": [125, 566], "scope": [142, 205, 529], "score": [520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533], "scrambl": 579, "script": 703, "search": [121, 385, 497, 579, 608], "second": [65, 68, 70, 73, 88, 89, 90, 98, 105, 109, 110, 112, 113, 114, 117, 151, 161, 163, 164, 170, 178, 197, 198, 209, 210, 221, 224, 232, 233, 243, 255, 267, 269, 275, 281, 282, 292, 298, 302, 304, 305, 307, 308, 320, 325, 328, 332, 338, 339, 345, 356, 357, 359, 360, 378, 379, 393, 396, 397, 398, 416, 420, 422, 423, 444, 457, 478, 487, 529, 600, 636, 671, 676, 678, 688, 691, 694, 704], "secondli": 340, "section": [173, 221, 364, 379, 398, 426, 444, 542, 666, 703], "see": [3, 72, 74, 75, 78, 79, 88, 89, 90, 93, 103, 104, 106, 108, 115, 117, 120, 134, 137, 148, 168, 171, 173, 174, 176, 177, 186, 190, 203, 206, 211, 220, 221, 225, 226, 230, 231, 238, 239, 240, 264, 266, 274, 276, 282, 284, 290, 291, 293, 301, 303, 304, 305, 306, 308, 309, 312, 319, 321, 322, 332, 340, 341, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 370, 371, 373, 379, 381, 387, 388, 393, 394, 398, 419, 420, 424, 425, 426, 427, 431, 432, 433, 435, 440, 441, 442, 444, 456, 458, 460, 461, 477, 478, 481, 497, 499, 512, 513, 514, 518, 524, 533, 542, 547, 550, 551, 552, 553, 557, 560, 570, 571, 581, 583, 585, 587, 588, 592, 595, 598, 604, 613, 616, 629, 634, 635, 636, 637, 638, 644, 645, 646, 649, 660, 662, 665, 671, 672, 676, 678, 683, 687, 689, 690, 695, 697, 699, 701, 706, 707, 711, 712], "seealso": 0, "seed": [2, 242, 296, 562, 579, 651], "seek": 275, "seem": [450, 481], "seen": [124, 137, 150, 305, 358, 359, 360, 460], "segment": [205, 460], "select": [127, 276, 305, 347, 355, 356, 357, 358, 359, 360, 534, 535, 611, 662, 697], "select_copi": 610, "self": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 237, 336, 372, 427, 428, 429, 430, 434, 438, 439, 456, 458, 468, 474, 476, 487, 516, 518, 524, 526, 539, 548, 569, 590], "selu": [336, 372], "semant": [3, 88, 89, 90, 119, 341, 505, 506, 684, 694], "semi": [361, 387], "send": [487, 712], "sens": [529, 683, 684, 704], "sensit": [388, 460], "sentence_length": 400, "separ": [173, 382, 390, 391, 392, 436, 554, 585, 704], "seq": [124, 136, 305, 379, 398, 434, 444, 472, 474, 476, 542, 681], "seq_len": [379, 398, 444], "seq_unpack": 542, "sequenc": [3, 94, 121, 123, 124, 127, 135, 158, 172, 174, 229, 230, 232, 305, 332, 342, 347, 355, 364, 379, 398, 434, 444, 457, 515, 518, 525, 539, 540, 541, 542, 543, 544, 545, 554, 557, 579, 581, 585, 608, 643, 646, 685, 694, 696, 699, 704], "sequenti": [373, 479, 505, 506, 515, 529, 694], "seri": [347, 390, 703], "serial": [275, 487, 604, 704, 710], "session": 481, "set": [2, 79, 92, 104, 116, 121, 132, 136, 137, 144, 174, 175, 176, 203, 230, 246, 247, 274, 275, 276, 290, 293, 296, 332, 336, 340, 341, 342, 343, 344, 345, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 372, 379, 382, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 410, 411, 412, 413, 415, 419, 420, 424, 425, 426, 431, 432, 433, 435, 442, 443, 444, 460, 461, 468, 472, 474, 476, 477, 478, 496, 497, 500, 501, 513, 519, 548, 572, 579, 581, 585, 587, 588, 596, 597, 608, 609, 612, 613, 614, 615, 616, 618, 619, 620, 621, 622, 626, 634, 635, 636, 637, 638, 644, 645, 651, 665, 675, 676, 677, 678, 687, 689, 690], "set_default_devic": [79, 106, 115, 174, 176, 186, 203, 206, 225, 226, 264, 274, 290, 557, 581, 583, 585, 587, 588, 614, 634, 635, 636, 637, 638, 676, 678, 699, 711], "set_default_dtyp": [79, 106, 115, 174, 176, 186, 203, 206, 214, 225, 226, 264, 557, 581, 585, 588, 614, 699], "set_deterministic_debug_mod": [215, 687], "set_devic": [497, 612, 711], "set_float32_matmul_precis": 217, "set_grad_en": [177, 712], "set_stat": 2, "set_warn_alwai": 254, "setup": [497, 694, 703], "setvar": 703, "sever": [103, 104, 177, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 355, 356, 357, 358, 359, 360, 375, 376, 395, 396, 397, 416, 421, 422, 423, 424, 425, 426, 482, 483, 516, 518, 519, 551, 577, 578, 682, 687], "sgd": [370, 487, 497, 703], "sgn": [200, 625], "sh": 703, "shall": [515, 519], "shallow": [364, 477, 478], "shamelessli": 620, "shao": 276, "shape": [64, 66, 67, 76, 92, 98, 107, 108, 110, 113, 118, 120, 124, 125, 129, 130, 137, 142, 145, 163, 164, 165, 167, 168, 173, 174, 176, 178, 190, 196, 197, 198, 199, 206, 208, 210, 224, 229, 230, 233, 241, 243, 257, 263, 264, 269, 270, 292, 293, 297, 305, 310, 311, 313, 314, 325, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 431, 432, 433, 435, 436, 437, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 500, 501, 512, 515, 518, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 554, 557, 560, 569, 573, 577, 578, 581, 583, 584, 585, 592, 594, 595, 599, 608, 611, 635, 636, 642, 646, 647, 650, 661, 668, 672, 682, 683, 684, 685, 694, 697, 699, 712], "shape_pad": 137, "shard": [497, 704], "share": [93, 94, 137, 202, 203, 204, 205, 237, 323, 324, 364, 445, 516, 554, 590, 604, 612, 642, 665, 671, 686], "shazeer": [472, 474, 476], "shi": [440, 441], "shift": [110, 113, 336, 342, 343, 344, 372, 468, 599], "short": [173, 263, 347, 398, 399, 620, 646, 711], "shorter": 263, "shortest": 540, "shorthand": 264, "shorttensor": 711, "should": [1, 3, 65, 68, 69, 79, 105, 106, 107, 108, 115, 128, 150, 164, 174, 175, 176, 186, 202, 205, 206, 207, 225, 226, 229, 230, 263, 264, 274, 275, 281, 290, 293, 294, 295, 332, 340, 341, 345, 361, 363, 364, 366, 367, 368, 372, 393, 398, 420, 428, 435, 436, 451, 456, 477, 481, 487, 489, 490, 491, 494, 495, 497, 498, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 534, 535, 539, 540, 541, 544, 546, 557, 558, 572, 574, 581, 582, 583, 584, 585, 586, 587, 588, 595, 611, 634, 635, 636, 637, 638, 650, 665, 674, 694, 699, 700, 704], "show": [137, 202, 305, 487], "showcas": 424, "shown": [400, 518, 620], "shrinkag": [383, 466], "shuffl": 348, "siam": 276, "side": [130, 167, 263, 337, 338, 339, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 374, 404, 405, 406, 407, 408, 409, 421, 422, 423, 450, 451, 453, 454, 455, 480, 484, 485, 486, 543, 577, 578, 608, 646, 674], "sigma": [341, 378, 379, 380, 398, 399, 458, 459, 513, 547, 644, 645, 689, 690], "sigma_i": 650, "sigma_j": 650, "sigmoid": [47, 48, 340, 341, 370, 379, 380, 398, 399, 458], "sign": [98, 145, 161, 199, 205, 284, 420, 592, 623, 626, 711], "signal": [263, 329, 330, 331, 333, 334, 335, 337, 338, 339, 355, 356, 357, 375, 376, 395, 396, 397, 416, 421, 422, 423, 482, 483, 646], "signal_2d": 416, "signal_4d": 416, "signatur": [142, 489, 490, 491, 494, 495, 518, 539, 553, 646], "signbit": 145, "signific": 616, "significand": 711, "significantli": [497, 616], "silent": [241, 503, 504, 636], "sim": [107, 442, 565, 585], "similar": [91, 118, 123, 136, 137, 197, 198, 361, 362, 374, 387, 390, 391, 392, 477, 539, 553, 554, 566, 594, 601, 662, 668, 684], "similarli": [128, 476, 520, 521, 522, 523, 524, 525, 526, 527, 536, 675, 676, 677, 678], "simpl": [150, 342, 343, 344, 370, 401, 402, 403, 468, 694], "simpler": 694, "simplest": [337, 338, 339, 355, 356, 357, 421, 422, 423, 516], "simpli": [253, 336, 365, 520, 521, 522, 523, 524, 525, 526, 527, 616], "simplic": 518, "simplifi": [418, 513], "sin": [49, 50, 95, 137, 142, 226, 305, 566], "sinc": [127, 173, 191, 192, 193, 263, 293, 340, 370, 424, 425, 426, 481, 487, 490, 529, 548, 553, 646, 704, 711], "sine": [96, 627, 629], "singl": [74, 75, 106, 115, 119, 137, 142, 146, 150, 225, 226, 230, 251, 264, 281, 305, 330, 331, 334, 335, 338, 339, 341, 355, 356, 357, 359, 360, 363, 364, 375, 376, 382, 395, 396, 397, 400, 422, 423, 436, 440, 441, 443, 457, 468, 489, 491, 494, 495, 496, 497, 503, 504, 507, 509, 511, 548, 549, 569, 595, 616, 639, 644, 645, 683, 684, 687, 689, 690, 694, 704, 707, 711], "singleton": [400, 443, 496, 686], "singular": [276, 284, 293, 513, 518, 562, 650, 651], "sinh": [51, 52, 96], "situat": [137, 146, 518], "six": 357, "size": [69, 70, 72, 74, 75, 76, 78, 79, 91, 92, 94, 105, 106, 108, 115, 117, 118, 119, 120, 121, 124, 128, 131, 137, 150, 151, 154, 155, 161, 164, 171, 173, 174, 175, 176, 179, 203, 205, 206, 207, 208, 225, 226, 230, 231, 241, 243, 263, 266, 274, 276, 284, 290, 291, 293, 294, 298, 301, 303, 304, 305, 306, 309, 310, 311, 314, 316, 319, 322, 324, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 370, 371, 373, 374, 375, 376, 379, 381, 382, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 416, 419, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 435, 440, 441, 443, 444, 450, 451, 452, 453, 454, 455, 460, 468, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 497, 514, 529, 539, 540, 541, 542, 543, 545, 547, 550, 552, 554, 557, 558, 560, 561, 562, 563, 565, 570, 571, 572, 573, 574, 575, 576, 577, 578, 581, 582, 583, 584, 585, 586, 588, 594, 599, 608, 611, 634, 635, 636, 637, 638, 639, 642, 643, 644, 645, 646, 649, 650, 651, 665, 666, 667, 672, 674, 682, 683, 684, 685, 686, 689, 690, 692, 693, 694, 695, 699, 700, 711], "size_averag": [340, 341, 361, 363, 387, 393, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477], "sizeof": 203, "skeleton": 520, "skew": 512, "skip": [103, 104, 127, 173, 177, 205, 275, 337, 338, 339, 347, 364, 374, 434, 468, 478, 480, 487, 497, 530, 532, 534, 535, 548, 551, 579, 604, 612, 613, 614, 630, 687], "sleef": [148, 629], "slice": [74, 75, 342, 343, 344, 462, 464, 468, 549, 593, 610, 611, 630, 681], "slide": [263, 337, 338, 339, 374, 421, 422, 423, 480, 577, 578, 646], "slight": [612, 711], "slightli": [553, 562, 651, 704], "slogdet": 284, "slope": [414, 460], "slow": [503, 504, 546, 683], "slower": [90, 191, 192, 193, 512], "small": [79, 137, 279, 281, 332, 362, 437, 442, 457, 477, 481, 560, 650, 651], "smaller": [150, 398, 497, 571, 616, 639], "smallest": [126, 266, 276, 571, 669], "smooth": [363, 388, 460, 465], "smoothl1loss": 388, "sn": [513, 547], "snm": 513, "so": [134, 137, 161, 163, 202, 205, 253, 263, 276, 281, 293, 355, 356, 357, 358, 359, 360, 364, 371, 374, 381, 462, 464, 480, 487, 497, 552, 626, 642, 646, 650, 671, 683, 688, 704, 711, 712], "sobol": 579, "soboleng": 579, "soft": 466, "softmax": [332, 363, 393, 418, 463], "softplu": 427, "softshrinkag": 466, "softwar": 687, "solut": [130, 340, 497, 674], "solv": [211, 221, 276, 294, 674], "solve_triangular": 674, "some": [68, 103, 137, 173, 199, 263, 298, 305, 308, 336, 340, 341, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 387, 390, 391, 392, 393, 394, 419, 420, 431, 432, 433, 435, 442, 445, 460, 461, 477, 487, 497, 499, 500, 501, 512, 546, 572, 592, 616, 622, 650, 694, 704], "someth": 173, "sometim": [374, 480, 518, 704, 711], "sooner": 704, "sort": [90, 91, 173, 228, 312, 332, 540, 541, 552, 573, 608, 669, 683], "sorted_idx": 662, "sorted_indic": [539, 541, 542, 544], "sorted_sequ": 608, "sorted_sequence_1d": 608, "sorter": 608, "sound": 457, "sourc": [4, 74, 75, 87, 100, 101, 102, 103, 104, 116, 118, 119, 123, 125, 127, 137, 138, 173, 177, 202, 205, 208, 213, 215, 216, 217, 220, 238, 239, 240, 242, 247, 252, 253, 254, 275, 276, 296, 305, 310, 311, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 562, 579, 604, 609, 612, 613, 614, 615, 616, 620, 621, 622, 639, 646, 651, 654, 655, 656, 657, 658, 659, 667, 685, 687, 712], "space": [156, 221, 230, 274, 290, 332, 355, 356, 357, 358, 359, 360, 374, 393, 404, 405, 406, 407, 408, 409, 422, 423, 480, 672, 707], "spacial": 341, "span": [363, 650], "spars": [68, 208, 251, 276, 298, 308, 324, 370, 371, 462, 562, 610, 634, 635, 636, 637, 638, 651, 671, 687, 711], "sparse_bsc": 634, "sparse_bsr": 635, "sparse_coo": [324, 636, 711], "sparse_csc": 637, "sparse_csr": 638, "sparse_dim": 636, "sparse_grad": 208, "sparseadam": 370, "sparsebsc": 671, "sparsebsr": 671, "sparsecsc": 671, "sparsecsr": 671, "sparsetensor": 636, "spatial": [125, 343, 374, 400, 440, 441, 463, 480, 481, 482, 483], "spatio": [344, 468], "spawn": 497, "special": [137, 166, 180, 181, 182, 184, 185, 234, 235, 236, 275, 289, 317, 364, 476, 498, 499, 500, 501, 552, 567, 624, 628, 698, 704], "specif": [2, 93, 164, 230, 263, 304, 374, 400, 443, 490, 491, 496, 520, 611, 616, 703, 707], "specifi": [2, 92, 94, 108, 131, 137, 149, 150, 154, 155, 156, 160, 161, 163, 173, 176, 187, 208, 221, 229, 230, 263, 275, 276, 286, 303, 305, 311, 318, 319, 322, 338, 339, 340, 341, 347, 359, 361, 363, 364, 370, 371, 374, 381, 387, 388, 393, 394, 398, 419, 420, 425, 431, 432, 433, 434, 435, 442, 460, 461, 477, 478, 479, 480, 482, 483, 497, 504, 505, 506, 512, 513, 514, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 534, 535, 550, 553, 562, 570, 579, 595, 600, 601, 604, 620, 634, 635, 636, 637, 638, 642, 644, 645, 646, 649, 666, 668, 672, 682, 683, 684, 685, 686, 688, 689, 690, 694, 711], "spectral": [264, 513, 537, 547], "spectral_norm": [364, 537], "speed": [173, 257, 332, 434, 505, 506, 616, 650, 712], "speedup": [434, 476], "spend": 276, "split": [124, 131, 171, 231, 364, 378, 379, 398, 434, 444, 666, 695, 704], "split_siz": 639, "split_size_or_sect": 639, "splitwithsizesbackward": 704, "spot": [505, 506], "sqrt": [53, 54, 146, 233, 264, 305, 342, 343, 344, 345, 355, 356, 357, 358, 359, 360, 377, 379, 380, 382, 390, 391, 392, 395, 396, 397, 398, 399, 400, 413, 415, 443, 444, 446, 468, 496, 518, 576, 603, 644, 645], "squar": [150, 160, 162, 263, 284, 293, 330, 334, 338, 339, 356, 357, 359, 360, 375, 376, 388, 396, 397, 419, 422, 423, 426, 443, 460, 496, 512, 603, 640, 674, 688], "squeez": [72, 74, 75, 76, 78, 266, 291, 301, 303, 304, 306, 309, 319, 322, 570, 644, 645, 649, 689, 690], "src": [164, 472, 475, 476, 605, 606, 607, 611, 630, 661, 687], "src_key_padding_mask": 476, "src_mask": 476, "sse3": 617, "stabil": [291, 341, 342, 343, 344, 381, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 443, 465, 468, 477, 496, 513, 547, 576], "stabl": [90, 142, 173, 276, 341, 633], "stack": [124, 135, 172, 232, 305, 347, 379, 398, 399, 444, 473, 475, 543, 694, 696], "stai": [364, 505, 506], "standard": [336, 342, 343, 344, 382, 390, 391, 392, 393, 400, 468, 474, 476, 554, 562, 585, 644, 645], "star": [355, 356, 357], "start": [1, 77, 79, 190, 205, 270, 274, 290, 323, 324, 332, 337, 338, 339, 373, 421, 422, 423, 429, 431, 497, 520, 524, 526, 539, 588, 618, 630, 634, 635, 637, 638, 704, 706], "start_dim": [190, 373], "stat": [468, 497], "state": [2, 220, 276, 379, 380, 398, 399, 424, 444, 446, 476, 482, 487, 489, 490, 491, 492, 493, 494, 495, 497, 498, 499, 579, 612, 621], "state_dict": [487, 498, 532, 550, 703], "stateless": [548, 707], "statement": 142, "stathopoulo": 276, "stathopoulosetal2002": 276, "static": [497, 703, 704], "static_graph": 497, "statist": [281, 342, 343, 344, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 468], "statu": [1, 293], "std": [2, 187, 188, 197, 198, 199, 554, 566, 592, 645, 684], "stdin": 103, "step": [65, 79, 108, 132, 227, 274, 275, 276, 290, 293, 305, 375, 376, 398, 497, 539, 588, 616, 630, 703], "stft": [106, 115, 225, 226, 263, 264], "still": [394, 419, 498, 499, 500, 501, 604, 704], "stirl": 442, "stochast": [375, 376], "stop": [79, 276, 347, 539], "storag": [92, 164, 203, 237, 241, 252, 275, 297, 323, 324, 364, 445, 590, 604, 611, 630, 642, 665, 671, 711], "storage_offset": 92, "store": [65, 117, 211, 276, 281, 293, 342, 343, 344, 370, 457, 512, 528, 529, 530, 532, 533, 534, 535, 539, 616, 707], "str": [125, 137, 168, 173, 203, 217, 275, 276, 305, 321, 340, 341, 347, 355, 356, 357, 361, 363, 371, 377, 381, 387, 388, 393, 394, 404, 405, 406, 419, 420, 431, 432, 433, 435, 442, 446, 460, 461, 472, 474, 476, 477, 478, 479, 481, 497, 512, 513, 514, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 536, 537, 538, 539, 543, 547, 548, 550, 573, 604, 608, 615, 616, 646, 694], "straight": 340, "strategi": [173, 332, 505, 506], "stream": [1, 594, 704, 712], "strict": 548, "stricter": 314, "strictli": [121, 230], "stride": [79, 92, 106, 115, 174, 176, 186, 203, 206, 207, 225, 226, 264, 274, 290, 308, 337, 338, 339, 355, 356, 357, 358, 359, 360, 374, 395, 396, 397, 404, 405, 406, 407, 408, 409, 421, 422, 423, 424, 425, 426, 440, 480, 497, 557, 577, 578, 581, 583, 584, 585, 587, 588, 595, 671, 676, 678, 692, 699, 711], "string": [103, 173, 275, 355, 356, 357, 429, 438, 472, 474, 476, 529, 572, 604, 612, 614, 711], "strip": 497, "strongli": [366, 367, 368, 372, 646], "struct": 694, "structur": [137, 142, 202, 428, 525, 529, 562, 651, 694, 704, 710, 712], "style": [91, 168, 202, 450, 481, 552], "styliz": [390, 391, 392], "sub": [301, 304, 306, 440, 441, 472, 473, 475, 593, 648, 666, 683, 711], "subclass": [428, 498, 499, 520, 525, 546], "subhead": 708, "subintro": 709, "subject": [79, 497, 711, 712], "sublist": 173, "sublist1": 173, "sublist2": 173, "submit": [1, 3], "submodul": [364, 428, 429, 430, 457, 494, 703], "submodule_nam": 548, "subscript": 173, "subsequ": [137, 355, 356, 357, 358, 359, 360, 457], "subslist_out": 173, "subspac": [434, 562, 650, 651], "substitut": 711, "subtl": [390, 391, 392], "subtleti": 364, "subtli": 379, "subtract": [79, 205, 634, 635, 637, 638, 647], "succeed": 293, "success": [293, 525, 634, 635, 637, 638], "successfulli": 617, "suffici": [651, 711], "suggest": 361, "suitabl": [121, 264, 608], "sum": [150, 155, 156, 173, 243, 281, 282, 283, 291, 314, 322, 340, 341, 347, 360, 361, 363, 364, 371, 374, 381, 387, 388, 393, 394, 395, 396, 397, 419, 420, 431, 432, 433, 435, 442, 460, 461, 462, 464, 477, 478, 480, 497, 529, 534, 535, 553, 594, 616, 670, 672, 687], "sum_": [65, 263, 337, 338, 339, 355, 356, 357, 363, 395, 396, 397, 416, 431, 435, 437, 644, 645, 646, 667, 672, 689, 690, 691], "sum_i": [432, 433, 461], "sum_j": [291, 418, 462, 464], "summar": [620, 704], "summari": [620, 704], "summaris": 393, "summat": [173, 263, 283, 291], "super": [428, 429, 430, 438, 439, 440, 441, 487], "supervis": [361, 387], "support": [64, 65, 66, 68, 72, 74, 75, 78, 105, 106, 110, 113, 115, 117, 129, 130, 137, 142, 145, 151, 168, 170, 173, 196, 197, 198, 199, 201, 202, 204, 225, 226, 237, 263, 264, 265, 276, 294, 298, 302, 307, 308, 313, 355, 356, 357, 358, 359, 360, 367, 370, 371, 374, 394, 415, 433, 434, 468, 476, 478, 480, 497, 505, 506, 553, 558, 560, 572, 591, 592, 613, 616, 617, 647, 650, 674, 676, 678, 691, 692, 693, 700, 703, 707, 711, 712], "suppos": [263, 704], "sure": [202, 276, 349, 451, 452, 453, 497, 551, 669, 703], "surg": 275, "surject": 518, "svd": [284, 518, 562, 651], "svdval": 650, "swap": [293, 477, 478, 671], "swapax": 653, "swish": 458, "switch": [367, 503, 604, 687], "symbol": [4, 674, 691], "symbool": [659, 712], "symfloat": [654, 655, 712], "symint": [654, 655, 657, 658, 659, 712], "symmetr": [106, 115, 128, 129, 130, 225, 226, 264, 276, 512, 518], "symmetri": 646, "sync": [497, 703], "sync_bn_network": 468, "synchron": [1, 3, 91, 276, 468, 497, 552, 554, 594, 712], "syntax": 701, "system": [130, 221, 275, 294, 472, 474, 476, 497, 516, 518, 617, 674, 703], "t": [66, 67, 76, 91, 92, 93, 94, 128, 129, 130, 135, 142, 150, 171, 190, 202, 203, 204, 205, 208, 221, 231, 263, 265, 275, 276, 284, 297, 310, 311, 312, 321, 341, 345, 347, 355, 356, 357, 364, 370, 371, 379, 388, 390, 391, 392, 393, 398, 415, 444, 460, 462, 480, 481, 487, 490, 491, 497, 498, 499, 512, 518, 520, 521, 522, 523, 524, 525, 526, 527, 529, 540, 542, 543, 554, 562, 568, 572, 589, 612, 614, 615, 623, 646, 650, 656, 662, 665, 671, 674, 694, 695, 704, 711, 712], "t0": 221, "t1": [66, 67, 94, 170, 221, 497], "t2": [66, 67, 94, 170, 202, 221, 497], "t3": 202, "t_": [305, 376], "t_0": 305, "t_i": 305, "t_map": 203, "t_modul": [537, 538, 547, 550], "tabl": 370, "tag": 275, "take": [151, 161, 163, 164, 332, 341, 371, 375, 376, 379, 398, 422, 423, 424, 425, 426, 436, 444, 482, 483, 497, 551, 569, 651, 674, 694, 711], "take_along_axi": 662, "taken": [79, 197, 198, 347, 363, 435, 443, 496, 620, 704], "talk": 706, "tamper": 275, "tan": [55, 56, 97], "tangent": [99, 469, 663, 664], "tanh": [99, 377, 379, 380, 398, 399, 427, 444, 446, 470], "taper": 646, "target": [122, 329, 330, 331, 332, 333, 334, 335, 340, 341, 347, 361, 363, 375, 376, 381, 387, 388, 393, 394, 419, 420, 424, 425, 426, 431, 432, 433, 435, 442, 460, 461, 481, 497, 687, 703], "target_length": 347, "target_n": 347, "task": [3, 390, 391, 392], "tau": [211, 559, 560], "taylor": 221, "tba": [701, 705, 708, 709, 714, 715], "tbai": 713, "technic": 704, "techniqu": [365, 520, 672, 707], "tell": 275, "templat": 137, "tempor": [142, 342, 344, 347, 468, 481], "temporari": 499, "temporarili": 612, "tend": 687, "tensor": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 246, 248, 251, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 332, 336, 337, 340, 341, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 379, 380, 381, 387, 393, 394, 398, 399, 418, 419, 420, 421, 424, 425, 426, 431, 432, 433, 434, 435, 436, 438, 439, 440, 441, 444, 446, 450, 451, 452, 453, 454, 455, 461, 462, 463, 464, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 497, 498, 499, 500, 502, 503, 504, 505, 506, 508, 510, 511, 512, 513, 514, 515, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 610, 611, 612, 613, 614, 617, 620, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 660, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 703, 704, 707], "tensor1": [66, 67, 298, 598], "tensor2": [66, 67, 298, 598], "tensor_1d": 710, "tensor_a": [123, 136], "tensor_b": 123, "tensor_nam": [515, 517, 518, 519], "tensor_split": [131, 171, 231, 695], "tensordot": 243, "tensorfloat32": [65, 68, 105, 117, 298, 308, 355, 356, 357, 358, 359, 360, 415, 616], "term": [127, 199, 332, 340, 381, 388, 398, 399, 433, 442, 460, 512, 520, 521, 522, 523, 524, 525, 526, 527, 592], "terminologi": [342, 343, 344, 468], "test": [72, 78, 137, 252, 253, 257, 258, 260, 261, 424, 450, 481, 482, 613, 614, 626, 702, 704, 708], "test_el": 257, "text": [60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 77, 79, 95, 96, 97, 98, 99, 105, 106, 107, 110, 113, 115, 117, 126, 129, 130, 132, 144, 145, 147, 148, 150, 168, 187, 188, 195, 196, 200, 201, 210, 224, 225, 226, 227, 233, 255, 263, 265, 268, 269, 270, 273, 274, 283, 290, 291, 292, 293, 313, 314, 325, 326, 329, 330, 331, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 366, 367, 368, 369, 370, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 431, 432, 433, 434, 435, 436, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 478, 479, 480, 481, 482, 483, 484, 485, 486, 496, 504, 512, 562, 565, 566, 569, 572, 585, 588, 591, 603, 623, 625, 627, 629, 640, 646, 647, 650, 651, 663, 664, 697], "texttt": [73, 255, 332], "tgt": [472, 473, 474], "th": [107, 127, 160, 165, 241, 263, 266, 293, 366, 367, 368, 372, 379, 387, 398, 444, 573, 646, 685, 711], "than": [108, 119, 126, 127, 131, 132, 161, 162, 191, 192, 193, 195, 199, 205, 210, 224, 228, 241, 251, 263, 265, 266, 269, 275, 279, 292, 295, 301, 304, 306, 309, 314, 324, 340, 341, 355, 356, 357, 364, 370, 371, 388, 398, 420, 434, 442, 451, 460, 466, 476, 477, 478, 487, 497, 505, 506, 512, 513, 515, 516, 542, 547, 553, 570, 571, 592, 593, 616, 620, 634, 635, 637, 638, 668, 676, 678, 687, 704, 707, 711], "thei": [65, 68, 69, 76, 103, 104, 105, 137, 177, 202, 255, 256, 263, 266, 275, 297, 301, 304, 306, 309, 314, 337, 338, 339, 358, 359, 360, 374, 413, 421, 422, 423, 457, 480, 487, 497, 498, 499, 512, 516, 539, 542, 551, 612, 646, 650, 687, 688, 704, 707, 711, 712], "them": [119, 158, 161, 173, 266, 275, 303, 322, 348, 370, 428, 462, 464, 525, 540, 543, 649, 683, 704], "themselv": 669, "theophil": 688, "theorem": 221, "theori": 704, "therefor": [106, 115, 202, 205, 225, 226, 370, 371, 480, 548, 704], "thi": [0, 1, 2, 3, 63, 65, 68, 72, 73, 78, 88, 89, 90, 91, 92, 99, 103, 104, 105, 108, 110, 113, 117, 118, 121, 125, 127, 128, 131, 132, 134, 137, 143, 144, 146, 151, 154, 155, 156, 161, 163, 164, 168, 171, 172, 173, 177, 190, 191, 192, 193, 194, 197, 198, 199, 202, 205, 209, 211, 212, 221, 225, 231, 232, 253, 263, 264, 265, 266, 267, 268, 275, 276, 279, 281, 284, 293, 294, 298, 301, 303, 304, 305, 306, 308, 309, 310, 316, 319, 320, 321, 322, 324, 332, 336, 340, 341, 342, 343, 344, 347, 348, 349, 355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 370, 371, 372, 374, 375, 376, 379, 380, 382, 387, 388, 390, 391, 392, 393, 395, 396, 397, 398, 399, 400, 401, 402, 403, 410, 411, 412, 413, 415, 421, 422, 423, 424, 425, 426, 428, 431, 434, 435, 440, 443, 444, 451, 452, 453, 457, 460, 462, 465, 468, 474, 475, 476, 477, 480, 481, 482, 483, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 499, 502, 505, 506, 512, 513, 514, 515, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 539, 540, 541, 542, 543, 546, 547, 548, 550, 551, 553, 554, 558, 560, 561, 562, 566, 570, 572, 579, 583, 585, 588, 592, 594, 601, 608, 610, 611, 612, 614, 615, 616, 620, 621, 622, 623, 630, 634, 635, 636, 637, 638, 644, 645, 646, 649, 650, 651, 652, 653, 657, 660, 662, 666, 668, 672, 674, 682, 683, 684, 686, 687, 689, 690, 691, 692, 693, 694, 695, 696, 700, 702, 703, 704, 706, 710, 711, 712], "thin": [512, 572], "thing": [305, 340], "third": [172, 173, 293, 332, 339, 357, 360, 397, 423, 703], "those": [161, 163, 275, 332, 340, 341, 361, 363, 387, 394, 419, 420, 431, 432, 433, 435, 442, 460, 461, 477, 481, 492, 493, 650, 672, 694, 704], "though": [298, 553, 704], "thread": [1, 3, 103, 104, 177, 218, 219, 364, 551, 618, 619, 704, 712], "three": [102, 171, 173, 221, 230, 295, 339, 357, 360, 397, 400, 423, 512, 553, 616], "threshold": [388, 460, 465, 620], "through": [284, 435, 487, 497, 505, 506, 518, 572, 694, 712], "throughout": 539, "throughput": 704, "throw": [251, 293, 500, 501, 542, 553, 568, 687], "thrown": [92, 94, 171, 231, 503, 695], "thu": [173, 298, 367, 481, 497, 636], "ti": [548, 601, 704], "tie_weight": 548, "time": [1, 2, 64, 65, 66, 67, 68, 69, 70, 73, 91, 105, 117, 125, 127, 137, 143, 150, 154, 165, 187, 188, 191, 192, 193, 201, 205, 255, 263, 265, 270, 275, 276, 298, 308, 313, 314, 316, 326, 334, 335, 337, 338, 339, 341, 342, 343, 344, 347, 355, 356, 357, 358, 359, 360, 364, 371, 374, 375, 376, 379, 390, 391, 392, 398, 400, 414, 421, 422, 423, 424, 425, 426, 440, 441, 443, 444, 465, 468, 478, 480, 481, 482, 483, 489, 490, 491, 494, 495, 496, 497, 512, 513, 516, 518, 552, 560, 561, 572, 594, 600, 642, 646, 647, 667, 694, 704], "time_step": 399, "tip": 0, "to_dlpack": 202, "to_her": 497, "to_spars": 324, "todai": [137, 712], "tofil": 203, "togeth": [173, 211, 379, 398, 444, 497, 672, 704], "tol": 276, "toler": [73, 255, 276], "too": [320, 347, 363, 428, 499, 548], "top": [340, 341, 363, 387, 394, 419, 435, 478, 481, 520, 524, 526, 669], "torch": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 488, 489, 490, 491, 492, 493, 494, 495, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 704, 706], "torch_doctest_autograd": 103, "torch_doctest_cuda": [1, 2, 3, 505, 506, 667], "torch_doctest_lapack": [293, 512, 513, 518], "torch_log": 137, "torchaudio": 703, "torchdynamo": 137, "torchvis": 703, "torchvison": 703, "toronto": 347, "total": [91, 205, 229, 230, 347, 374, 387, 394, 419, 434, 480, 497, 503, 552, 554, 556, 594, 620, 646, 704], "total_length": 542, "total_transformer_block_params_in_b": 704, "totensor": 703, "toward": [168, 229, 230, 276, 328, 592, 600, 601, 704], "trace": [137, 142, 173, 276, 704], "traceabl": 4, "traceback": [103, 251], "track": [103, 305, 342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468, 525], "track_running_stat": [342, 343, 344, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468], "tracker": 276, "trade": [341, 616], "tradit": 476, "trail": [541, 543], "train": [103, 142, 332, 336, 342, 343, 344, 363, 364, 365, 370, 371, 382, 390, 391, 392, 400, 401, 402, 403, 410, 411, 412, 428, 434, 435, 447, 468, 476, 497, 513, 516, 518, 547], "train_dataset": 703, "train_load": 703, "tran": 263, "transfer": 711, "transform": [128, 263, 345, 382, 390, 391, 392, 400, 415, 457, 487, 646, 703, 704], "transformer_decod": 473, "transformer_encod": 475, "transformer_model": 472, "transformerblock": 704, "transformerdecoderlay": 473, "transformerencoderlay": 475, "transit": [305, 646], "translat": 221, "transpos": [71, 129, 130, 173, 358, 359, 360, 444, 480, 507, 508, 512, 560, 650, 652, 653, 660, 674], "transposit": [293, 671], "trapezoid": [156, 673], "travers": 497, "treat": [275, 285, 286, 287, 288, 305, 322, 381, 400, 432, 433, 435, 438, 443, 457, 462, 496, 497, 548, 552, 601, 616, 646, 661, 662, 668, 683, 711], "tree": [137, 428, 472], "triangl": 233, "triangular": [128, 129, 130, 572, 674, 675, 676, 677, 678], "trick": 341, "trigger": 620, "trilinear": [481, 687], "trim": [106, 115, 225, 226, 263], "tripler": [177, 551], "triplet": [477, 478], "triplet_loss": [477, 478], "tripletmarginloss": 478, "tripletmarginwithdistanceloss": 477, "triton": [137, 703], "triu": [518, 674], "trivial": [127, 512, 636], "tropp": [562, 651], "trou": [355, 356, 357, 358, 359, 360, 374, 480], "true": [1, 3, 66, 71, 72, 73, 74, 75, 76, 78, 87, 89, 90, 94, 103, 104, 106, 109, 112, 114, 115, 121, 122, 128, 136, 137, 142, 143, 168, 174, 175, 176, 177, 178, 179, 203, 205, 208, 210, 224, 225, 226, 229, 230, 240, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 269, 275, 276, 285, 286, 287, 288, 291, 292, 293, 295, 297, 301, 303, 304, 305, 306, 309, 314, 319, 322, 325, 328, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371, 372, 375, 376, 379, 380, 381, 382, 387, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 419, 420, 421, 422, 423, 424, 425, 426, 431, 432, 433, 434, 435, 437, 442, 443, 444, 445, 446, 460, 461, 468, 472, 474, 475, 476, 477, 478, 481, 482, 487, 490, 496, 497, 498, 499, 500, 501, 503, 507, 508, 512, 513, 514, 517, 518, 519, 531, 539, 540, 541, 542, 543, 545, 546, 547, 548, 550, 551, 552, 553, 560, 562, 570, 572, 573, 577, 578, 579, 596, 597, 604, 607, 608, 616, 617, 620, 622, 626, 633, 636, 644, 645, 646, 649, 650, 665, 669, 674, 683, 684, 687, 688, 689, 690, 694, 697, 703, 704, 711, 712], "true_branch": 142, "true_divid": 168, "true_fn": 142, "trunc": [57, 58, 66, 168, 189, 196, 199, 601], "truncat": [196, 616, 680], "trust": 275, "truth": 363, "try": [137, 205, 347, 355, 356, 357, 358, 359, 360, 481, 497, 694], "tu": 128, "tupl": [72, 74, 75, 76, 78, 92, 93, 100, 101, 102, 120, 142, 149, 152, 153, 171, 174, 176, 191, 201, 206, 211, 229, 231, 266, 291, 293, 295, 301, 303, 305, 306, 309, 311, 319, 322, 329, 330, 331, 333, 334, 335, 337, 338, 339, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 364, 374, 375, 376, 395, 396, 397, 404, 405, 406, 407, 408, 409, 421, 422, 423, 424, 425, 426, 450, 451, 452, 453, 454, 455, 479, 480, 481, 482, 483, 484, 485, 486, 491, 497, 508, 510, 518, 529, 542, 548, 552, 553, 557, 562, 563, 572, 581, 583, 585, 595, 599, 600, 633, 634, 635, 636, 637, 638, 639, 642, 644, 645, 649, 650, 651, 665, 666, 667, 668, 669, 674, 681, 682, 683, 684, 685, 689, 690, 694, 695, 697, 699, 712], "turn": [87, 137, 254, 634, 635, 636, 637, 638, 687], "tutori": 707, "tvar": 276, "twelv": 711, "two": [71, 73, 101, 125, 127, 152, 153, 161, 170, 173, 179, 197, 198, 229, 231, 255, 265, 268, 270, 275, 298, 301, 304, 306, 309, 321, 338, 340, 341, 355, 356, 357, 358, 359, 360, 361, 363, 374, 379, 387, 388, 394, 396, 398, 419, 420, 422, 431, 432, 433, 435, 436, 442, 444, 460, 461, 476, 477, 478, 480, 512, 514, 518, 540, 550, 552, 553, 573, 588, 601, 616, 636, 650, 667, 671, 672, 674, 683, 691, 695, 704, 711], "txt": 703, "ty": 548, "type": [1, 2, 3, 64, 65, 66, 67, 68, 69, 79, 87, 93, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 121, 122, 123, 124, 125, 127, 136, 138, 142, 154, 155, 168, 173, 174, 175, 176, 186, 187, 188, 194, 196, 197, 198, 199, 202, 203, 205, 206, 207, 209, 213, 215, 217, 220, 225, 226, 228, 229, 230, 242, 245, 247, 248, 251, 252, 253, 254, 262, 263, 264, 267, 274, 275, 276, 290, 293, 296, 303, 305, 313, 319, 322, 332, 336, 355, 356, 357, 358, 359, 360, 364, 370, 371, 418, 429, 436, 438, 462, 463, 464, 488, 489, 490, 491, 492, 493, 494, 495, 497, 502, 503, 504, 507, 508, 509, 510, 511, 512, 513, 515, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 550, 552, 553, 557, 558, 562, 570, 571, 572, 574, 575, 576, 577, 578, 581, 582, 583, 584, 585, 586, 587, 588, 591, 592, 594, 598, 601, 608, 609, 612, 613, 614, 616, 634, 635, 636, 637, 638, 639, 646, 647, 649, 650, 651, 657, 665, 674, 676, 678, 683, 684, 685, 687, 688, 694, 697, 699, 700, 703, 710, 711, 712], "type1": 571, "type2": 571, "typecheck": 253, "typedstorag": 252, "typeerror": 529, "typeguard": [252, 253], "typic": [2, 150, 194, 202, 265, 268, 275, 361, 387, 487, 616, 634, 635, 637, 638, 703], "u": [128, 293, 295, 345, 355, 356, 357, 358, 359, 360, 379, 380, 398, 399, 413, 415, 444, 446, 447, 468, 479, 518, 562, 650, 651, 712], "u_": 295, "u_1": 479, "u_i": 479, "u_n": 479, "uint8": [72, 78, 204, 571, 574, 575, 598, 711], "uint_tensor": 711, "un": 347, "unaffect": 381, "unari": [472, 474, 476], "unbalanc": [363, 435], "unbatch": [347, 363, 374, 379, 390, 398, 444], "unbias": [150, 342, 343, 344, 382, 390, 391, 392, 400, 468, 644, 645, 689, 690], "unbind": 694, "unchang": [190, 593, 642], "uncoalesc": 636, "uncondition": 540, "unconstrain": 518, "undefin": [92, 113, 121, 176, 204, 205, 275, 340, 497, 566], "under": [103, 122, 347, 512, 515, 518, 593, 704, 712], "underflow": 393, "underli": [92, 203, 237, 241, 275, 323, 590, 671, 686], "understood": 124, "undesir": [347, 355, 356, 357, 358, 359, 360, 646], "undon": [520, 521, 522, 523, 524, 525, 526, 527, 536], "unequ": [356, 357, 359, 360], "unexpect": [151, 202, 205, 548, 642], "unflatten": 707, "unflattened_s": 479, "unfold": 374, "unfortun": 497, "unicodedecodeerror": 275, "uniform": [107, 363, 447, 581, 582, 712], "uniform_": [63, 99, 107, 712], "uniformli": [583, 584], "uniniti": [174, 175, 487, 500, 501, 546, 687], "uninitializedparamet": [413, 487], "union": [142, 479, 518], "uniqu": [257, 304, 311, 650, 684], "unique_consecut": 683, "unit": [336, 346, 369, 372, 377, 378, 379, 380, 447, 448, 458, 522, 523, 527, 530, 532, 535, 585, 674, 704], "unitari": [512, 560], "unitriangular": 674, "unknown": [500, 501], "unless": [93, 108, 275, 304, 381, 476, 491, 529, 548, 608, 687, 704], "unlik": [103, 170, 190, 194, 301, 304, 306, 400, 500, 501, 591, 657, 691, 711, 712], "unnecessari": [505, 506, 546], "unnorm": 363, "unord": [429, 438], "unpack": [295, 364, 542, 544, 551], "unpack_data": 295, "unpack_pivot": 295, "unpacked_sequ": 544, "unpad": 545, "unpadded_sequ": 545, "unparametr": 518, "unparametris": 519, "unpickl": 275, "unpool": [424, 425, 426], "unpooled_output": 426, "unprun": [523, 524, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535], "unreduc": [340, 341, 363, 388, 394, 419, 435, 460, 478], "unsaf": [275, 515, 518], "unseed": 579, "unseg": 347, "unshard": 704, "unsign": 711, "unsort": [540, 541, 608], "unsorted_indic": [539, 541, 542, 544], "unspecifi": [462, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 636], "unsqueez": [265, 370, 448, 518, 668], "unstabl": [284, 293, 650], "unstack": 545, "unstructur": [525, 529], "unsuccessfulli": 694, "unsw": 579, "until": [1, 3, 205, 265, 276, 487, 668, 703, 704], "untrust": 275, "untypedstorag": 252, "unus": [389, 497], "unused_argument1": 389, "unused_argument2": 389, "up": [137, 156, 173, 193, 257, 332, 347, 374, 434, 474, 476, 480, 481, 497, 505, 506, 579, 601, 683, 684, 704, 712], "updat": [342, 343, 344, 364, 370, 371, 379, 390, 391, 392, 429, 438, 468, 505, 506, 513, 518, 548, 703], "upon": [137, 515, 518, 683], "upper": [116, 121, 128, 129, 130, 132, 187, 188, 228, 229, 447, 572, 587, 608, 674, 677, 678], "upsampl": [359, 482, 483], "upscal": 440, "upscale_factor": 440, "us": [1, 2, 3, 65, 68, 79, 92, 93, 94, 103, 104, 105, 106, 107, 115, 117, 118, 125, 127, 137, 142, 143, 146, 148, 154, 155, 156, 165, 173, 174, 175, 176, 186, 187, 188, 194, 196, 199, 203, 206, 211, 212, 218, 219, 221, 225, 226, 227, 228, 241, 253, 263, 264, 266, 268, 274, 275, 276, 281, 284, 290, 293, 294, 297, 298, 303, 304, 305, 308, 314, 319, 321, 322, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 364, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 379, 380, 381, 382, 387, 388, 390, 391, 392, 393, 395, 396, 397, 398, 399, 400, 401, 402, 403, 410, 411, 412, 414, 415, 416, 421, 422, 423, 424, 425, 430, 434, 435, 436, 437, 439, 440, 441, 442, 443, 444, 446, 450, 451, 452, 453, 454, 455, 456, 457, 460, 462, 465, 468, 476, 477, 478, 479, 481, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 512, 513, 514, 515, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 529, 532, 533, 540, 541, 542, 546, 547, 548, 550, 551, 553, 554, 557, 560, 570, 572, 573, 574, 577, 578, 579, 581, 583, 585, 587, 588, 594, 601, 604, 609, 610, 612, 613, 614, 616, 618, 619, 621, 629, 633, 634, 635, 636, 637, 638, 646, 649, 650, 651, 665, 669, 672, 676, 678, 683, 686, 687, 691, 694, 699, 701, 703, 704, 706, 707, 710, 711, 712], "usa": 381, "usag": [137, 173, 202, 276, 497, 703, 704, 712], "use_amp": 703, "use_deterministic_algorithm": [87, 174, 175, 176, 247, 615], "use_mm_for_euclid_dist": 125, "use_mm_for_euclid_dist_if_necessari": 125, "use_reentr": 497, "use_trivi": 512, "use_xpu": 703, "user": [202, 275, 472, 474, 475, 476, 490, 491, 497, 505, 506, 515, 529, 711], "usual": [366, 367, 368, 372, 387, 390, 391, 392, 393, 487, 497, 694], "uszkoreit": [472, 474, 476], "utf": 275, "util": [174, 175, 176, 202, 379, 398, 444, 445, 488, 489, 490, 491, 492, 493, 494, 495, 497, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 654, 655, 657, 658, 659, 687, 703, 706, 710], "v": [121, 263, 276, 434, 477, 478, 514, 545, 550, 562, 595, 636, 650, 651, 694], "v1": 561, "v2": [561, 703], "valid": [2, 128, 173, 266, 298, 355, 356, 357, 487, 524, 529, 533, 572], "valu": [2, 60, 63, 66, 67, 70, 74, 75, 76, 79, 88, 89, 90, 94, 99, 106, 107, 108, 113, 115, 121, 125, 129, 130, 132, 145, 146, 149, 152, 153, 156, 164, 165, 174, 175, 176, 178, 187, 188, 194, 199, 206, 208, 210, 215, 217, 221, 224, 225, 226, 227, 228, 229, 230, 237, 251, 256, 257, 258, 259, 262, 263, 265, 266, 269, 273, 274, 275, 276, 279, 284, 290, 292, 293, 296, 301, 303, 304, 306, 309, 312, 314, 318, 319, 320, 321, 324, 325, 328, 332, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 369, 370, 371, 372, 374, 381, 382, 383, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 400, 401, 402, 403, 410, 411, 412, 413, 414, 415, 418, 420, 421, 422, 423, 424, 425, 426, 429, 433, 434, 435, 436, 437, 438, 439, 442, 443, 457, 460, 462, 463, 464, 465, 466, 468, 471, 472, 474, 476, 477, 478, 480, 481, 487, 489, 491, 494, 495, 496, 497, 504, 512, 513, 516, 518, 520, 521, 522, 523, 524, 525, 526, 527, 532, 533, 539, 542, 543, 546, 548, 552, 553, 557, 558, 562, 566, 569, 573, 575, 576, 588, 590, 592, 593, 594, 599, 600, 601, 608, 611, 620, 623, 630, 633, 634, 635, 636, 637, 638, 646, 650, 651, 662, 666, 669, 672, 675, 676, 677, 678, 680, 683, 684, 686, 697, 699, 700, 711, 712], "valueerror": [518, 519, 539, 542], "vandermond": 688, "var": [342, 343, 344, 381, 382, 390, 391, 392, 400, 468, 576, 690], "varepsilon": 477, "vari": [341, 460, 539], "variabl": [142, 146, 150, 174, 276, 379, 398, 428, 431, 444, 497, 540, 541, 542, 543, 544, 545, 557, 581, 583, 585, 687, 694, 699], "varianc": [150, 342, 343, 344, 372, 381, 390, 391, 392, 401, 402, 403, 410, 411, 412, 468, 508, 510, 576, 585, 586, 689, 690], "variant": [321, 324, 674], "variou": 276, "vaswani": [472, 474, 476], "vdim": 434, "vdot": 265, "vec": [69, 316, 549], "vec1": 70, "vec2": [70, 212, 561], "vecdot": 691, "vector": [68, 69, 70, 98, 118, 119, 125, 136, 146, 150, 151, 154, 155, 160, 162, 211, 293, 298, 305, 314, 316, 342, 343, 344, 347, 364, 370, 371, 374, 382, 390, 391, 392, 437, 468, 477, 480, 503, 511, 513, 518, 549, 553, 561, 562, 650, 688, 691, 694, 707, 710, 711], "vector_norm": 553, "veri": [148, 390, 391, 392, 498, 499, 512, 560, 629, 674, 694], "verifi": [156, 672], "versa": [204, 205, 420], "version": [103, 142, 225, 263, 298, 323, 341, 429, 481, 488, 518, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 547, 548, 605, 606, 607, 642, 644, 645, 646, 650, 671, 685, 687, 689, 690, 703, 704, 712], "versu": 432, "vert": [362, 437], "vert_p": 437, "vertic": [695, 696], "vh": [518, 650], "via": [1, 124, 177, 275, 276, 342, 343, 344, 364, 382, 390, 391, 392, 400, 468, 512, 547, 550, 711], "vice": [204, 205, 420], "video": [440, 441], "view": [71, 76, 92, 100, 101, 102, 103, 119, 131, 143, 144, 163, 164, 171, 190, 191, 192, 193, 231, 348, 379, 398, 444, 480, 481, 482, 483, 497, 503, 563, 595, 599, 600, 604, 610, 611, 630, 639, 649, 661, 666, 670, 682, 692, 693, 695, 704, 711], "view_as_r": 646, "view_copi": 712, "viewbackward": 704, "visibl": [429, 430, 438, 439], "vision": [363, 703], "visual": [305, 355, 356, 357, 358, 359, 360, 374, 421, 422, 423, 480], "vjp": 694, "void": 2, "vol": [263, 381], "volum": 230, "volumetr": [344, 468, 481], "vstack": 602, "vw_i": 434, "vychisl": 579, "w": [106, 115, 150, 208, 225, 226, 263, 330, 331, 338, 339, 341, 343, 344, 356, 357, 363, 367, 368, 370, 371, 372, 379, 391, 392, 400, 411, 412, 422, 423, 433, 434, 435, 440, 441, 463, 479, 480, 482, 483, 513, 514, 547, 550], "w_": [330, 331, 334, 335, 338, 339, 341, 349, 350, 351, 352, 353, 354, 356, 357, 359, 360, 363, 375, 376, 379, 380, 396, 397, 398, 399, 422, 423, 425, 426, 435, 440, 441, 444, 446, 450, 451, 452, 453, 454, 455, 481, 482, 483, 484, 485, 486], "w_c": 363, "w_hf": 398, "w_hg": 398, "w_hi": 398, "w_hn": 379, "w_ho": 398, "w_hr": 379, "w_hz": 379, "w_i": 150, "w_ia_i": 150, "w_if": 398, "w_ig": 398, "w_ii": 398, "w_in": 379, "w_io": 398, "w_ir": 379, "w_ix_": 150, "w_iz": 379, "w_j": 463, "w_n": [340, 341], "wa": [1, 127, 138, 263, 275, 293, 314, 398, 424, 425, 426, 458, 481, 497, 499, 542, 644, 645, 683, 684, 689, 690, 694, 704], "wai": [221, 340, 371, 390, 391, 392, 398, 410, 411, 412, 428, 457, 474, 476, 492, 493, 497, 516, 546, 704, 712], "wait": [1, 3], "wait_ev": 3, "wait_stream": 3, "want": [103, 305, 375, 376, 481, 497, 499, 548, 551, 604, 704], "warn": [0, 127, 247, 263, 275, 305, 515, 518, 615, 622, 646, 687, 694], "warn_alwai": 254, "warn_onli": 687, "wasn": 275, "we": [79, 106, 115, 137, 173, 202, 221, 225, 226, 241, 275, 276, 295, 314, 332, 337, 338, 339, 340, 341, 375, 393, 481, 491, 497, 505, 506, 512, 515, 524, 526, 529, 533, 534, 573, 613, 614, 616, 683, 694, 703, 704, 706, 711, 712], "weakli": [323, 324], "web": 579, "weigend": 381, "weight": [108, 150, 229, 230, 270, 314, 340, 341, 345, 355, 356, 357, 358, 359, 360, 363, 370, 371, 379, 380, 382, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415, 432, 433, 435, 436, 443, 444, 446, 458, 487, 496, 505, 506, 507, 508, 510, 512, 513, 514, 516, 518, 529, 531, 532, 533, 534, 535, 536, 537, 538, 546, 547, 548, 550, 576, 687, 694, 703, 704], "weight_g": 550, "weight_hh": [380, 399, 444, 446], "weight_hh_l": [379, 398, 444], "weight_hr_l": 398, "weight_ih": [380, 399, 444, 446], "weight_ih_l": [379, 398, 444], "weight_mask": [532, 535], "weight_norm": 538, "weight_orig": 532, "weight_u": 547, "weight_v": 550, "weights_onli": 275, "well": [342, 343, 344, 363, 398, 468, 497, 572, 683, 704, 712], "were": [275, 497, 503, 525, 542, 608, 612, 661, 668, 694], "what": [293, 355, 356, 357, 358, 359, 360, 374, 422, 423, 457, 480, 520, 521, 522, 523, 524, 525, 526, 527, 573, 704], "whatev": [612, 674], "when": [1, 65, 68, 79, 91, 94, 103, 105, 108, 117, 125, 128, 129, 130, 136, 137, 143, 144, 148, 156, 173, 190, 194, 199, 205, 221, 255, 256, 258, 259, 262, 265, 266, 274, 275, 276, 284, 290, 293, 298, 304, 305, 308, 314, 319, 320, 321, 332, 337, 338, 339, 340, 341, 342, 343, 344, 347, 355, 356, 357, 358, 359, 360, 361, 363, 364, 370, 371, 374, 377, 379, 380, 382, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 410, 411, 412, 415, 419, 420, 421, 422, 423, 424, 425, 426, 428, 431, 432, 433, 434, 435, 436, 442, 443, 444, 456, 457, 460, 461, 462, 463, 465, 468, 474, 475, 476, 477, 479, 480, 481, 482, 483, 487, 496, 497, 498, 499, 500, 501, 505, 506, 512, 513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 542, 547, 551, 552, 553, 554, 560, 562, 569, 572, 573, 595, 601, 608, 613, 616, 622, 629, 636, 642, 646, 650, 660, 665, 667, 672, 676, 678, 687, 694, 697, 704, 706, 711], "whenev": [94, 512, 513], "where": [1, 3, 72, 74, 75, 78, 91, 106, 115, 121, 128, 129, 130, 137, 146, 150, 152, 153, 156, 160, 178, 210, 224, 225, 226, 227, 255, 256, 258, 259, 262, 263, 264, 265, 266, 269, 275, 276, 281, 284, 291, 292, 293, 294, 298, 301, 303, 304, 305, 306, 309, 314, 319, 320, 322, 325, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 369, 370, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 431, 432, 433, 434, 435, 436, 437, 440, 441, 442, 443, 444, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 496, 497, 500, 501, 505, 506, 512, 540, 541, 542, 543, 552, 560, 570, 572, 573, 593, 594, 630, 633, 634, 635, 636, 637, 638, 644, 645, 646, 649, 650, 651, 665, 674, 675, 676, 677, 678, 683, 684, 689, 690, 691, 692, 693, 694, 704, 711], "wherea": [319, 650], "whether": [72, 74, 75, 78, 88, 89, 94, 103, 104, 106, 115, 128, 129, 130, 136, 138, 203, 225, 226, 263, 266, 275, 291, 293, 301, 303, 304, 306, 309, 314, 319, 320, 321, 322, 347, 387, 393, 428, 437, 442, 478, 490, 497, 498, 512, 515, 518, 531, 545, 548, 553, 560, 570, 573, 617, 644, 645, 646, 649, 650, 669, 674, 683, 684, 687, 689, 690, 694, 704], "which": [2, 4, 63, 76, 90, 94, 99, 108, 121, 124, 127, 131, 137, 142, 148, 149, 150, 151, 156, 160, 161, 162, 163, 164, 173, 190, 191, 192, 193, 194, 199, 202, 208, 211, 230, 241, 251, 257, 263, 275, 281, 297, 304, 309, 314, 320, 323, 324, 330, 331, 332, 334, 335, 336, 338, 339, 342, 343, 344, 347, 356, 357, 359, 360, 363, 364, 371, 378, 379, 388, 390, 391, 392, 393, 395, 396, 397, 398, 400, 414, 418, 422, 423, 424, 425, 426, 431, 433, 443, 457, 460, 462, 464, 468, 477, 478, 487, 496, 497, 505, 506, 512, 514, 515, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 535, 536, 548, 550, 553, 562, 574, 588, 592, 594, 595, 599, 601, 608, 612, 616, 620, 621, 622, 629, 633, 639, 642, 646, 651, 657, 666, 671, 672, 675, 676, 677, 678, 682, 683, 686, 687, 694, 703, 704, 711], "whichev": [150, 573, 694], "while": [74, 75, 98, 230, 276, 320, 332, 348, 388, 390, 391, 392, 398, 447, 460, 468, 476, 490, 528, 529, 530, 532, 533, 534, 535, 553, 608, 616, 704], "whitespac": 173, "whole": [457, 468, 497, 694], "whose": [127, 145, 161, 173, 178, 205, 210, 221, 224, 230, 269, 274, 290, 292, 325, 497, 554, 566, 623, 668, 704], "why": [173, 349, 451, 452, 453, 704], "wide": 512, "wider": 194, "width": [228, 229, 230, 338, 339, 356, 357, 359, 360, 396, 397, 422, 423, 435, 463, 481], "win": 646, "win_length": [263, 646], "window": [106, 115, 225, 226, 263, 264, 337, 338, 339, 375, 376, 395, 396, 397, 421, 422, 423, 424, 425, 426, 577, 578, 646], "window_length": [106, 115, 225, 226, 264], "wise": [66, 67, 77, 98, 144, 173, 178, 197, 198, 209, 210, 224, 232, 267, 269, 285, 286, 287, 288, 292, 302, 305, 307, 325, 346, 360, 367, 369, 383, 384, 385, 386, 388, 414, 417, 427, 436, 447, 448, 449, 456, 458, 459, 460, 465, 466, 467, 469, 470, 696], "wish": 642, "with_replac": 136, "within": [2, 92, 137, 142, 156, 296, 337, 338, 339, 347, 366, 367, 368, 372, 374, 421, 422, 423, 468, 480, 516, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 536, 577, 578, 608, 686, 712], "without": [134, 137, 263, 314, 342, 343, 344, 367, 371, 390, 391, 392, 425, 436, 468, 476, 487, 497, 530, 546, 595, 612, 681], "won": [490, 491, 712], "word": [121, 332, 355, 356, 357, 370, 371, 472, 497, 512, 608, 704], "word_language_model": 472, "work": [1, 3, 137, 174, 176, 191, 192, 193, 203, 276, 364, 425, 462, 497, 581, 585, 587, 618, 621, 634, 635, 636, 637, 638, 657, 662, 665, 704, 712], "worker": 497, "worker1": 497, "workflow": [703, 712], "workload": 704, "workspac": 137, "world": [468, 497], "world_siz": 497, "wors": 687, "would": [77, 127, 174, 176, 203, 314, 337, 338, 339, 340, 341, 379, 393, 398, 421, 422, 423, 438, 444, 478, 487, 497, 499, 505, 506, 539, 551, 581, 585, 587, 598, 608, 634, 635, 636, 637, 638, 665, 666, 671, 703, 704, 707], "wrap": [364, 468, 491, 497, 516, 542, 712], "wrapper": [4, 197, 198, 364], "write": [76, 119, 204, 243, 604, 674, 687, 694], "writeabl": [143, 144], "written": [203, 364], "wu": 276, "www": [347, 478], "x": [71, 92, 98, 100, 101, 102, 103, 104, 119, 120, 121, 124, 125, 130, 137, 142, 143, 146, 149, 150, 156, 163, 167, 168, 173, 177, 187, 188, 191, 192, 193, 201, 221, 237, 241, 253, 266, 276, 281, 282, 283, 291, 294, 297, 298, 305, 318, 319, 323, 324, 330, 331, 340, 341, 342, 343, 344, 346, 361, 363, 369, 375, 376, 377, 379, 380, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 394, 395, 396, 397, 398, 399, 400, 414, 417, 418, 419, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 443, 444, 446, 447, 448, 449, 456, 458, 459, 460, 461, 463, 465, 466, 467, 468, 469, 470, 471, 477, 478, 481, 487, 496, 513, 516, 518, 539, 540, 541, 542, 543, 548, 551, 552, 553, 562, 563, 574, 576, 590, 593, 594, 596, 597, 599, 600, 604, 608, 633, 642, 643, 644, 645, 646, 652, 653, 660, 666, 668, 669, 670, 671, 672, 673, 674, 684, 686, 688, 689, 690, 692, 693, 694, 697, 711, 712], "x1": [125, 362, 420, 477, 478], "x2": [125, 420, 477, 478], "x3": 477, "x86": 617, "x_": [150, 183, 277, 278, 280, 283, 291, 341, 363, 418, 435, 462, 464, 672], "x_0": 672, "x_1": [152, 153, 154, 155, 345, 361, 362, 672], "x_2": [152, 153, 154, 155, 345, 361, 362], "x_3": [152, 153, 154, 155], "x_diff": 672, "x_i": [132, 152, 153, 154, 155, 279, 418, 437, 462, 464, 477, 569, 644, 645, 672, 689, 690, 691], "x_j": [418, 462, 464], "x_n": [340, 341, 387, 388, 394, 419, 460, 672], "x_t": [342, 343, 344, 379, 390, 391, 392, 398, 444, 468], "xa": 415, "xdoctest": [1, 2, 3, 103, 104, 127, 173, 177, 275, 293, 305, 347, 349, 351, 352, 353, 364, 370, 371, 374, 424, 434, 450, 451, 452, 453, 454, 455, 468, 478, 480, 481, 482, 484, 485, 487, 497, 505, 506, 512, 513, 518, 530, 532, 534, 535, 546, 548, 551, 579, 604, 612, 613, 614, 667, 687], "xi_1": 221, "xi_2": 221, "xing": 579, "xla": 711, "xn": 125, "xor": [114, 288], "xpu": [216, 703, 711, 712], "xy": 305, "y": [98, 100, 101, 102, 103, 104, 119, 125, 143, 150, 156, 167, 173, 177, 281, 282, 305, 340, 341, 342, 343, 344, 345, 361, 363, 382, 387, 388, 390, 391, 392, 394, 400, 415, 419, 420, 431, 432, 433, 435, 437, 443, 460, 461, 468, 471, 477, 478, 487, 496, 518, 551, 576, 594, 596, 597, 642, 668, 672, 673, 694, 697, 712], "y_": [150, 183, 277, 278, 280, 341, 363, 393, 672], "y_0": 672, "y_1": 672, "y_diff": 672, "y_i": [132, 152, 153, 154, 155, 279, 477, 672, 691], "y_n": [340, 341, 363, 387, 388, 394, 419, 435, 460, 672], "yang": 276, "yet": [309, 520, 524, 526, 711], "yield": [161, 163, 697], "you": [68, 103, 119, 137, 173, 275, 298, 305, 308, 347, 355, 356, 357, 358, 359, 360, 363, 398, 424, 425, 426, 428, 433, 434, 435, 463, 472, 474, 476, 481, 487, 497, 513, 540, 548, 550, 551, 572, 595, 604, 612, 634, 635, 637, 638, 642, 694, 703, 704, 706, 710, 711, 712], "your": [103, 137, 428, 435, 476, 497, 515, 518, 551, 617, 683, 701, 703, 707, 710, 712], "z": [91, 128, 139, 173, 177, 305, 380, 518, 551, 552, 566, 596, 597], "z_t": 379, "za": 173, "zero": [59, 70, 77, 91, 100, 101, 102, 107, 108, 128, 129, 130, 135, 145, 149, 164, 168, 186, 187, 188, 190, 199, 205, 227, 228, 231, 251, 263, 276, 284, 285, 286, 287, 288, 293, 294, 314, 318, 322, 336, 337, 338, 339, 347, 355, 356, 357, 358, 359, 360, 362, 365, 366, 367, 368, 370, 371, 372, 374, 379, 380, 382, 395, 396, 397, 398, 399, 400, 404, 405, 406, 407, 408, 409, 421, 422, 423, 424, 425, 426, 434, 437, 440, 441, 442, 443, 444, 446, 466, 480, 481, 484, 485, 486, 496, 523, 524, 525, 526, 541, 548, 552, 556, 560, 572, 574, 575, 576, 585, 592, 601, 611, 626, 630, 634, 635, 636, 637, 638, 642, 650, 665, 666, 668, 674, 700, 711, 712], "zero_grad": [497, 703], "zero_infin": 347, "zero_point": [187, 188, 574, 575, 576, 577, 578], "zeroredundancyoptim": 497, "zeroth": 264, "zh": 579, "zipf": 332, "zipfil": 604, "\u00e0": [355, 356, 357, 358, 359, 360, 374, 480]}, "titles": ["Admonitions", "Event", "Generator", "Stream", "_assert", "_foreach_abs", "_foreach_abs_", "_foreach_acos", "_foreach_acos_", "_foreach_asin", "_foreach_asin_", "_foreach_atan", "_foreach_atan_", "_foreach_ceil", "_foreach_ceil_", "_foreach_cos", "_foreach_cos_", "_foreach_cosh", "_foreach_cosh_", "_foreach_erf", "_foreach_erf_", "_foreach_erfc", "_foreach_erfc_", "_foreach_exp", "_foreach_exp_", "_foreach_expm1", "_foreach_expm1_", "_foreach_floor", "_foreach_floor_", "_foreach_frac", "_foreach_frac_", "_foreach_lgamma", "_foreach_lgamma_", "_foreach_log", "_foreach_log10", "_foreach_log10_", "_foreach_log1p", "_foreach_log1p_", "_foreach_log2", "_foreach_log2_", "_foreach_log_", "_foreach_neg", "_foreach_neg_", "_foreach_reciprocal", "_foreach_reciprocal_", "_foreach_round", "_foreach_round_", "_foreach_sigmoid", "_foreach_sigmoid_", "_foreach_sin", "_foreach_sin_", "_foreach_sinh", "_foreach_sinh_", "_foreach_sqrt", "_foreach_sqrt_", "_foreach_tan", "_foreach_tan_", "_foreach_trunc", "_foreach_trunc_", "_foreach_zero_", "abs", "absolute", "acos", "acosh", "add", "addbmm", "addcdiv", "addcmul", "addmm", "addmv", "addr", "adjoint", "all", "allclose", "amax", "amin", "aminmax", "angle", "any", "arange", "arccos", "arccosh", "arcsin", "arcsinh", "arctan", "arctan2", "arctanh", "are_deterministic_algorithms_enabled", "argmax", "argmin", "argsort", "argwhere", "as_strided", "as_tensor", "asarray", "asin", "asinh", "atan", "atan2", "atanh", "atleast_1d", "atleast_2d", "atleast_3d", "inference_mode", "set_grad_enabled", "baddbmm", "bartlett_window", "bernoulli", "bincount", "bitwise_and", "bitwise_left_shift", "bitwise_not", "bitwise_or", "bitwise_right_shift", "bitwise_xor", "blackman_window", "block_diag", "bmm", "broadcast_shapes", "broadcast_tensors", "broadcast_to", "bucketize", "can_cast", "cartesian_prod", "cat", "cdist", "ceil", "chain_matmul", "cholesky", "cholesky_inverse", "cholesky_solve", "chunk", "clamp", "clip", "clone", "column_stack", "combinations", "compile", "compiled_with_cxx11_abi", "complex", "concat", "concatenate", "cond", "conj", "conj_physical", "copysign", "corrcoef", "cos", "cosh", "count_nonzero", "cov", "cross", "cummax", "cummin", "cumprod", "cumsum", "cumulative_trapezoid", "deg2rad", "dequantize", "det", "diag", "diag_embed", "diagflat", "diagonal", "diagonal_scatter", "diff", "digamma", "dist", "div", "divide", "dot", "dsplit", "dstack", "einsum", "empty", "empty_like", "empty_strided", "enable_grad", "eq", "equal", "erf", "erfc", "erfinv", "exp", "exp2", "expm1", "eye", "fake_quantize_per_channel_affine", "fake_quantize_per_tensor_affine", "fix", "flatten", "flip", "fliplr", "flipud", "float_power", "floor", "floor_divide", "fmax", "fmin", "fmod", "frac", "frexp", "from_dlpack", "from_file", "from_numpy", "frombuffer", "full", "full_like", "gather", "gcd", "ge", "geqrf", "ger", "get_default_device", "get_default_dtype", "get_deterministic_debug_mode", "get_device_module", "get_float32_matmul_precision", "get_num_interop_threads", "get_num_threads", "get_rng_state", "gradient", "greater", "greater_equal", "gt", "hamming_window", "hann_window", "heaviside", "histc", "histogram", "histogramdd", "hsplit", "hstack", "hypot", "i0", "igamma", "igammac", "imag", "index_add", "index_copy", "index_reduce", "index_select", "initial_seed", "inner", "inverse", "is_complex", "is_conj", "is_deterministic_algorithms_warn_only_enabled", "is_floating_point", "is_grad_enabled", "is_inference_mode_enabled", "is_nonzero", "is_storage", "is_tensor", "is_warn_always_enabled", "isclose", "isfinite", "isin", "isinf", "isnan", "isneginf", "isposinf", "isreal", "istft", "kaiser_window", "kron", "kthvalue", "lcm", "ldexp", "le", "lerp", "less", "less_equal", "lgamma", "linspace", "load", "lobpcg", "log", "log10", "log1p", "log2", "logaddexp", "logaddexp2", "logcumsumexp", "logdet", "logical_and", "logical_not", "logical_or", "logical_xor", "logit", "logspace", "logsumexp", "lt", "lu", "lu_solve", "lu_unpack", "manual_seed", "masked_select", "matmul", "matrix_exp", "matrix_power", "max", "maximum", "mean", "median", "meshgrid", "min", "minimum", "mm", "mode", "moveaxis", "movedim", "msort", "mul", "multinomial", "multiply", "mv", "mvlgamma", "nan_to_num", "nanmean", "nanmedian", "nanquantile", "nansum", "narrow", "narrow_copy", "ne", "neg", "negative", "nextafter", "torch.nn.AdaptiveAvgPool1d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool3d", "torch.nn.AdaptiveLogSoftmaxWithLoss", "torch.nn.AdaptiveMaxPool1d", "torch.nn.AdaptiveMaxPool2d", "torch.nn.AdaptiveMaxPool3d", "torch.nn.AlphaDropout", "torch.nn.AvgPool1d", "torch.nn.AvgPool2d", "torch.nn.AvgPool3d", "torch.nn.BCELoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm3d", "torch.nn.Bilinear", "torch.nn.CELU", "torch.nn.CTCLoss", "torch.nn.ChannelShuffle", "torch.nn.CircularPad1d", "torch.nn.CircularPad2d", "torch.nn.CircularPad3d", "torch.nn.ConstantPad1d", "torch.nn.ConstantPad2d", "torch.nn.ConstantPad3d", "torch.nn.Conv1d", "torch.nn.Conv2d", "torch.nn.Conv3d", "torch.nn.ConvTranspose1d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose3d", "torch.nn.CosineEmbeddingLoss", "torch.nn.CosineSimilarity", "torch.nn.CrossEntropyLoss", "torch.nn.DataParallel", "torch.nn.Dropout", "torch.nn.Dropout1d", "torch.nn.Dropout2d", "torch.nn.Dropout3d", "torch.nn.ELU", "torch.nn.Embedding", "torch.nn.EmbeddingBag", "torch.nn.FeatureAlphaDropout", "torch.nn.Flatten", "torch.nn.Fold", "torch.nn.FractionalMaxPool2d", "torch.nn.FractionalMaxPool3d", "torch.nn.GELU", "torch.nn.GLU", "torch.nn.GRU", "torch.nn.GRUCell", "torch.nn.GaussianNLLLoss", "torch.nn.GroupNorm", "torch.nn.Hardshrink", "torch.nn.Hardsigmoid", "torch.nn.Hardswish", "torch.nn.Hardtanh", "torch.nn.HingeEmbeddingLoss", "torch.nn.HuberLoss", "torch.nn.Identity", "torch.nn.InstanceNorm1d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm3d", "torch.nn.KLDivLoss", "torch.nn.L1Loss", "torch.nn.LPPool1d", "torch.nn.LPPool2d", "torch.nn.LPPool3d", "torch.nn.LSTM", "torch.nn.LSTMCell", "torch.nn.LayerNorm", "torch.nn.LazyBatchNorm1d", "torch.nn.LazyBatchNorm2d", "torch.nn.LazyBatchNorm3d", "torch.nn.LazyConv1d", "torch.nn.LazyConv2d", "torch.nn.LazyConv3d", "torch.nn.LazyConvTranspose1d", "torch.nn.LazyConvTranspose2d", "torch.nn.LazyConvTranspose3d", "torch.nn.LazyInstanceNorm1d", "torch.nn.LazyInstanceNorm2d", "torch.nn.LazyInstanceNorm3d", "torch.nn.LazyLinear", "torch.nn.LeakyReLU", "torch.nn.Linear", "torch.nn.LocalResponseNorm", "torch.nn.LogSigmoid", "torch.nn.LogSoftmax", "torch.nn.MSELoss", "torch.nn.MarginRankingLoss", "torch.nn.MaxPool1d", "torch.nn.MaxPool2d", "torch.nn.MaxPool3d", "torch.nn.MaxUnpool1d", "torch.nn.MaxUnpool2d", "torch.nn.MaxUnpool3d", "torch.nn.Mish", "torch.nn.Module", "torch.nn.ModuleDict", "torch.nn.ModuleList", "torch.nn.MultiLabelMarginLoss", "torch.nn.MultiLabelSoftMarginLoss", "torch.nn.MultiMarginLoss", "torch.nn.MultiheadAttention", "torch.nn.NLLLoss", "torch.nn.PReLU", "torch.nn.PairwiseDistance", "torch.nn.ParameterDict", "torch.nn.ParameterList", "torch.nn.PixelShuffle", "torch.nn.PixelUnshuffle", "torch.nn.PoissonNLLLoss", "torch.nn.RMSNorm", "torch.nn.RNN", "torch.nn.RNNBase", "torch.nn.RNNCell", "torch.nn.RReLU", "torch.nn.ReLU", "torch.nn.ReLU6", "torch.nn.ReflectionPad1d", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad3d", "torch.nn.ReplicationPad1d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad3d", "torch.nn.SELU", "torch.nn.Sequential", "torch.nn.SiLU", "torch.nn.Sigmoid", "torch.nn.SmoothL1Loss", "torch.nn.SoftMarginLoss", "torch.nn.Softmax", "torch.nn.Softmax2d", "torch.nn.Softmin", "torch.nn.Softplus", "torch.nn.Softshrink", "torch.nn.Softsign", "torch.nn.SyncBatchNorm", "torch.nn.Tanh", "torch.nn.Tanhshrink", "torch.nn.Threshold", "torch.nn.Transformer", "torch.nn.TransformerDecoder", "torch.nn.TransformerDecoderLayer", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoderLayer", "torch.nn.TripletMarginLoss", "torch.nn.TripletMarginWithDistanceLoss", "torch.nn.Unflatten", "torch.nn.Unfold", "torch.nn.Upsample", "torch.nn.UpsamplingBilinear2d", "torch.nn.UpsamplingNearest2d", "torch.nn.ZeroPad1d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad3d", "torch.nn.modules.lazy.LazyModuleMixin", "register_module_backward_hook", "register_module_buffer_registration_hook", "register_module_forward_hook", "register_module_forward_pre_hook", "register_module_full_backward_hook", "register_module_full_backward_pre_hook", "register_module_module_registration_hook", "register_module_parameter_registration_hook", "torch.nn.modules.normalization.RMSNorm", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parameter.Buffer", "torch.nn.parameter.Parameter", "torch.nn.parameter.UninitializedBuffer", "torch.nn.parameter.UninitializedParameter", "clip_grad_norm", "clip_grad_norm", "clip_grad_value", "convert_conv2d_weight_memory_format", "convert_conv3d_weight_memory_format", "fuse_conv_bn_eval", "fuse_conv_bn_weights", "fuse_linear_bn_eval", "fuse_linear_bn_weights", "parameters_to_vector", "orthogonal", "spectral_norm", "weight_norm", "torch.nn.utils.parametrize.ParametrizationList", "cached", "is_parametrized", "register_parametrization", "remove_parametrizations", "BasePruningMethod", "CustomFromMask", "Identity", "L1Unstructured", "LnStructured", "PruningContainer", "RandomStructured", "RandomUnstructured", "custom_from_mask", "global_unstructured", "identity", "is_pruned", "l1_unstructured", "ln_structured", "random_structured", "random_unstructured", "remove", "remove_spectral_norm", "remove_weight_norm", "PackedSequence", "pack_padded_sequence", "pack_sequence", "pad_packed_sequence", "pad_sequence", "unpack_sequence", "unpad_sequence", "skip_init", "spectral_norm", "functional_call", "vector_to_parameters", "weight_norm", "no_grad", "nonzero", "norm", "normal", "not_equal", "numel", "ones", "ones_like", "orgqr", "ormqr", "outer", "pca_lowrank", "permute", "pinverse", "poisson", "polar", "polygamma", "positive", "pow", "prod", "promote_types", "qr", "quantile", "quantize_per_channel", "quantize_per_tensor", "quantized_batch_norm", "quantized_max_pool1d", "quantized_max_pool2d", "torch.quasirandom.SobolEngine", "rad2deg", "rand", "rand_like", "randint", "randint_like", "randn", "randn_like", "randperm", "range", "ravel", "real", "reciprocal", "remainder", "renorm", "repeat_interleave", "reshape", "resolve_conj", "resolve_neg", "result_type", "roll", "rot90", "round", "row_stack", "rsqrt", "save", "scatter", "scatter_add", "scatter_reduce", "searchsorted", "seed", "select", "select_scatter", "set_default_device", "set_default_dtype", "set_default_tensor_type", "set_deterministic_debug_mode", "set_float32_matmul_precision", "set_flush_denormal", "set_num_interop_threads", "set_num_threads", "set_printoptions", "set_rng_state", "set_warn_always", "sgn", "sigmoid", "sign", "signbit", "sin", "sinc", "sinh", "slice_scatter", "slogdet", "softmax", "sort", "sparse_bsc_tensor", "sparse_bsr_tensor", "sparse_coo_tensor", "sparse_csc_tensor", "sparse_csr_tensor", "split", "sqrt", "square", "squeeze", "stack", "std", "std_mean", "stft", "sub", "subtract", "sum", "svd", "svd_lowrank", "swapaxes", "swapdims", "sym_float", "sym_int", "sym_ite", "sym_max", "sym_min", "sym_not", "t", "take", "take_along_dim", "tan", "tanh", "tensor", "tensor_split", "tensordot", "tile", "topk", "trace", "transpose", "trapezoid", "trapz", "triangular_solve", "tril", "tril_indices", "triu", "triu_indices", "true_divide", "trunc", "unbind", "unflatten", "unique", "unique_consecutive", "unravel_index", "unsqueeze", "use_deterministic_algorithms", "vander", "var", "var_mean", "vdot", "view_as_complex", "view_as_real", "vmap", "vsplit", "vstack", "where", "xlogy", "zeros", "zeros_like", "PyTorch Sphinx Theme 2 documentation", "Subintro page home", "Pytorch 2.4: Getting Started on Intel GPU", "FSDP Notes", "Test Page 1", "Test 2 page", "torch.nn", "Overview", "Getting Started", "Test Markdown Page", "Tensor Attributes", "torch", "Tutorials", "Tutorial 1", "Tutorial 2"], "titleterms": {"1": [705, 708, 714], "2": [701, 703, 705, 706, 708, 715], "3": [701, 709], "4": [701, 703], "In": 712, "_assert": 4, "_foreach_ab": 5, "_foreach_abs_": 6, "_foreach_aco": 7, "_foreach_acos_": 8, "_foreach_asin": 9, "_foreach_asin_": 10, "_foreach_atan": 11, "_foreach_atan_": 12, "_foreach_ceil": 13, "_foreach_ceil_": 14, "_foreach_co": 15, "_foreach_cos_": 16, "_foreach_cosh": 17, "_foreach_cosh_": 18, "_foreach_erf": 19, "_foreach_erf_": 20, "_foreach_erfc": 21, "_foreach_erfc_": 22, "_foreach_exp": 23, "_foreach_exp_": 24, "_foreach_expm1": 25, "_foreach_expm1_": 26, "_foreach_floor": 27, "_foreach_floor_": 28, "_foreach_frac": 29, "_foreach_frac_": 30, "_foreach_lgamma": 31, "_foreach_lgamma_": 32, "_foreach_log": 33, "_foreach_log10": 34, "_foreach_log10_": 35, "_foreach_log1p": 36, "_foreach_log1p_": 37, "_foreach_log2": 38, "_foreach_log2_": 39, "_foreach_log_": 40, "_foreach_neg": 41, "_foreach_neg_": 42, "_foreach_reciproc": 43, "_foreach_reciprocal_": 44, "_foreach_round": 45, "_foreach_round_": 46, "_foreach_sigmoid": 47, "_foreach_sigmoid_": 48, "_foreach_sin": 49, "_foreach_sin_": 50, "_foreach_sinh": 51, "_foreach_sinh_": 52, "_foreach_sqrt": 53, "_foreach_sqrt_": 54, "_foreach_tan": 55, "_foreach_tan_": 56, "_foreach_trunc": 57, "_foreach_trunc_": 58, "_foreach_zero_": 59, "ab": 60, "absolut": 61, "acceler": 712, "aco": 62, "acosh": 63, "activ": 707, "adaptiveavgpool1d": 329, "adaptiveavgpool2d": 330, "adaptiveavgpool3d": 331, "adaptivelogsoftmaxwithloss": 332, "adaptivemaxpool1d": 333, "adaptivemaxpool2d": 334, "adaptivemaxpool3d": 335, "add": 64, "addbmm": 65, "addcdiv": 66, "addcmul": 67, "addmm": 68, "addmv": 69, "addr": 70, "adjoint": 71, "admonit": 0, "alias": 707, "all": 72, "allclos": 73, "alphadropout": 336, "amax": 74, "amin": 75, "aminmax": 76, "amp": 703, "angl": 77, "ani": 78, "anoth": 709, "api": 710, "arang": 79, "arcco": 80, "arccosh": 81, "arcsin": 82, "arcsinh": 83, "arctan": 84, "arctan2": 85, "arctanh": 86, "are_deterministic_algorithms_en": 87, "argmax": 88, "argmin": 89, "argsort": 90, "argwher": 91, "as_strid": 92, "as_tensor": 93, "asarrai": 94, "asin": 95, "asinh": 96, "atan": 97, "atan2": 98, "atanh": 99, "atleast_1d": 100, "atleast_2d": 101, "atleast_3d": 102, "attribut": 711, "avail": 703, "avgpool1d": 337, "avgpool2d": 338, "avgpool3d": 339, "baddbmm": 105, "bartlett_window": 106, "basepruningmethod": 520, "batchnorm1d": 342, "batchnorm2d": 343, "batchnorm3d": 344, "bceloss": 340, "bcewithlogitsloss": 341, "bernoulli": 107, "bilinear": 345, "bincount": 108, "bitwise_and": 109, "bitwise_left_shift": 110, "bitwise_not": 111, "bitwise_or": 112, "bitwise_right_shift": 113, "bitwise_xor": 114, "bla": 712, "blackman_window": 115, "block_diag": 116, "bmm": 117, "broadcast_shap": 118, "broadcast_tensor": 119, "broadcast_to": 120, "bucket": 121, "buffer": [498, 704], "build": 703, "cach": 516, "can_cast": 122, "cartesian_prod": 123, "cat": 124, "cdist": 125, "ceil": 126, "celu": 346, "chain_matmul": 127, "chang": 703, "channelshuffl": 348, "check": 703, "choleski": 128, "cholesky_invers": 129, "cholesky_solv": 130, "chunk": 131, "circularpad1d": 349, "circularpad2d": 350, "circularpad3d": 351, "clamp": 132, "clip": 133, "clip_grad_norm": [502, 503], "clip_grad_valu": 504, "clone": 134, "co": 147, "code": 703, "column_stack": 135, "combin": 136, "commun": 704, "comparison": 712, "compil": [137, 703], "compiled_with_cxx11_abi": 138, "complex": 139, "comput": 712, "concat": 140, "concaten": 141, "cond": 142, "conj": 143, "conj_phys": 144, "constantpad1d": 352, "constantpad2d": 353, "constantpad3d": 354, "contain": 707, "control": 712, "conv1d": 355, "conv2d": 356, "conv3d": 357, "convert_conv2d_weight_memory_format": 505, "convert_conv3d_weight_memory_format": 506, "convolut": 707, "convtranspose1d": 358, "convtranspose2d": 359, "convtranspose3d": 360, "copysign": 145, "corrcoef": 146, "cosh": 148, "cosineembeddingloss": 361, "cosinesimilar": 362, "count_nonzero": 149, "cov": 150, "creation": 712, "cross": 151, "crossentropyloss": 363, "ctcloss": 347, "cummax": 152, "cummin": 153, "cumprod": 154, "cumsum": 155, "cumulative_trapezoid": 156, "custom_from_mask": 528, "customfrommask": 521, "dataparallel": [364, 707], "deg2rad": 157, "dequant": 158, "det": 159, "devic": 711, "diag": 160, "diag_emb": 161, "diagflat": 162, "diagon": 163, "diagonal_scatt": 164, "diff": 165, "digamma": 166, "disabl": 712, "dist": 167, "distanc": 707, "distribut": 707, "distributeddataparallel": 497, "div": 168, "divid": 169, "document": 701, "dot": 170, "dropout": [365, 707], "dropout1d": 366, "dropout2d": 367, "dropout3d": 368, "dsplit": 171, "dstack": 172, "dtype": 711, "einsum": 173, "elu": 369, "embed": 370, "embeddingbag": 371, "empti": 174, "empty_lik": 175, "empty_strid": 176, "enable_grad": 177, "environ": 703, "eq": 178, "equal": 179, "erf": 180, "erfc": 181, "erfinv": 182, "event": 1, "exampl": 703, "exp": 183, "exp2": 184, "expm1": 185, "export": 712, "ey": 186, "fake_quantize_per_channel_affin": 187, "fake_quantize_per_tensor_affin": 188, "featurealphadropout": 372, "fix": 189, "flatten": [190, 373], "flip": 191, "fliplr": 192, "flipud": 193, "float_pow": 194, "floor": 195, "floor_divid": 196, "flow": 712, "fmax": 197, "fmin": 198, "fmod": 199, "fold": 374, "foreach": 712, "fp32": 703, "frac": 200, "fractionalmaxpool2d": 375, "fractionalmaxpool3d": 376, "frexp": 201, "from": 703, "from_dlpack": 202, "from_fil": 203, "from_numpi": 204, "frombuff": 205, "fsdp": 704, "full": 206, "full_lik": 207, "function": 707, "functional_cal": 548, "fuse_conv_bn_ev": 507, "fuse_conv_bn_weight": 508, "fuse_linear_bn_ev": 509, "fuse_linear_bn_weight": 510, "gather": 208, "gaussiannllloss": 381, "gcd": 209, "ge": 210, "gelu": 377, "gener": [2, 712], "geqrf": 211, "ger": 212, "get": [703, 709], "get_default_devic": 213, "get_default_dtyp": 214, "get_deterministic_debug_mod": 215, "get_device_modul": 216, "get_float32_matmul_precis": 217, "get_num_interop_thread": 218, "get_num_thread": 219, "get_rng_stat": 220, "global_unstructur": 529, "glu": 378, "gpu": [703, 707], "gradient": [221, 712], "greater": 222, "greater_equ": 223, "groupnorm": 382, "gru": 379, "grucel": 380, "gt": 224, "hamming_window": 225, "hann_window": 226, "hardshrink": 383, "hardsigmoid": 384, "hardswish": 385, "hardtanh": 386, "hardwar": 703, "head": [701, 708, 709], "heavisid": 227, "hingeembeddingloss": 387, "histc": 228, "histogram": 229, "histogramdd": 230, "home": 702, "hsplit": 231, "hstack": 232, "huberloss": 388, "hypot": 233, "i0": 234, "ident": [389, 522, 530], "igamma": 235, "igammac": 236, "imag": 237, "index": 712, "index_add": 238, "index_copi": 239, "index_reduc": 240, "index_select": 241, "infer": 703, "inference_mod": 103, "initi": 707, "initial_se": 242, "inner": 243, "instancenorm1d": 390, "instancenorm2d": 391, "instancenorm3d": 392, "intel": 703, "invers": 244, "is_complex": 245, "is_conj": 246, "is_deterministic_algorithms_warn_only_en": 247, "is_floating_point": 248, "is_grad_en": 249, "is_inference_mode_en": 250, "is_nonzero": 251, "is_parametr": 517, "is_prun": 531, "is_storag": 252, "is_tensor": 253, "is_warn_always_en": 254, "isclos": 255, "isfinit": 256, "isin": 257, "isinf": 258, "isnan": 259, "isneginf": 260, "isposinf": 261, "isreal": 262, "istft": 263, "join": 712, "kaiser_window": 264, "kldivloss": 393, "kron": 265, "kthvalu": 266, "l1_unstructur": 532, "l1loss": 394, "l1unstructur": 523, "lapack": 712, "layer": 707, "layernorm": 400, "layout": 711, "lazi": [487, 707], "lazybatchnorm1d": 401, "lazybatchnorm2d": 402, "lazybatchnorm3d": 403, "lazyconv1d": 404, "lazyconv2d": 405, "lazyconv3d": 406, "lazyconvtranspose1d": 407, "lazyconvtranspose2d": 408, "lazyconvtranspose3d": 409, "lazyinstancenorm1d": 410, "lazyinstancenorm2d": 411, "lazyinstancenorm3d": 412, "lazylinear": 413, "lazymodulemixin": 487, "lcm": 267, "ldexp": 268, "le": 269, "leakyrelu": 414, "lerp": 270, "less": 271, "less_equ": 272, "lgamma": 273, "linear": [415, 707], "linspac": 274, "ln_structur": 533, "lnstructur": 524, "load": 275, "lobpcg": 276, "local": 712, "localresponsenorm": 416, "log": 277, "log10": 278, "log1p": 279, "log2": 280, "logaddexp": 281, "logaddexp2": 282, "logcumsumexp": 283, "logdet": 284, "logical_and": 285, "logical_not": 286, "logical_or": 287, "logical_xor": 288, "logit": 289, "logsigmoid": 417, "logsoftmax": 418, "logspac": 290, "logsumexp": 291, "loss": 707, "lppool1d": 395, "lppool2d": 396, "lppool3d": 397, "lstm": 398, "lstmcell": 399, "lt": 292, "lu": 293, "lu_solv": 294, "lu_unpack": 295, "manual_se": 296, "marginrankingloss": 420, "markdown": 710, "masked_select": 297, "math": 712, "matmul": 298, "matrix_exp": 299, "matrix_pow": 300, "max": 301, "maximum": 302, "maxpool1d": 421, "maxpool2d": 422, "maxpool3d": 423, "maxunpool1d": 424, "maxunpool2d": 425, "maxunpool3d": 426, "mean": 303, "median": 304, "memory_format": 711, "meshgrid": 305, "min": 306, "minimum": [307, 703], "mish": 427, "mm": 308, "mode": 309, "modul": [428, 487, 496, 707], "moduledict": 429, "modulelist": 430, "moveaxi": 310, "movedim": 311, "mseloss": 419, "msort": 312, "mul": 313, "multi": 707, "multiheadattent": 434, "multilabelmarginloss": 431, "multilabelsoftmarginloss": 432, "multimarginloss": 433, "multinomi": 314, "multipli": 315, "mutat": 712, "mv": 316, "mvlgamma": 317, "my": 705, "nan_to_num": 318, "nanmean": 319, "nanmedian": 320, "nanquantil": 321, "nansum": 322, "narrow": 323, "narrow_copi": 324, "ne": 325, "neg": [326, 327], "nextaft": 328, "nllloss": 435, "nn": [329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 497, 498, 499, 500, 501, 515, 707], "no_grad": 551, "non": 707, "nonlinear": 707, "nonzero": 552, "norm": 553, "normal": [496, 554, 707], "not_equ": 555, "note": 704, "nuanc": 704, "number": 712, "numel": 556, "ones": 557, "ones_lik": 558, "op": 712, "oper": 712, "optim": 712, "orgqr": 559, "ormqr": 560, "orthogon": 512, "other": [707, 712], "outer": 561, "overview": 708, "pack_padded_sequ": 540, "pack_sequ": 541, "packedsequ": 539, "pad": 707, "pad_packed_sequ": 542, "pad_sequ": 543, "page": [702, 705, 706, 710], "pairwisedist": 437, "parallel": [497, 712], "paramet": [498, 499, 500, 501], "parameterdict": 438, "parameterlist": 439, "parameters_to_vector": 511, "parametr": 515, "parametrizationlist": 515, "path": 712, "payload": 704, "pca_lowrank": 562, "permut": 563, "pinvers": 564, "pixelshuffl": 440, "pixelunshuffl": 441, "place": 712, "pointwis": 712, "poisson": 565, "poissonnllloss": 442, "polar": 566, "polygamma": 567, "pool": 707, "posit": 568, "pow": 569, "prefetch": 704, "prelu": 436, "prerequisit": 703, "prod": 570, "promote_typ": 571, "pruningcontain": 525, "pytorch": [701, 703], "qr": 572, "quantil": 573, "quantiz": 707, "quantize_per_channel": 574, "quantize_per_tensor": 575, "quantized_batch_norm": 576, "quantized_max_pool1d": 577, "quantized_max_pool2d": 578, "quasi": 712, "quasirandom": 579, "rad2deg": 580, "rand": 581, "rand_lik": 582, "randint": 583, "randint_lik": 584, "randn": 585, "randn_lik": 586, "random": 712, "random_structur": 534, "random_unstructur": 535, "randomstructur": 526, "randomunstructur": 527, "randperm": 587, "rang": 588, "ravel": 589, "real": 590, "reciproc": 591, "recurr": 707, "reduct": 712, "reflectionpad1d": 450, "reflectionpad2d": 451, "reflectionpad3d": 452, "register_module_backward_hook": 488, "register_module_buffer_registration_hook": 489, "register_module_forward_hook": 490, "register_module_forward_pre_hook": 491, "register_module_full_backward_hook": 492, "register_module_full_backward_pre_hook": 493, "register_module_module_registration_hook": 494, "register_module_parameter_registration_hook": 495, "register_parametr": 518, "relu": 448, "relu6": 449, "remaind": 592, "remov": 536, "remove_parametr": 519, "remove_spectral_norm": 537, "remove_weight_norm": 538, "renorm": 593, "repeat_interleav": 594, "replicationpad1d": 453, "replicationpad2d": 454, "replicationpad3d": 455, "reshap": 595, "resolve_conj": 596, "resolve_neg": 597, "result_typ": 598, "rmsnorm": [443, 496], "rnn": 444, "rnnbase": 445, "rnncell": 446, "roll": 599, "rot90": 600, "round": 601, "row_stack": 602, "rrelu": 447, "rsqrt": 603, "sampl": 712, "save": 604, "scatter": 605, "scatter_add": 606, "scatter_reduc": 607, "searchsort": 608, "seed": 609, "select": 610, "select_scatt": 611, "selu": 456, "sequenti": 457, "serial": 712, "set": 703, "set_default_devic": 612, "set_default_dtyp": 613, "set_default_tensor_typ": 614, "set_deterministic_debug_mod": 615, "set_float32_matmul_precis": 616, "set_flush_denorm": 617, "set_grad_en": 104, "set_num_interop_thread": 618, "set_num_thread": 619, "set_printopt": 620, "set_rng_stat": 621, "set_warn_alwai": 622, "sgn": 623, "shuffl": 707, "sigmoid": [459, 624], "sign": 625, "signbit": 626, "silu": 458, "sin": 627, "sinc": 628, "sinh": 629, "size": 704, "skip_init": 546, "slice": 712, "slice_scatt": 630, "slogdet": 631, "smoothl1loss": 460, "sobolengin": 579, "softmarginloss": 461, "softmax": [462, 632], "softmax2d": 463, "softmin": 464, "softplu": 465, "softshrink": 466, "softsign": 467, "softwar": 703, "sort": 633, "sourc": 703, "spars": 707, "sparse_bsc_tensor": 634, "sparse_bsr_tensor": 635, "sparse_coo_tensor": 636, "sparse_csc_tensor": 637, "sparse_csr_tensor": 638, "spectral": 712, "spectral_norm": [513, 547], "sphinx": 701, "split": 639, "sqrt": 640, "squar": 641, "squeez": 642, "stack": 643, "start": [703, 709], "std": 644, "std_mean": 645, "stft": 646, "stream": 3, "sub": 647, "subead": 708, "subhead": 705, "subintro": 702, "subtract": 648, "sum": [649, 707], "svd": 650, "svd_lowrank": 651, "swapax": 652, "swapdim": 653, "sym_float": 654, "sym_int": 655, "sym_it": 656, "sym_max": 657, "sym_min": 658, "sym_not": 659, "symbol": 712, "syncbatchnorm": 468, "t": 660, "tag": 712, "take": 661, "take_along_dim": 662, "tan": 663, "tanh": [469, 664], "tanhshrink": 470, "tensor": [665, 710, 711, 712], "tensor_split": 666, "tensordot": 667, "test": [705, 706, 710], "theme": 701, "threshold": 471, "tile": 668, "topk": 669, "torch": [329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 496, 497, 498, 499, 500, 501, 515, 579, 703, 707, 710, 711, 712], "trace": 670, "train": 703, "transform": [472, 707], "transformerdecod": 473, "transformerdecoderlay": 474, "transformerencod": 475, "transformerencoderlay": 476, "transpos": 671, "trapezoid": 672, "trapz": 673, "triangular_solv": 674, "tril": 675, "tril_indic": 676, "tripletmarginloss": 477, "tripletmarginwithdistanceloss": 478, "triu": 677, "triu_indic": 678, "true_divid": 679, "trunc": 680, "tutori": [713, 714, 715], "unbind": 681, "unflatten": [479, 682], "unfold": 480, "uninitializedbuff": 500, "uninitializedparamet": 501, "uniqu": 683, "unique_consecut": 684, "unpack_sequ": 544, "unpad_sequ": 545, "unravel_index": 685, "unsqueez": 686, "up": 703, "upsampl": 481, "upsamplingbilinear2d": 482, "upsamplingnearest2d": 483, "use_deterministic_algorithm": 687, "util": [515, 707, 712], "vander": 688, "var": 689, "var_mean": 690, "vdot": 691, "vector_to_paramet": 549, "view_as_complex": 692, "view_as_r": 693, "vision": 707, "vmap": 694, "vsplit": 695, "vstack": 696, "warn": 710, "weight": 707, "weight_norm": [514, 550], "where": 697, "xlogi": 698, "zero": 699, "zeropad1d": 484, "zeropad2d": 485, "zeropad3d": 486, "zeros_lik": 700}})